import requests
import pandas as pd
import re
import os
import time
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import sys

###############################################################################
#                           é…ç½®åŒºåŸŸ - æ‰€æœ‰é…ç½®é›†ä¸­åœ¨æ­¤å¤„                     #
###############################################################################

# =============================================================================
# æ–‡ä»¶è·¯å¾„é…ç½®
# =============================================================================

# æœ¬åœ°æºæ–‡ä»¶è·¯å¾„ï¼šåŒ…å«è‡ªå®šä¹‰çš„ç›´æ’­æºï¼Œæ ¼å¼ä¸º"é¢‘é“åç§°,URL"æˆ–ç›´æ¥URL
LOCAL_SOURCE_FILE = "local.txt"

# é¢‘é“æ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼šå®šä¹‰è¾“å‡ºæ–‡ä»¶ä¸­é¢‘é“çš„æ’åºé¡ºåºï¼Œæ¯è¡Œä¸€ä¸ªé¢‘é“åç§°
DEMO_TEMPLATE_FILE = "demo.txt"

# è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼šç”Ÿæˆçš„ç›´æ’­æºæ–‡ä»¶
OUTPUT_TXT_FILE = "iptv.txt"    # TXTæ ¼å¼è¾“å‡ºæ–‡ä»¶
OUTPUT_M3U_FILE = "iptv.m3u"    # M3Uæ ¼å¼è¾“å‡ºæ–‡ä»¶

# =============================================================================
# ç½‘ç»œè¯·æ±‚é…ç½®
# =============================================================================

# åœ¨çº¿ç›´æ’­æºURLåˆ—è¡¨ï¼šç¨‹åºä¼šä»è¿™äº›URLè·å–ç›´æ’­æºæ•°æ®
ONLINE_SOURCE_URLS = [
     "https://ghfast.top/raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt",
     "https://gh-proxy.com/https://raw.githubusercontent.com/wwb521/live/main/tv.m3u",
     "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv4/result.m3u",  
     "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
     "https://raw.githubusercontent.com/suxuang/myIPTV/main/ipv4.m3u",
     "https://raw.githubusercontent.com/vbskycn/iptv/master/tv/iptv4.txt",
     "https://gh-proxy.com/https://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt",
     "http://47.120.41.246:8899/zb.txt",
]

# è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼šç½‘ç»œè¯·æ±‚çš„æœ€å¤§ç­‰å¾…æ—¶é—´
REQUEST_TIMEOUT = 10

# ç”¨æˆ·ä»£ç†å¤´ï¼šæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®ï¼Œé¿å…è¢«ç½‘ç«™å±è”½
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

# =============================================================================
# å¹¶å‘å¤„ç†é…ç½®
# =============================================================================

# æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼šåŒæ—¶è¿›è¡Œçš„ç½‘ç»œè¯·æ±‚æ•°é‡
MAX_WORKERS = 10

# é¢‘é“æµ‹è¯•å¹¶å‘æ•°ï¼šåŒæ—¶æµ‹è¯•çš„é¢‘é“æ•°é‡
CHANNEL_TEST_WORKERS = 5

# URLæµ‹è¯•å¹¶å‘æ•°ï¼šå•ä¸ªé¢‘é“å†…åŒæ—¶æµ‹è¯•çš„URLæ•°é‡
URL_TEST_WORKERS = 8

# =============================================================================
# é¢‘é“å¤„ç†é…ç½®
# =============================================================================

# å•ä¸ªé¢‘é“æœ€å¤§ä¿ç•™URLæ•°é‡ï¼šæ¯ä¸ªé¢‘é“æœ€ç»ˆä¿ç•™çš„æœ€ä½³æºæ•°é‡
MAX_URLS_PER_CHANNEL = 8

# æµæµ‹è¯•è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼šæµ‹è¯•å•ä¸ªæµåª’ä½“çš„æœ€å¤§æ—¶é—´
STREAM_TEST_TIMEOUT = 8

# =============================================================================
# æ­£åˆ™è¡¨è¾¾å¼é…ç½®
# =============================================================================

# IPv4åœ°å€åŒ¹é…æ¨¡å¼ï¼šè¯†åˆ«IPv4æ ¼å¼çš„URL
IPV4_PATTERN = re.compile(r'^https?://(\d{1,3}\.){3}\d{1,3}')

# M3Uæ ¼å¼è§£ææ¨¡å¼ï¼šä»EXTINFè¡Œä¸­æå–é¢‘é“åç§°
EXTINF_PATTERN = re.compile(r'tvg-name="([^"]+)"')

# TXTæ ¼å¼è§£ææ¨¡å¼ï¼šåŒ¹é…"é¢‘é“åç§°,URL"æ ¼å¼
TXT_LINE_PATTERN = re.compile(r"^(.+?),(?:\s*)(http.+)")

# é¢‘é“åç§°æ¸…ç†æ¨¡å¼ï¼šç§»é™¤æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
CHANNEL_NAME_CLEAN_PATTERN = re.compile(r'[<>:"/\\|?*]')

###############################################################################
#                           ç¨‹åºä»£ç åŒºåŸŸ - ä¸è¦ä¿®æ”¹ä¸‹é¢çš„ä»£ç                  #
###############################################################################

class StreamTester:
    """æµåª’ä½“æµ‹è¯•å™¨ - åªæµ‹è¯•å“åº”å»¶æ—¶"""
    
    def __init__(self):
        self.results_cache = {}
        self.lock = threading.Lock()
        self.test_count = 0
        self.success_count = 0
    
    def test_stream(self, program_name, stream_url):
        """æµ‹è¯•å•ä¸ªæµåª’ä½“çš„å“åº”æ—¶é—´"""
        cache_key = f"{program_name}|{stream_url}"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.results_cache:
            return self.results_cache[cache_key]
        
        self.test_count += 1
        start_time = time.time()
        
        try:
            # ä½¿ç”¨HEADè¯·æ±‚æµ‹è¯•å“åº”æ—¶é—´
            response = requests.head(
                stream_url, 
                timeout=STREAM_TEST_TIMEOUT,
                headers=HEADERS,
                allow_redirects=True
            )
            response.close()
            
            response_time = (time.time() - start_time) * 1000  # æ¯«ç§’
            
            result = {
                'response_time': response_time,
                'available': True,
                'status_code': response.status_code
            }
            
            self.success_count += 1
            
        except Exception as e:
            result = {
                'response_time': 9999,
                'available': False,
                'status_code': 0,
                'error': str(e)
            }
        
        # ç¼“å­˜ç»“æœ
        with self.lock:
            self.results_cache[cache_key] = result
        
        return result
    
    def calculate_score(self, test_result):
        """è®¡ç®—å¾—åˆ† - åŸºäºå“åº”æ—¶é—´ï¼Œå“åº”æ—¶é—´è¶ŠçŸ­å¾—åˆ†è¶Šé«˜"""
        if not test_result['available']:
            return 0
        
        # å“åº”æ—¶é—´å¾—åˆ†ï¼ˆå“åº”æ—¶é—´è¶ŠçŸ­å¾—åˆ†è¶Šé«˜ï¼‰
        # å“åº”æ—¶é—´0-100mså¾—100åˆ†ï¼Œ100-500msçº¿æ€§é€’å‡ï¼Œ500msä»¥ä¸Šå¾—0åˆ†
        response_time = test_result['response_time']
        if response_time <= 100:
            score = 100
        elif response_time <= 500:
            score = 100 - (response_time - 100) / 4  # 100-500msçº¿æ€§é€’å‡
        else:
            score = 0
        
        return round(score, 2)
    
    def get_stats(self):
        """è·å–æµ‹è¯•ç»Ÿè®¡"""
        return {
            'total_tests': self.test_count,
            'successful_tests': self.success_count,
            'success_rate': round(self.success_count / max(self.test_count, 1) * 100, 2),
            'cache_size': len(self.results_cache)
        }

def clean_channel_name(name):
    """æ¸…ç†é¢‘é“åç§°ä¸­çš„éæ³•å­—ç¬¦"""
    if not name or not isinstance(name, str):
        return "æœªçŸ¥é¢‘é“"
    return CHANNEL_NAME_CLEAN_PATTERN.sub('_', name).strip()

def load_local_sources():
    """åŠ è½½æœ¬åœ°æº"""
    if not os.path.exists(LOCAL_SOURCE_FILE):
        print(f"ğŸ“ æœ¬åœ°æºæ–‡ä»¶ {LOCAL_SOURCE_FILE} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return []
    
    streams = []
    try:
        with open(LOCAL_SOURCE_FILE, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                # æ”¯æŒå¤šç§æ ¼å¼
                if ',' in line:
                    parts = line.split(',', 1)
                    if len(parts) == 2 and parts[1].startswith(('http://', 'https://')):
                        program_name = clean_channel_name(parts[0].strip())
                        stream_url = parts[1].strip()
                        streams.append({
                            "program_name": program_name,
                            "stream_url": stream_url,
                            "source": "local"
                        })
                elif line.startswith(('http://', 'https://')):
                    program_name = f"æœ¬åœ°é¢‘é“_{line_num}"
                    streams.append({
                        "program_name": program_name,
                        "stream_url": line.strip(),
                        "source": "local"
                    })
    except Exception as e:
        print(f"âŒ è¯»å–æœ¬åœ°æºæ–‡ä»¶å¤±è´¥: {e}")
    
    print(f"âœ… ä»æœ¬åœ°æºåŠ è½½äº† {len(streams)} ä¸ªé¢‘é“")
    return streams

def load_demo_template():
    """åŠ è½½æ¨¡æ¿é¢‘é“åˆ—è¡¨"""
    if not os.path.exists(DEMO_TEMPLATE_FILE):
        print(f"âš ï¸ æ¨¡æ¿æ–‡ä»¶ {DEMO_TEMPLATE_FILE} ä¸å­˜åœ¨ï¼Œå°†æŒ‰é¢‘é“åæ’åº")
        return []
    
    channels = []
    try:
        with open(DEMO_TEMPLATE_FILE, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line and not line.startswith('#'):
                    cleaned_name = clean_channel_name(line)
                    if cleaned_name and cleaned_name != "æœªçŸ¥é¢‘é“":
                        channels.append(cleaned_name)
    except Exception as e:
        print(f"âŒ è¯»å–æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
    
    print(f"ğŸ“‹ ä»æ¨¡æ¿åŠ è½½äº† {len(channels)} ä¸ªé¢‘é“")
    return channels

def fetch_streams_from_url(url):
    """ä»URLè·å–ç›´æ’­æºæ•°æ®"""
    print(f"ğŸŒ æ­£åœ¨çˆ¬å–ç½‘ç«™æº: {url}")
    try:
        response = requests.get(url, timeout=REQUEST_TIMEOUT, headers=HEADERS)
        response.encoding = 'utf-8'
        response.raise_for_status()
        
        content_length = len(response.content)
        print(f"âœ… æˆåŠŸè·å– {url} çš„æ•°æ® ({content_length} å­—èŠ‚)")
        return response.text
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚ {url} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

def fetch_online_sources(urls):
    """è·å–åœ¨çº¿æº"""
    if not urls:
        print("âš ï¸ æœªæä¾›åœ¨çº¿æºURLï¼Œè·³è¿‡åœ¨çº¿æºè·å–")
        return []
    
    all_streams = []
    
    print("ğŸš€ å¼€å§‹è·å–åœ¨çº¿ç›´æ’­æº...")
    with ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(urls))) as executor:
        future_to_url = {executor.submit(fetch_streams_from_url, url): url for url in urls}
        
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            try:
                if content := future.result():
                    # è§£æå†…å®¹
                    if content.startswith("#EXTM3U"):
                        streams = parse_m3u(content)
                    else:
                        streams = parse_txt(content)
                    
                    # æ ‡è®°æ¥æºå¹¶æ¸…ç†é¢‘é“å
                    for stream in streams:
                        stream['source'] = 'online'
                        stream['program_name'] = clean_channel_name(stream['program_name'])
                    
                    all_streams.extend(streams)
                    print(f"ğŸ“¡ ä» {url} è§£æäº† {len(streams)} ä¸ªé¢‘é“")
            except Exception as e:
                print(f"âŒ å¤„ç† {url} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    print(f"âœ… ä»åœ¨çº¿æºè·å–äº† {len(all_streams)} ä¸ªé¢‘é“")
    return all_streams

def parse_m3u(content):
    """è§£æM3Uæ ¼å¼"""
    streams = []
    current_program = None
    
    for line in content.splitlines():
        line = line.strip()
        if not line:
            continue
            
        if line.startswith("#EXTINF"):
            current_program = "æœªçŸ¥é¢‘é“"
            if match := EXTINF_PATTERN.search(line):
                current_program = match.group(1).strip()
            elif "," in line:
                current_program = line.split(",", 1)[1].strip()
            current_program = clean_channel_name(current_program)
                
        elif line.startswith(('http://', 'https://')):
            if current_program:
                streams.append({
                    "program_name": current_program,
                    "stream_url": line.strip()
                })
                current_program = None
                
    return streams

def parse_txt(content):
    """è§£æTXTæ ¼å¼"""
    streams = []
    for line in content.splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        
        # å°è¯•åŒ¹é… "é¢‘é“å,URL" æ ¼å¼
        if match := TXT_LINE_PATTERN.match(line):
            program_name = clean_channel_name(match.group(1).strip())
            stream_url = match.group(2).strip()
            
            streams.append({
                "program_name": program_name,
                "stream_url": stream_url
            })
        elif line.startswith(('http://', 'https://')):
            # åªæœ‰URLæ²¡æœ‰é¢‘é“åçš„æƒ…å†µ
            streams.append({
                "program_name": f"åœ¨çº¿é¢‘é“_{len(streams)}",
                "stream_url": line.strip()
            })
            
    return streams

def merge_and_deduplicate_sources(local_sources, online_sources):
    """åˆå¹¶å¹¶å»é‡æº"""
    all_sources = []
    seen_urls = set()
    
    # ä¼˜å…ˆæ·»åŠ æœ¬åœ°æº
    for source in local_sources:
        if source['stream_url'] not in seen_urls:
            all_sources.append(source)
            seen_urls.add(source['stream_url'])
    
    # æ·»åŠ åœ¨çº¿æºï¼ˆä¸é‡å¤çš„ï¼‰
    for source in online_sources:
        if source['stream_url'] not in seen_urls:
            all_sources.append(source)
            seen_urls.add(source['stream_url'])
    
    print(f"ğŸ”„ åˆå¹¶åæ€»é¢‘é“æ•°: {len(all_sources)} (æœ¬åœ°: {len(local_sources)}, åœ¨çº¿: {len(online_sources)}, å»é‡: {len(local_sources) + len(online_sources) - len(all_sources)})")
    return all_sources

def group_by_channel(sources):
    """æŒ‰é¢‘é“ååˆ†ç»„"""
    channels = {}
    
    for source in sources:
        program_name = source['program_name']
        if not program_name or program_name == "æœªçŸ¥é¢‘é“":
            continue
            
        if program_name not in channels:
            channels[program_name] = []
        
        channels[program_name].append({
            'url': source['stream_url'],
            'source': source.get('source', 'unknown')
        })
    
    return channels

def test_channel_urls(tester, program_name, urls):
    """æµ‹è¯•é¢‘é“çš„æ‰€æœ‰URLå¹¶æ’åº"""
    if not urls:
        return []
    
    test_results = []
    
    print(f"ğŸ” æµ‹è¯•é¢‘é“ '{program_name}' çš„ {len(urls)} ä¸ªæº...")
    
    with ThreadPoolExecutor(max_workers=min(URL_TEST_WORKERS, len(urls))) as executor:
        future_to_url = {
            executor.submit(tester.test_stream, program_name, url_info['url']): url_info 
            for url_info in urls
        }
        
        for future in as_completed(future_to_url):
            url_info = future_to_url[future]
            try:
                test_result = future.result()
                score = tester.calculate_score(test_result)
                
                test_results.append({
                    'url': url_info['url'],
                    'source': url_info['source'],
                    'response_time': round(test_result['response_time'], 2),
                    'available': test_result['available'],
                    'score': score
                })
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•URL {url_info['url']} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    # æŒ‰å¾—åˆ†æ’åºï¼Œè¿‡æ»¤ä¸å¯ç”¨çš„
    available_results = [r for r in test_results if r['available']]
    sorted_results = sorted(available_results, key=lambda x: x['score'], reverse=True)
    
    # é™åˆ¶æ¯ä¸ªé¢‘é“çš„URLæ•°é‡
    final_results = sorted_results[:MAX_URLS_PER_CHANNEL]
    
    if final_results:
        best_time = final_results[0]['response_time']
        print(f"âœ… {program_name}: æ‰¾åˆ° {len(final_results)} ä¸ªå¯ç”¨æº (æœ€ä½³å“åº”: {best_time}ms)")
    else:
        print(f"âŒ {program_name}: æ— å¯ç”¨æº")
    
    return final_results

def organize_channels_by_template(template_channels, tested_channels):
    """æŒ‰ç…§æ¨¡æ¿é¡ºåºæ•´ç†é¢‘é“"""
    organized = []
    missing_channels = []
    added_channels = set()
    
    # æŒ‰ç…§æ¨¡æ¿é¡ºåºæ·»åŠ é¢‘é“
    for channel_name in template_channels:
        if channel_name in tested_channels and tested_channels[channel_name]:
            channel_data = tested_channels[channel_name]
            organized.append({
                'program_name': channel_name,
                'streams': channel_data
            })
            added_channels.add(channel_name)
        else:
            missing_channels.append(channel_name)
    
    # æ·»åŠ æ¨¡æ¿ä¸­æ²¡æœ‰ä½†æºä¸­æœ‰çš„é¢‘é“
    for channel_name, channel_data in tested_channels.items():
        if channel_name not in added_channels and channel_data:
            organized.append({
                'program_name': channel_name,
                'streams': channel_data
            })
    
    # æŠ¥å‘Šç¼ºå¤±é¢‘é“
    if missing_channels:
        print(f"âš ï¸ ä»¥ä¸‹ {len(missing_channels)} ä¸ªæ¨¡æ¿é¢‘é“æœªæ‰¾åˆ°æˆ–æ— å¯ç”¨çš„æº: {', '.join(missing_channels[:5])}{'...' if len(missing_channels) > 5 else ''}")
    
    return organized

def display_channel_stats(organized_channels, tester):
    """æ˜¾ç¤ºé¢‘é“ç»Ÿè®¡ä¿¡æ¯"""
    if not organized_channels:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„é¢‘é“æ•°æ®")
        return
    
    print("\n" + "="*60)
    print("ğŸ“Š é¢‘é“ç»Ÿè®¡æŠ¥å‘Š")
    print("="*60)
    
    total_channels = len(organized_channels)
    total_streams = sum(len(channel['streams']) for channel in organized_channels)
    avg_streams_per_channel = round(total_streams / max(total_channels, 1), 2)
    
    # ç»Ÿè®¡æºç±»å‹
    local_count = 0
    online_count = 0
    
    # ç»Ÿè®¡æ¯ä¸ªé¢‘é“çš„æ¥å£æ•°é‡
    channel_stream_counts = {}
    for channel in organized_channels:
        stream_count = len(channel['streams'])
        channel_stream_counts[channel['program_name']] = stream_count
    
    for channel in organized_channels:
        for stream in channel['streams']:
            if stream.get('source') == 'local':
                local_count += 1
            else:
                online_count += 1
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    print(f"ğŸ“º æ€»é¢‘é“æ•°: {total_channels}")
    print(f"ğŸ”— æ€»æµåª’ä½“æº: {total_streams}")
    print(f"ğŸ“ˆ å¹³å‡æ¯ä¸ªé¢‘é“æºæ•°: {avg_streams_per_channel}")
    print(f"ğŸ’¾ æœ¬åœ°æº: {local_count}")
    print(f"ğŸŒ åœ¨çº¿æº: {online_count}")
    
    # æ˜¾ç¤ºæµ‹è¯•ç»Ÿè®¡
    test_stats = tester.get_stats()
    print(f"ğŸ§ª æµ‹è¯•ç»Ÿè®¡: {test_stats['successful_tests']}/{test_stats['total_tests']} æˆåŠŸ ({test_stats['success_rate']}%)")
    
    # æ˜¾ç¤ºé¢‘é“æ¥å£æ•°é‡åˆ†å¸ƒ
    print(f"\nğŸ“‹ é¢‘é“æ¥å£æ•°é‡åˆ†å¸ƒ:")
    count_distribution = {}
    for count in channel_stream_counts.values():
        count_distribution[count] = count_distribution.get(count, 0) + 1
    
    for count in sorted(count_distribution.keys()):
        channel_count = count_distribution[count]
        print(f"  {count}ä¸ªæ¥å£: {channel_count}ä¸ªé¢‘é“")
    
    print("="*60)

def save_to_txt(organized_channels, filename=OUTPUT_TXT_FILE):
    """ä¿å­˜ä¸ºTXTæ ¼å¼ï¼Œæ˜¾ç¤ºæ¯ä¸ªé¢‘é“çš„æ¥å£æ•°é‡"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            # å†™å…¥æ–‡ä»¶å¤´ä¿¡æ¯
            f.write(f"# IPTVç›´æ’­æºåˆ—è¡¨\n")
            f.write(f"# ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# æ€»é¢‘é“æ•°: {len(organized_channels)}\n")
            f.write(f"# æ€»æ¥å£æ•°: {sum(len(channel['streams']) for channel in organized_channels)}\n\n")
            
            # å†™å…¥é¢‘é“ç»Ÿè®¡
            f.write("# é¢‘é“æ¥å£æ•°é‡ç»Ÿè®¡:\n")
            for channel in organized_channels:
                stream_count = len(channel['streams'])
                f.write(f"# {channel['program_name']}: {stream_count}ä¸ªæ¥å£\n")
            f.write("\n")
            
            # å†™å…¥æ‰€æœ‰æº
            all_streams = []
            
            for channel in organized_channels:
                for stream in channel['streams']:
                    line = f"{channel['program_name']},{stream['url']}"
                    all_streams.append(line)
            
            f.write("\n".join(all_streams))
        
        print(f"âœ… æ–‡æœ¬æ–‡ä»¶å·²ä¿å­˜: {os.path.abspath(filename)}")
        
        # æ˜¾ç¤ºæ–‡ä»¶ä¸­çš„é¢‘é“æ¥å£ä¿¡æ¯
        print(f"ğŸ“‹ ç”Ÿæˆçš„TXTæ–‡ä»¶ä¸­åŒ…å«:")
        for channel in organized_channels:
            stream_count = len(channel['streams'])
            print(f"   {channel['program_name']}: {stream_count}ä¸ªæ¥å£")
            
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜TXTæ–‡ä»¶å¤±è´¥: {e}")
        return False

def save_to_m3u(organized_channels, filename=OUTPUT_M3U_FILE):
    """ä¿å­˜ä¸ºM3Uæ ¼å¼ï¼Œåœ¨æ³¨é‡Šä¸­æ˜¾ç¤ºæ¥å£æ•°é‡"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("#EXTM3U\n")
            f.write(f"# ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# æ€»é¢‘é“æ•°: {len(organized_channels)}\n")
            f.write(f"# æ€»æ¥å£æ•°: {sum(len(channel['streams']) for channel in organized_channels)}\n")
            
            # å†™å…¥é¢‘é“ç»Ÿè®¡
            f.write("# é¢‘é“æ¥å£æ•°é‡ç»Ÿè®¡:\n")
            for channel in organized_channels:
                stream_count = len(channel['streams'])
                f.write(f"# {channel['program_name']}: {stream_count}ä¸ªæ¥å£\n")
            
            # å†™å…¥é¢‘é“æ•°æ®
            for channel in organized_channels:
                stream_count = len(channel['streams'])
                for i, stream in enumerate(channel['streams']):
                    # åœ¨EXTINFè¡Œä¸­æ·»åŠ æ¥å£åºå·ä¿¡æ¯
                    f.write(f'#EXTINF:-1 tvg-name="{channel["program_name"]}",{channel["program_name"]} [æ¥å£{i+1}/{stream_count}]\n')
                    f.write(f"{stream['url']}\n")
        
        print(f"âœ… M3Uæ–‡ä»¶å·²ä¿å­˜: {os.path.abspath(filename)}")
        
        # æ˜¾ç¤ºæ–‡ä»¶ä¸­çš„é¢‘é“æ¥å£ä¿¡æ¯
        print(f"ğŸ“‹ ç”Ÿæˆçš„M3Uæ–‡ä»¶ä¸­åŒ…å«:")
        for channel in organized_channels:
            stream_count = len(channel['streams'])
            print(f"   {channel['program_name']}: {stream_count}ä¸ªæ¥å£")
            
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜M3Uæ–‡ä»¶å¤±è´¥: {e}")
        return False

def create_sample_files():
    """åˆ›å»ºç¤ºä¾‹æ–‡ä»¶"""
    # åˆ›å»ºæœ¬åœ°æºç¤ºä¾‹
    if not os.path.exists(LOCAL_SOURCE_FILE):
        sample_local = """# æœ¬åœ°ç›´æ’­æºç¤ºä¾‹
# æ ¼å¼: é¢‘é“åç§°,URL
CCTV-1,http://example.com/cctv1.m3u8
CCTV-2,http://example.com/cctv2.m3u8
æ¹–å—å«è§†,http://example.com/hunan.m3u8
æµ™æ±Ÿå«è§†,http://example.com/zhejiang.m3u8
"""
        with open(LOCAL_SOURCE_FILE, 'w', encoding='utf-8') as f:
            f.write(sample_local)
        print(f"ğŸ“ å·²åˆ›å»ºç¤ºä¾‹æœ¬åœ°æºæ–‡ä»¶: {LOCAL_SOURCE_FILE}")
    
    # åˆ›å»ºæ¨¡æ¿ç¤ºä¾‹
    if not os.path.exists(DEMO_TEMPLATE_FILE):
        sample_demo = """# é¢‘é“æ¨¡æ¿ç¤ºä¾‹
# æ¯è¡Œä¸€ä¸ªé¢‘é“åç§°ï¼Œå°†æŒ‰æ­¤é¡ºåºæ’åˆ—è¾“å‡º
CCTV-1
CCTV-2
æ¹–å—å«è§†
æµ™æ±Ÿå«è§†
æ±Ÿè‹å«è§†
åŒ—äº¬å«è§†
ä¸œæ–¹å«è§†
"""
        with open(DEMO_TEMPLATE_FILE, 'w', encoding='utf-8') as f:
            f.write(sample_demo)
        print(f"ğŸ“‹ å·²åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶: {DEMO_TEMPLATE_FILE}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ IPTVç›´æ’­æºæ•´ç†å·¥å…·")
    print("=" * 50)
    
    # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    create_sample_files()
    
    start_time = time.time()
    
    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = StreamTester()
    
    try:
        # 1. åŠ è½½æœ¬åœ°æºï¼ˆä¼˜å…ˆï¼‰
        local_sources = load_local_sources()
        
        # 2. åŠ è½½åœ¨çº¿æº
        online_sources = fetch_online_sources(ONLINE_SOURCE_URLS)
        
        # 3. åˆå¹¶æºï¼ˆæœ¬åœ°æºä¼˜å…ˆï¼‰
        all_sources = merge_and_deduplicate_sources(local_sources, online_sources)
        
        if not all_sources:
            print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç›´æ’­æº")
            return
        
        # 4. æŒ‰é¢‘é“åˆ†ç»„
        channel_groups = group_by_channel(all_sources)
        print(f"ğŸ” å‘ç° {len(channel_groups)} ä¸ªå”¯ä¸€é¢‘é“")
        
        if not channel_groups:
            print("âŒ é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„é¢‘é“æ•°æ®")
            return
        
        # 5. æµ‹è¯•æ‰€æœ‰é¢‘é“çš„URLï¼ˆä¸é™åˆ¶æ•°é‡ï¼‰
        print("\nğŸš€ å¼€å§‹æµ‹è¯•æ‰€æœ‰é¢‘é“æº...")
        tested_channels = {}
        
        with ThreadPoolExecutor(max_workers=CHANNEL_TEST_WORKERS) as executor:
            future_to_channel = {
                executor.submit(test_channel_urls, tester, name, urls): name 
                for name, urls in channel_groups.items()
            }
            
            for future in as_completed(future_to_channel):
                channel_name = future_to_channel[future]
                try:
                    tested_urls = future.result()
                    if tested_urls:
                        tested_channels[channel_name] = tested_urls
                except Exception as e:
                    print(f"âŒ æµ‹è¯•é¢‘é“ {channel_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        if not tested_channels:
            print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ç›´æ’­æº")
            return
        
        # 6. æŒ‰ç…§æ¨¡æ¿æ’åº
        template_channels = load_demo_template()
        organized_channels = organize_channels_by_template(template_channels, tested_channels)
        
        print(f"âœ… æ•´ç†å®Œæˆ: {len(organized_channels)} ä¸ªé¢‘é“")
        
        # 7. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        display_channel_stats(organized_channels, tester)
        
        # 8. ä¿å­˜æ–‡ä»¶
        success_txt = save_to_txt(organized_channels)
        success_m3u = save_to_m3u(organized_channels)
        
        total_time = time.time() - start_time
        
        if success_txt and success_m3u:
            print(f"\nğŸ‰ å¤„ç†å®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {OUTPUT_TXT_FILE}, {OUTPUT_M3U_FILE}")
            
            # æ˜¾ç¤ºæœ€ç»ˆæ–‡ä»¶ä¿¡æ¯
            if os.path.exists(OUTPUT_TXT_FILE):
                file_size = os.path.getsize(OUTPUT_TXT_FILE)
                print(f"ğŸ“„ {OUTPUT_TXT_FILE}: {file_size} å­—èŠ‚")
            if os.path.exists(OUTPUT_M3U_FILE):
                file_size = os.path.getsize(OUTPUT_M3U_FILE)
                print(f"ğŸ“„ {OUTPUT_M3U_FILE}: {file_size} å­—èŠ‚")
        else:
            print(f"\nâš ï¸ å¤„ç†å®Œæˆï¼Œä½†éƒ¨åˆ†æ–‡ä»¶ä¿å­˜å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
    except Exception as e:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
