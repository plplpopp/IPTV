import requests
import re
import os
import time
import concurrent.futures
from tqdm import tqdm
import sys
import urllib3
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============================ é…ç½®æ–‡ä»¶ ============================
# æºURLåˆ—è¡¨
URL_SOURCES = [
    "https://raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt",
    "https://raw.githubusercontent.com/wwb521/live/main/tv.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv4/result.m3u",  
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
    "https://raw.githubusercontent.com/suxuang/myIPTV/main/ipv4.m3u",
    "https://raw.githubusercontent.com/vbskycn/iptv/master/tv/iptv4.txt",
    "https://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt",
    "http://47.120.41.246:8899/zb.txt",
]

# æœ¬åœ°æºæ–‡ä»¶
LOCAL_SOURCE_FILE = "local.txt"

# æ¨¡æ¿é¢‘é“æ–‡ä»¶
TEMPLATE_FILE = "demo.txt"

# è¾“å‡ºæ–‡ä»¶
OUTPUT_TXT = "iptv.txt"
OUTPUT_M3U = "iptv.m3u"

# æ¯ä¸ªé¢‘é“ä¿ç•™çš„æ¥å£æ•°é‡
MAX_STREAMS_PER_CHANNEL = 5

# è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
REQUEST_TIMEOUT = 8

# æµ‹é€Ÿè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
SPEED_TEST_TIMEOUT = 12

# æœ€å¤§çº¿ç¨‹æ•°
MAX_WORKERS = 15

# ============================ é¢‘é“åç§°æ˜ å°„å’Œè§„åˆ™ ============================
CHANNEL_MAPPING_RULES = {
    # CCTVé¢‘é“æ˜ å°„
    'CCTV-1': ['CCTV1', 'CCTV-1', 'CCTV 1', 'å¤®è§†1å¥—', 'ä¸­å¤®1å¥—', 'CCTV1ç»¼åˆ', 'ä¸­å¤®ä¸€å¥—', 'å¤®è§†ä¸€å¥—'],
    'CCTV-2': ['CCTV2', 'CCTV-2', 'CCTV 2', 'å¤®è§†2å¥—', 'ä¸­å¤®2å¥—', 'CCTV2è´¢ç»', 'ä¸­å¤®äºŒå¥—', 'å¤®è§†äºŒå¥—'],
    'CCTV-3': ['CCTV3', 'CCTV-3', 'CCTV 3', 'å¤®è§†3å¥—', 'ä¸­å¤®3å¥—', 'CCTV3ç»¼è‰º', 'ä¸­å¤®ä¸‰å¥—', 'å¤®è§†ä¸‰å¥—'],
    'CCTV-4': ['CCTV4', 'CCTV-4', 'CCTV 4', 'å¤®è§†4å¥—', 'ä¸­å¤®4å¥—', 'CCTV4ä¸­æ–‡å›½é™…', 'ä¸­å¤®å››å¥—', 'å¤®è§†å››å¥—'],
    'CCTV-5': ['CCTV5', 'CCTV-5', 'CCTV 5', 'å¤®è§†5å¥—', 'ä¸­å¤®5å¥—', 'CCTV5ä½“è‚²', 'ä¸­å¤®äº”å¥—', 'å¤®è§†äº”å¥—'],
    'CCTV-5+': ['CCTV5+', 'CCTV5plus', 'CCTV-5+', 'CCTV5 Plus', 'å¤®è§†5+', 'CCTV5+ä½“è‚²èµ›äº‹'],
    'CCTV-6': ['CCTV6', 'CCTV-6', 'CCTV 6', 'å¤®è§†6å¥—', 'ä¸­å¤®6å¥—', 'CCTV6ç”µå½±', 'ä¸­å¤®å…­å¥—', 'å¤®è§†å…­å¥—'],
    'CCTV-7': ['CCTV7', 'CCTV-7', 'CCTV 7', 'å¤®è§†7å¥—', 'ä¸­å¤®7å¥—', 'CCTV7å›½é˜²å†›äº‹', 'ä¸­å¤®ä¸ƒå¥—', 'å¤®è§†ä¸ƒå¥—'],
    'CCTV-8': ['CCTV8', 'CCTV-8', 'CCTV 8', 'å¤®è§†8å¥—', 'ä¸­å¤®8å¥—', 'CCTV8ç”µè§†å‰§', 'ä¸­å¤®å…«å¥—', 'å¤®è§†å…«å¥—'],
    'CCTV-9': ['CCTV9', 'CCTV-9', 'CCTV 9', 'å¤®è§†9å¥—', 'ä¸­å¤®9å¥—', 'CCTV9çºªå½•', 'ä¸­å¤®ä¹å¥—', 'å¤®è§†ä¹å¥—'],
    'CCTV-10': ['CCTV10', 'CCTV-10', 'CCTV 10', 'å¤®è§†10å¥—', 'ä¸­å¤®10å¥—', 'CCTV10ç§‘æ•™', 'ä¸­å¤®åå¥—', 'å¤®è§†åå¥—'],
    'CCTV-11': ['CCTV11', 'CCTV-11', 'CCTV 11', 'å¤®è§†11å¥—', 'ä¸­å¤®11å¥—', 'CCTV11æˆæ›²', 'ä¸­å¤®åä¸€å¥—', 'å¤®è§†åä¸€å¥—'],
    'CCTV-12': ['CCTV12', 'CCTV-12', 'CCTV 12', 'å¤®è§†12å¥—', 'ä¸­å¤®12å¥—', 'CCTV12ç¤¾ä¼šä¸æ³•', 'ä¸­å¤®åäºŒå¥—', 'å¤®è§†åäºŒå¥—'],
    'CCTV-13': ['CCTV13', 'CCTV-13', 'CCTV 13', 'å¤®è§†13å¥—', 'ä¸­å¤®13å¥—', 'CCTV13æ–°é—»', 'ä¸­å¤®åä¸‰å¥—', 'å¤®è§†åä¸‰å¥—'],
    'CCTV-14': ['CCTV14', 'CCTV-14', 'CCTV 14', 'å¤®è§†14å¥—', 'ä¸­å¤®14å¥—', 'CCTV14å°‘å„¿', 'ä¸­å¤®åå››å¥—', 'å¤®è§†åå››å¥—'],
    'CCTV-15': ['CCTV15', 'CCTV-15', 'CCTV 15', 'å¤®è§†15å¥—', 'ä¸­å¤®15å¥—', 'CCTV15éŸ³ä¹', 'ä¸­å¤®åäº”å¥—', 'å¤®è§†åäº”å¥—'],
    'CCTV-16': ['CCTV16', 'CCTV-16', 'CCTV 16', 'å¤®è§†16å¥—', 'ä¸­å¤®16å¥—', 'CCTV16å¥¥æ—åŒ¹å…‹', 'ä¸­å¤®åå…­å¥—', 'å¤®è§†åå…­å¥—'],
    'CCTV-17': ['CCTV17', 'CCTV-17', 'CCTV 17', 'å¤®è§†17å¥—', 'ä¸­å¤®17å¥—', 'CCTV17å†œä¸šå†œæ‘', 'ä¸­å¤®åä¸ƒå¥—', 'å¤®è§†åä¸ƒå¥—'],
    
    # å«è§†é¢‘é“æ˜ å°„
    'åŒ—äº¬å«è§†': ['åŒ—äº¬å«è§†', 'åŒ—äº¬ç”µè§†å°', 'BTV', 'åŒ—äº¬å°', 'åŒ—äº¬å«è§†é«˜æ¸…', 'BTVåŒ—äº¬'],
    'æ¹–å—å«è§†': ['æ¹–å—å«è§†', 'æ¹–å—ç”µè§†å°', 'HUNAN', 'æ¹–å—å°', 'æ¹–å—å«è§†å›¾æ ‡', 'HUNAN TV'],
    'æµ™æ±Ÿå«è§†': ['æµ™æ±Ÿå«è§†', 'æµ™æ±Ÿç”µè§†å°', 'ZHEJIANG', 'æµ™æ±Ÿå°', 'ZHEJIANG TV'],
    'æ±Ÿè‹å«è§†': ['æ±Ÿè‹å«è§†', 'æ±Ÿè‹ç”µè§†å°', 'JIANGSU', 'æ±Ÿè‹å°', 'JIANGSU TV'],
    'ä¸œæ–¹å«è§†': ['ä¸œæ–¹å«è§†', 'ä¸Šæµ·ä¸œæ–¹', 'DRAGON', 'ä¸œæ–¹å°', 'ä¸Šæµ·ä¸œæ–¹å«è§†'],
    'å®‰å¾½å«è§†': ['å®‰å¾½å«è§†', 'å®‰å¾½ç”µè§†å°', 'ANHUI', 'å®‰å¾½å°', 'ANHUI TV'],
    'å¹¿ä¸œå«è§†': ['å¹¿ä¸œå«è§†', 'å¹¿ä¸œç”µè§†å°', 'GUANGDONG', 'å¹¿ä¸œå°', 'GUANGDONG TV'],
    'æ·±åœ³å«è§†': ['æ·±åœ³å«è§†', 'æ·±åœ³ç”µè§†å°', 'SHENZHEN', 'æ·±åœ³å°', 'SHENZHEN TV'],
    'å±±ä¸œå«è§†': ['å±±ä¸œå«è§†', 'å±±ä¸œç”µè§†å°', 'SHANDONG', 'å±±ä¸œå°', 'SHANDONG TV'],
    'å¤©æ´¥å«è§†': ['å¤©æ´¥å«è§†', 'å¤©æ´¥ç”µè§†å°', 'TIANJIN', 'å¤©æ´¥å°', 'TIANJIN TV'],
    'æ¹–åŒ—å«è§†': ['æ¹–åŒ—å«è§†', 'æ¹–åŒ—ç”µè§†å°', 'HUBEI', 'æ¹–åŒ—å°', 'HUBEI TV'],
    'å››å·å«è§†': ['å››å·å«è§†', 'å››å·ç”µè§†å°', 'SICHUAN', 'å››å·å°', 'SICHUAN TV'],
    'è¾½å®å«è§†': ['è¾½å®å«è§†', 'è¾½å®ç”µè§†å°', 'LIAONING', 'è¾½å®å°', 'LIAONING TV'],
    'æ²³å—å«è§†': ['æ²³å—å«è§†', 'æ²³å—ç”µè§†å°', 'HENAN', 'æ²³å—å°', 'HENAN TV'],
    'é‡åº†å«è§†': ['é‡åº†å«è§†', 'é‡åº†ç”µè§†å°', 'CHONGQING', 'é‡åº†å°', 'CHONGQING TV'],
    'é»‘é¾™æ±Ÿå«è§†': ['é»‘é¾™æ±Ÿå«è§†', 'é»‘é¾™æ±Ÿç”µè§†å°', 'HEILONGJIANG', 'é»‘é¾™æ±Ÿå°', 'HEILONGJIANG TV'],
    'æ²³åŒ—å«è§†': ['æ²³åŒ—å«è§†', 'æ²³åŒ—ç”µè§†å°', 'HEBEI', 'æ²³åŒ—å°', 'HEBEI TV'],
    'å‰æ—å«è§†': ['å‰æ—å«è§†', 'å‰æ—ç”µè§†å°', 'JILIN', 'å‰æ—å°', 'JILIN TV'],
    'é™•è¥¿å«è§†': ['é™•è¥¿å«è§†', 'é™•è¥¿ç”µè§†å°', 'SHAANXI', 'é™•è¥¿å°', 'SHAANXI TV'],
    'å±±è¥¿å«è§†': ['å±±è¥¿å«è§†', 'å±±è¥¿ç”µè§†å°', 'SHANXI', 'å±±è¥¿å°', 'SHANXI TV'],
    'ç”˜è‚ƒå«è§†': ['ç”˜è‚ƒå«è§†', 'ç”˜è‚ƒç”µè§†å°', 'GANSU', 'ç”˜è‚ƒå°', 'GANSU TV'],
    'é’æµ·å«è§†': ['é’æµ·å«è§†', 'é’æµ·ç”µè§†å°', 'QINGHAI', 'é’æµ·å°', 'QINGHAI TV'],
    'ç¦å»ºå«è§†': ['ç¦å»ºå«è§†', 'ç¦å»ºç”µè§†å°', 'FUJIAN', 'ç¦å»ºå°', 'FUJIAN TV'],
    'æ±Ÿè¥¿å«è§†': ['æ±Ÿè¥¿å«è§†', 'æ±Ÿè¥¿ç”µè§†å°', 'JIANGXI', 'æ±Ÿè¥¿å°', 'JIANGXI TV'],
    'å¹¿è¥¿å«è§†': ['å¹¿è¥¿å«è§†', 'å¹¿è¥¿ç”µè§†å°', 'GUANGXI', 'å¹¿è¥¿å°', 'GUANGXI TV'],
    'è´µå·å«è§†': ['è´µå·å«è§†', 'è´µå·ç”µè§†å°', 'GUIZHOU', 'è´µå·å°', 'GUIZHOU TV'],
    'äº‘å—å«è§†': ['äº‘å—å«è§†', 'äº‘å—ç”µè§†å°', 'YUNNAN', 'äº‘å—å°', 'YUNNAN TV'],
    'å†…è’™å¤å«è§†': ['å†…è’™å¤å«è§†', 'å†…è’™å¤ç”µè§†å°', 'NEIMENGGU', 'å†…è’™å¤å°', 'å†…è’™å¤å«è§†æ±‰è¯­'],
    'æ–°ç–†å«è§†': ['æ–°ç–†å«è§†', 'æ–°ç–†ç”µè§†å°', 'XINJIANG', 'æ–°ç–†å°', 'æ–°ç–†å«è§†æ±‰è¯­'],
    'è¥¿è—å«è§†': ['è¥¿è—å«è§†', 'è¥¿è—ç”µè§†å°', 'XIZANG', 'è¥¿è—å°', 'è¥¿è—å«è§†æ±‰è¯­'],
    'å®å¤å«è§†': ['å®å¤å«è§†', 'å®å¤ç”µè§†å°', 'NINGXIA', 'å®å¤å°', 'NINGXIA TV'],
    'æµ·å—å«è§†': ['æµ·å—å«è§†', 'æµ·å—ç”µè§†å°', 'HAINAN', 'æµ·å—å°', 'HAINAN TV'],
    
    # å…¶ä»–é¢‘é“
    'å‡¤å‡°å«è§†': ['å‡¤å‡°å«è§†', 'å‡¤å‡°ä¸­æ–‡', 'å‡¤å‡°å°', 'FENG HUANG', 'å‡¤å‡°å«è§†å›¾æ ‡', 'å‡¤å‡°å«è§†ä¸­æ–‡å°'],
    'å‡¤å‡°å«è§†é¦™æ¸¯': ['å‡¤å‡°å«è§†é¦™æ¸¯', 'å‡¤å‡°é¦™æ¸¯', 'å‡¤å‡°å«è§†é¦™æ¸¯å°'],
}

# ============================ æ­£åˆ™è¡¨è¾¾å¼ ============================
channel_pattern = re.compile(r"^([^,]+?),\s*(https?://.+)", re.IGNORECASE)
extinf_name_pattern = re.compile(r'#EXTINF:.*?,(.+)', re.IGNORECASE)

class IPTVProcessor:
    """IPTVå¤„ç†å™¨ä¸»ç±»"""
    
    def __init__(self):
        self.channel_db = {}

    def create_correct_template(self):
        """åˆ›å»ºæ­£ç¡®çš„æ¨¡æ¿æ–‡ä»¶æ ¼å¼"""
        logger.info("ğŸ“ åˆ›å»ºæ¨¡æ¿æ–‡ä»¶...")
        
        template_content = """å¤®è§†é¢‘é“,#genre#
CCTV-1
CCTV-2
CCTV-3
CCTV-4
CCTV-5
CCTV-5+
CCTV-6
CCTV-7
CCTV-8
CCTV-9
CCTV-10
CCTV-11
CCTV-12
CCTV-13
CCTV-14
CCTV-15
CCTV-16
CCTV-17
å«è§†é¢‘é“,#genre#
å®‰å¾½å«è§†
å¹¿ä¸œå«è§†
æµ™æ±Ÿå«è§†
æ¹–å—å«è§†
åŒ—äº¬å«è§†
æ¹–åŒ—å«è§†
é»‘é¾™æ±Ÿå«è§†
é‡åº†å«è§†
ä¸œæ–¹å«è§†
ä¸œå—å«è§†
ç”˜è‚ƒå«è§†
å‡¤å‡°å«è§†
å¹¿è¥¿å«è§†
è´µå·å«è§†
æµ·å—å«è§†
æ²³åŒ—å«è§†
æ²³å—å«è§†
æ±Ÿè‹å«è§†
æ±Ÿè¥¿å«è§†
å‰æ—å«è§†
è¾½å®å«è§†
å†…è’™å¤å«è§†
å®å¤å«è§†
é’æµ·å«è§†
å±±ä¸œå«è§†
å±±è¥¿å«è§†
é™•è¥¿å«è§†
å››å·å«è§†
å¤©æ´¥å«è§†
è¥¿è—å«è§†
æ–°ç–†å«è§†
äº‘å—å«è§†
å…¶ä»–é¢‘é“,#genre#
å®‰å¾½å›½é™…
å®‰å¾½å½±è§†
ç¬¬ä¸€è´¢ç»
æ¢¨å›­é¢‘é“"""
        
        try:
            with open(TEMPLATE_FILE, 'w', encoding='utf-8') as f:
                f.write(template_content)
            logger.info(f"âœ… åˆ›å»ºæ¨¡æ¿æ–‡ä»¶: {TEMPLATE_FILE}")
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def clean_channel_name(self, channel_name):
        """æ·±åº¦æ¸…ç†é¢‘é“åç§°"""
        if not channel_name:
            return ""
        
        original_name = channel_name
        
        # å»é™¤å¸¸è§çš„åç¼€å’Œè´¨é‡æ ‡è¯†
        suffixes = [
            'é«˜æ¸…', 'è¶…æ¸…', 'æ ‡æ¸…', 'HD', 'FHD', '4K', '8K', 'ç›´æ’­', 'é¢‘é“', 'å«è§†å°', 
            'ç”µè§†å°', 'å°', 'CHANNEL', 'CCTV', 'å«è§†', 'ç»¼åˆ', 'æºç ', 'ç¨³å®š',
            'æµç•…', 'ç§’å¼€', 'ç‹¬å®¶', 'ç²¾å“', 'ä¼˜è´¨', 'æ¨è', 'æœ€ä½³', 'å¤‡ç”¨', 'çº¿è·¯',
            'ã€', 'ã€‘', '(', ')', 'ï¼ˆ', 'ï¼‰', '[', ']'
        ]
        
        # å»é™¤æ‹¬å·å†…å®¹ï¼ˆåŒ…æ‹¬å„ç§æ‹¬å·ï¼‰
        cleaned_name = re.sub(r'[\(ï¼ˆ\[ã€].*?[\)ï¼‰\]ã€‘]', '', channel_name)
        
        # å»é™¤è´¨é‡æ ‡è¯†
        quality_patterns = [
            r'\d{3,4}[PpXx]',  # 1080p, 720pç­‰
            r'[Pp]é«˜æ¸…',        # Pé«˜æ¸…
            r'[Hh]265',         # H265
            r'[Hh]264',         # H264
            r'[Aa][Vv][Cc]',    # AVC
            r'[Hh][Ee][Vv][Cc]', # HEVC
        ]
        
        for pattern in quality_patterns:
            cleaned_name = re.sub(pattern, '', cleaned_name)
        
        # å»é™¤åç¼€è¯
        for suffix in suffixes:
            cleaned_name = cleaned_name.replace(suffix, '')
        
        # æ ‡å‡†åŒ–CCTVåç§°
        cctv_match = re.search(r'CCTV[\-\s]*(\d+\+?)', cleaned_name, re.IGNORECASE)
        if cctv_match:
            num = cctv_match.group(1)
            cleaned_name = f"CCTV-{num}" if '+' not in num else f"CCTV-{num}"
        
        # æ ‡å‡†åŒ–å«è§†åç§°
        if 'å«è§†' not in cleaned_name and any(prov in cleaned_name for prov in 
            ['åŒ—äº¬', 'æ¹–å—', 'æµ™æ±Ÿ', 'æ±Ÿè‹', 'ä¸œæ–¹', 'å®‰å¾½', 'å¹¿ä¸œ', 'æ·±åœ³', 'å±±ä¸œ', 
             'å¤©æ´¥', 'æ¹–åŒ—', 'å››å·', 'è¾½å®', 'æ²³å—', 'é‡åº†', 'é»‘é¾™æ±Ÿ', 'æ²³åŒ—', 'å‰æ—',
             'é™•è¥¿', 'å±±è¥¿', 'ç”˜è‚ƒ', 'é’æµ·', 'ç¦å»º', 'æ±Ÿè¥¿', 'å¹¿è¥¿', 'è´µå·', 'äº‘å—',
             'å†…è’™å¤', 'æ–°ç–†', 'è¥¿è—', 'å®å¤', 'æµ·å—']):
            cleaned_name = cleaned_name + 'å«è§†'
        
        # å»é™¤å¤šä½™ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        cleaned_name = re.sub(r'\s+', ' ', cleaned_name).strip()
        cleaned_name = re.sub(r'[ä¸¨|Â·]', '', cleaned_name).strip()
        
        # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œè¿”å›åŸå§‹åç§°
        if not cleaned_name:
            return original_name.strip()
        
        return cleaned_name

    def load_template_channels(self):
        """åŠ è½½æ¨¡æ¿é¢‘é“åˆ—è¡¨"""
        if not os.path.exists(TEMPLATE_FILE):
            logger.error(f"âŒ æ¨¡æ¿æ–‡ä»¶ {TEMPLATE_FILE} ä¸å­˜åœ¨")
            if not self.create_correct_template():
                return []
        
        template_channels = []
        
        try:
            logger.info(f"ğŸ“ åŠ è½½æ¨¡æ¿æ–‡ä»¶: {TEMPLATE_FILE}")
            with open(TEMPLATE_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        template_channels.append(line)
            
            # ç»Ÿè®¡é¢‘é“æ•°é‡ï¼ˆä»…ç”¨äºä¿¡æ¯æ˜¾ç¤ºï¼‰
            channel_count = len([line for line in template_channels if '#genre#' not in line and ',' not in line])
            logger.info(f"âœ… æ¨¡æ¿æ–‡ä»¶åŠ è½½å®Œæˆï¼Œå…± {channel_count} ä¸ªé¢‘é“")
            
            return template_channels
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return []

    def load_local_sources(self):
        """ä¼˜å…ˆåŠ è½½æœ¬åœ°æºæ–‡ä»¶"""
        local_streams = []
        if not os.path.exists(LOCAL_SOURCE_FILE):
            logger.warning(f"âš ï¸  æœ¬åœ°æºæ–‡ä»¶ {LOCAL_SOURCE_FILE} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return local_streams
        
        try:
            logger.info(f"ğŸ“ åŠ è½½æœ¬åœ°æºæ–‡ä»¶: {LOCAL_SOURCE_FILE}")
            with open(LOCAL_SOURCE_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å¤„ç†M3Uæ ¼å¼
            if content.strip().startswith('#EXTM3U'):
                lines = content.splitlines()
                current_channel = None
                for line in lines:
                    line = line.strip()
                    if line.startswith('#EXTINF'):
                        # æå–é¢‘é“åç§°
                        match = extinf_name_pattern.search(line)
                        if match:
                            current_channel = match.group(1).strip()
                    elif line and (line.startswith('http') or line.startswith('rtmp')) and current_channel:
                        local_streams.append(('local', f"{current_channel},{line}"))
                        current_channel = None
            else:
                # å¤„ç†æ™®é€šæ ¼å¼
                for line in content.splitlines():
                    line = line.strip()
                    if line and not line.startswith('#'):
                        local_streams.append(('local', line))
                        
            logger.info(f"âœ… æœ¬åœ°æºæ–‡ä»¶åŠ è½½å®Œæˆï¼Œå…± {len(local_streams)} ä¸ªæµ")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æœ¬åœ°æºæ–‡ä»¶å¤±è´¥: {e}")
        
        return local_streams

    def fetch_online_sources(self):
        """æŠ“å–åœ¨çº¿æºæ•°æ®"""
        online_streams = []
        
        def fetch_single_url(url):
            """è·å–å•ä¸ªURLçš„æºæ•°æ®"""
            try:
                logger.info(f"ğŸŒ æŠ“å–: {url}")
                response = requests.get(url, timeout=25, verify=False)
                response.encoding = 'utf-8'
                if response.status_code == 200:
                    lines = [line.strip() for line in response.text.splitlines() if line.strip()]
                    logger.info(f"âœ… æˆåŠŸæŠ“å– {url}: {len(lines)} è¡Œ")
                    return (url, lines)
                else:
                    logger.error(f"âŒ æŠ“å– {url} å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    return (url, [])
            except requests.exceptions.Timeout:
                logger.warning(f"â° æŠ“å– {url} è¶…æ—¶")
                return (url, [])
            except Exception as e:
                logger.error(f"âŒ æŠ“å– {url} å¤±è´¥: {str(e)[:100]}...")
                return (url, [])
        
        if not URL_SOURCES:
            logger.warning("âš ï¸  æ²¡æœ‰é…ç½®åœ¨çº¿æºURL")
            return online_streams
        
        logger.info("ğŸŒ æŠ“å–åœ¨çº¿æº...")
        try:
            with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(URL_SOURCES), 6)) as executor:
                future_to_url = {executor.submit(fetch_single_url, url): url for url in URL_SOURCES}
                
                for future in concurrent.futures.as_completed(future_to_url):
                    url = future_to_url[future]
                    try:
                        source_url, result = future.result()
                        online_streams.extend([(source_url, line) for line in result])
                    except Exception as e:
                        logger.error(f"âŒ å¤„ç† {url} æ—¶å‡ºé”™: {e}")
            
            logger.info(f"âœ… åœ¨çº¿æºæŠ“å–å®Œæˆï¼Œå…±è·å– {len(online_streams)} è¡Œæ•°æ®")
        except Exception as e:
            logger.error(f"âŒ æŠ“å–åœ¨çº¿æºæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        return online_streams

    def parse_stream_line(self, source, line):
        """è§£ææµæ•°æ®è¡Œï¼Œæå–é¢‘é“åç§°å’ŒURL"""
        # è·³è¿‡æ³¨é‡Šè¡Œå’Œç©ºè¡Œ
        if not line or line.startswith('#'):
            return None
        
        # å°è¯•åŒ¹é…æ ‡å‡†æ ¼å¼: é¢‘é“åç§°,URL
        match = channel_pattern.match(line)
        if match:
            channel_name = match.group(1).strip()
            url = match.group(2).strip()
            return (channel_name, url, source)
        
        # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
        if ',' in line:
            parts = line.split(',', 1)
            if len(parts) == 2 and (parts[1].startswith(('http://', 'https://', 'rtmp://'))):
                return (parts[0].strip(), parts[1].strip(), source)
        
        return None

    def build_complete_channel_database(self, local_streams, online_streams):
        """æ„å»ºå®Œæ•´çš„é¢‘é“æ•°æ®åº“"""
        logger.info("ğŸ“Š æ„å»ºé¢‘é“æ•°æ®åº“...")
        channel_db = {}
        processed_count = 0
        
        all_streams = local_streams + online_streams
        
        # ç”¨äºå»é‡çš„URLé›†åˆ
        seen_urls = set()
        
        for source, line in all_streams:
            try:
                result = self.parse_stream_line(source, line)
                if result:
                    channel_name, url, source_info = result
                    
                    # URLå»é‡
                    if url in seen_urls:
                        continue
                    seen_urls.add(url)
                    
                    # æ·±åº¦æ¸…ç†é¢‘é“åç§°ç”¨äºåŒ¹é…
                    cleaned_name = self.clean_channel_name(channel_name)
                    
                    if cleaned_name and url:
                        if cleaned_name not in channel_db:
                            channel_db[cleaned_name] = []
                        
                        channel_db[cleaned_name].append((url, source_info, {}))
                        processed_count += 1
            except Exception as e:
                logger.warning(f"è§£æè¡Œå¤±è´¥: {line[:50]}... é”™è¯¯: {e}")
        
        logger.info(f"âœ… é¢‘é“æ•°æ®åº“æ„å»ºå®Œæˆ:")
        logger.info(f"  - å¤„ç†æ•°æ®è¡Œ: {processed_count}")
        logger.info(f"  - å”¯ä¸€é¢‘é“æ•°: {len(channel_db)}")
        logger.info(f"  - æ€»æµæ•°é‡: {sum(len(urls) for urls in channel_db.values())}")
        
        return channel_db

    def comprehensive_speed_test(self, url):
        """å…¨é¢æµ‹é€ŸåŠŸèƒ½"""
        try:
            start_time = time.time()
            response = requests.head(url, timeout=REQUEST_TIMEOUT, verify=False, 
                                   headers={'User-Agent': 'Mozilla/5.0'})
            head_time = time.time()
            response_time_ms = round((head_time - start_time) * 1000)
            
            if response.status_code != 200:
                return (False, None, None, f"HTTP {response.status_code}")
            
            download_speed = None
            try:
                chunk_size = 1024 * 50
                start_download = time.time()
                download_response = requests.get(url, timeout=SPEED_TEST_TIMEOUT, 
                                               verify=False, stream=True,
                                               headers={'User-Agent': 'Mozilla/5.0'})
                
                downloaded = 0
                for chunk in download_response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        downloaded += len(chunk)
                        if downloaded >= chunk_size:
                            break
                
                end_download = time.time()
                download_time = end_download - start_download
                
                if download_time > 0.1:
                    download_speed = round((downloaded / 1024) / download_time)
                
                download_response.close()
                
            except Exception as e:
                download_speed = None
            
            return (True, response_time_ms, download_speed, None)
            
        except requests.exceptions.Timeout:
            return (False, None, None, "Timeout")
        except requests.exceptions.ConnectionError:
            return (False, None, None, "Connection Error")
        except Exception as e:
            return (False, None, None, str(e)[:50])

    def speed_test_all_channels(self, channel_db):
        """å¯¹æ‰€æœ‰é¢‘é“è¿›è¡Œæµ‹é€Ÿ"""
        logger.info("ğŸš€ å¼€å§‹å…¨é¢æµ‹é€Ÿ...")
        
        total_urls = sum(len(urls) for urls in channel_db.values())
        logger.info(f"ğŸ“Š éœ€è¦æµ‹é€Ÿçš„URLæ€»æ•°: {total_urls}")
        
        if total_urls == 0:
            logger.warning("âš ï¸  æ²¡æœ‰éœ€è¦æµ‹é€Ÿçš„URLï¼Œè·³è¿‡æµ‹é€Ÿæ­¥éª¤")
            return channel_db, {
                'total_tested': 0,
                'success_count': 0,
                'timeout_count': 0,
                'error_count': 0,
                'response_times': []
            }
        
        all_urls_to_test = []
        url_to_channel_map = {}
        
        for channel_name, urls in channel_db.items():
            for url, source, _ in urls:
                all_urls_to_test.append(url)
                url_to_channel_map[url] = channel_name
        
        speed_stats = {
            'total_tested': 0,
            'success_count': 0,
            'timeout_count': 0,
            'error_count': 0,
            'response_times': []
        }
        
        logger.info("â±ï¸  æ­£åœ¨è¿›è¡Œå…¨é¢æµ‹é€Ÿ...")
        with tqdm(total=len(all_urls_to_test), desc="å…¨é¢æµ‹é€Ÿ", unit="URL", 
                  bar_format='{l_bar}{bar:30}{r_bar}{bar:-30b}') as pbar:
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                future_to_url = {executor.submit(self.comprehensive_speed_test, url): url for url in all_urls_to_test}
                
                for future in concurrent.futures.as_completed(future_to_url):
                    url = future_to_url[future]
                    channel_name = url_to_channel_map[url]
                    
                    try:
                        is_alive, response_time, download_speed, error_msg = future.result()
                        speed_stats['total_tested'] += 1
                        
                        for i, (stream_url, source, speed_info) in enumerate(channel_db[channel_name]):
                            if stream_url == url:
                                channel_db[channel_name][i] = (
                                    stream_url, 
                                    source, 
                                    {
                                        'alive': is_alive,
                                        'response_time': response_time,
                                        'download_speed': download_speed,
                                        'error': error_msg,
                                        'score': self.calculate_stream_score(is_alive, response_time, download_speed)
                                    }
                                )
                                break
                        
                        if is_alive:
                            speed_stats['success_count'] += 1
                            if response_time:
                                speed_stats['response_times'].append(response_time)
                        else:
                            if error_msg == "Timeout":
                                speed_stats['timeout_count'] += 1
                            else:
                                speed_stats['error_count'] += 1
                        
                        pbar.set_postfix(
                            success=f"{speed_stats['success_count']}/{speed_stats['total_tested']}",
                            avg_time=f"{sum(speed_stats['response_times'])/len(speed_stats['response_times']) if speed_stats['response_times'] else 0:.0f}ms"
                        )
                        pbar.update(1)
                        
                    except Exception as e:
                        logger.warning(f"æµ‹é€Ÿå¤„ç†å¤±è´¥: {e}")
                        pbar.update(1)
        
        if speed_stats['response_times']:
            avg_response_time = sum(speed_stats['response_times']) / len(speed_stats['response_times'])
        else:
            avg_response_time = 0
        
        logger.info(f"âœ… å…¨é¢æµ‹é€Ÿå®Œæˆ:")
        logger.info(f"  - æµ‹è¯•æ€»æ•°: {speed_stats['total_tested']}")
        logger.info(f"  - æˆåŠŸ: {speed_stats['success_count']} ({speed_stats['success_count']/speed_stats['total_tested']*100:.1f}%)")
        logger.info(f"  - å¹³å‡å“åº”: {avg_response_time:.0f}ms")
        
        return channel_db, speed_stats

    def calculate_stream_score(self, is_alive, response_time, download_speed):
        """è®¡ç®—æµè´¨é‡ç»¼åˆè¯„åˆ†"""
        if not is_alive:
            return 0
        
        score = 0
        
        if response_time:
            if response_time <= 100:
                score += 60
            elif response_time <= 300:
                score += 50
            elif response_time <= 500:
                score += 40
            elif response_time <= 1000:
                score += 30
            elif response_time <= 2000:
                score += 20
            else:
                score += 10
        
        if download_speed:
            if download_speed >= 1000:
                score += 40
            elif download_speed >= 500:
                score += 30
            elif download_speed >= 200:
                score += 20
            elif download_speed >= 100:
                score += 10
            else:
                score += 5
        
        return score

    def is_channel_match(self, template_channel, db_channel):
        """ç²¾å‡†åŒ¹é…é¢‘é“åç§°ï¼Œä½¿ç”¨æ˜ å°„è§„åˆ™"""
        template_clean = self.clean_channel_name(template_channel)
        db_clean = self.clean_channel_name(db_channel)
        
        template_lower = template_clean.lower().strip()
        db_lower = db_clean.lower().strip()
        
        # å®Œå…¨åŒ¹é…
        if template_lower == db_lower:
            return True
        
        # ä½¿ç”¨æ˜ å°„è§„åˆ™åŒ¹é…
        for standard_name, variants in CHANNEL_MAPPING_RULES.items():
            standard_clean = self.clean_channel_name(standard_name).lower()
            
            # å¦‚æœæ¨¡æ¿é¢‘é“åœ¨æ ‡å‡†åç§°ä¸­
            if template_lower == standard_clean:
                # æ£€æŸ¥æ•°æ®åº“é¢‘é“æ˜¯å¦åœ¨å˜ä½“åˆ—è¡¨ä¸­
                for variant in variants:
                    if db_lower == self.clean_channel_name(variant).lower():
                        return True
            
            # å¦‚æœæ•°æ®åº“é¢‘é“æ˜¯æ ‡å‡†åç§°
            if db_lower == standard_clean:
                # æ£€æŸ¥æ¨¡æ¿é¢‘é“æ˜¯å¦åœ¨å˜ä½“åˆ—è¡¨ä¸­
                for variant in variants:
                    if template_lower == self.clean_channel_name(variant).lower():
                        return True
        
        # å¯¹äºCCTVé¢‘é“è¿›è¡Œç²¾å‡†åŒ¹é…
        if 'cctv' in template_lower and 'cctv' in db_lower:
            # æå–CCTVæ•°å­—éƒ¨åˆ†
            template_nums = re.findall(r'cctv[-\s]*(\d+\+?)', template_lower)
            db_nums = re.findall(r'cctv[-\s]*(\d+\+?)', db_lower)
            
            if template_nums and db_nums:
                # æ•°å­—éƒ¨åˆ†å®Œå…¨åŒ¹é…
                if template_nums[0] == db_nums[0]:
                    return True
            
            # å¤„ç†CCTV-5+ç­‰ç‰¹æ®Šæƒ…å†µ
            if 'cctv-5+' in template_lower and any(x in db_lower for x in ['cctv5+', 'cctv-5+', 'cctv5plus']):
                return True
            if 'cctv5+' in template_lower and any(x in db_lower for x in ['cctv5+', 'cctv-5+', 'cctv5plus']):
                return True
        
        # å¯¹äºå«è§†é¢‘é“è¿›è¡Œç²¾å‡†åŒ¹é…
        if 'å«è§†' in template_clean and 'å«è§†' in db_clean:
            template_province = template_clean.replace('å«è§†', '').strip()
            db_province = db_clean.replace('å«è§†', '').strip()
            if template_province == db_province:
                return True
            # å¤„ç†ç®€ç§°åŒ¹é…
            if template_province in db_province or db_province in template_province:
                return True
        
        # å…¶ä»–é¢‘é“çš„å®½æ¾åŒ¹é…
        template_no_space = template_lower.replace(' ', '').replace('-', '')
        db_no_space = db_lower.replace(' ', '').replace('-', '')
        
        if template_no_space in db_no_space or db_no_space in template_no_space:
            similarity = len(set(template_no_space) & set(db_no_space)) / len(set(template_no_space) | set(db_no_space))
            if similarity > 0.7:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                return True
        
        return False

    def find_matching_channels(self, template_channel, channel_db):
        """æŸ¥æ‰¾åŒ¹é…çš„é¢‘é“"""
        matched_urls = []
        
        for db_channel, urls in channel_db.items():
            if self.is_channel_match(template_channel, db_channel):
                valid_urls = [(url, source, info) for url, source, info in urls 
                            if info.get('alive', False)]
                matched_urls.extend(valid_urls)
        
        return matched_urls

    def match_template_channels(self, template_channels, channel_db):
        """åŒ¹é…æ¨¡æ¿é¢‘é“å¹¶é€‰æ‹©æœ€ä½³æµ"""
        logger.info("ğŸ¯ å¼€å§‹æ¨¡æ¿é¢‘é“åŒ¹é…...")
        
        txt_lines = []
        m3u_lines = ['#EXTM3U']
        current_group = "é»˜è®¤åˆ†ç»„"
        matched_count = 0
        total_matched_streams = 0
        
        for line in template_channels:
            if '#genre#' in line:
                group_name = line.replace(',#genre#', '').strip()
                current_group = group_name
                txt_lines.append(line)
                continue
            
            # æ¨¡æ¿è¡Œåªæœ‰é¢‘é“åç§°ï¼ˆæ²¡æœ‰URLï¼‰
            if line and not line.endswith('#genre#'):
                # ä½¿ç”¨åŸå§‹æ¨¡æ¿åç§°ï¼Œä¸è¿›è¡Œæ¸…ç†
                template_channel_original = line
                # ç”¨äºåŒ¹é…çš„æ¸…ç†ååç§°
                template_channel_for_match = self.clean_channel_name(line)
                
                logger.info(f"  ğŸ” æŸ¥æ‰¾é¢‘é“: {template_channel_original}")
                
                matched_urls = self.find_matching_channels(template_channel_for_match, channel_db)
                
                if matched_urls:
                    matched_urls.sort(key=lambda x: x[2].get('score', 0), reverse=True)
                    best_urls = matched_urls[:MAX_STREAMS_PER_CHANNEL]
                    
                    for url, source, info in best_urls:
                        # ä½¿ç”¨åŸå§‹æ¨¡æ¿åç§°è¾“å‡ºï¼Œç¡®ä¿æ˜¾ç¤ºå®Œæ•´çš„"CCTV-1"ç­‰åç§°
                        output_channel_name = template_channel_original.strip()
                        txt_lines.append(f"{output_channel_name},{url}")
                        m3u_lines.append(f'#EXTINF:-1 group-title="{current_group}",{output_channel_name}')
                        m3u_lines.append(url)
                    
                    matched_count += 1
                    total_matched_streams += len(best_urls)
                    logger.info(f"  âœ… {template_channel_original}: æ‰¾åˆ° {len(best_urls)} ä¸ªä¼˜è´¨æµ")
                else:
                    logger.warning(f"  âŒ {template_channel_original}: æœªæ‰¾åˆ°æœ‰æ•ˆæµ")
        
        try:
            with open(OUTPUT_TXT, 'w', encoding='utf-8') as f:
                f.write('\n'.join(txt_lines))
            logger.info(f"âœ… ç”ŸæˆTXTæ–‡ä»¶: {OUTPUT_TXT}")
        except Exception as e:
            logger.error(f"âŒ å†™å…¥TXTæ–‡ä»¶å¤±è´¥: {e}")
        
        try:
            with open(OUTPUT_M3U, 'w', encoding='utf-8') as f:
                f.write('\n'.join(m3u_lines))
            logger.info(f"âœ… ç”ŸæˆM3Uæ–‡ä»¶: {OUTPUT_M3U}")
        except Exception as e:
            logger.error(f"âŒ å†™å…¥M3Uæ–‡ä»¶å¤±è´¥: {e}")
        
        logger.info(f"ğŸ¯ æ¨¡æ¿åŒ¹é…å®Œæˆ: {matched_count} ä¸ªé¢‘é“åŒ¹é…æˆåŠŸï¼Œå…± {total_matched_streams} ä¸ªæµ")
        return matched_count

    def run(self):
        """è¿è¡Œä¸»æµç¨‹"""
        logger.info("ğŸ¬ IPTVé¢‘é“æ•´ç†å·¥å…·å¼€å§‹è¿è¡Œ...")
        start_time = time.time()
        
        try:
            # 1. ä¼˜å…ˆåŠ è½½æœ¬åœ°æº
            logger.info("æ­¥éª¤1: ä¼˜å…ˆåŠ è½½æœ¬åœ°æº")
            local_streams = self.load_local_sources()
            
            # 2. æŠ“å–åœ¨çº¿æº
            logger.info("æ­¥éª¤2: æŠ“å–åœ¨çº¿æº")
            online_streams = self.fetch_online_sources()
            
            # 3. åˆå¹¶æ‰€æœ‰æºæ„å»ºå®Œæ•´æ•°æ®åº“
            logger.info("æ­¥éª¤3: åˆå¹¶æ‰€æœ‰æºæ„å»ºå®Œæ•´æ•°æ®åº“")
            self.channel_db = self.build_complete_channel_database(local_streams, online_streams)
            
            if not self.channel_db:
                logger.error("âŒ æ— æ³•æ„å»ºé¢‘é“æ•°æ®åº“ï¼Œåœæ­¢æ‰§è¡Œ")
                return False
            
            # 4. å¯¹æ‰€æœ‰é¢‘é“è¿›è¡Œæµ‹é€Ÿ
            logger.info("æ­¥éª¤4: å…¨é¢æµ‹é€Ÿå’Œå»¶æ—¶æµ‹è¯•")
            self.channel_db, speed_stats = self.speed_test_all_channels(self.channel_db)
            
            # 5. åŠ è½½æ¨¡æ¿å¹¶è¿›è¡ŒåŒ¹é…
            logger.info("æ­¥éª¤5: æ¨¡æ¿é¢‘é“åŒ¹é…")
            template_channels = self.load_template_channels()
            if template_channels:
                matched_count = self.match_template_channels(template_channels, self.channel_db)
            else:
                logger.error("âŒ æ— æ³•åŠ è½½æ¨¡æ¿ï¼Œè·³è¿‡åŒ¹é…")
                return False
            
            # æœ€ç»ˆç»Ÿè®¡
            end_time = time.time()
            execution_time = round(end_time - start_time, 2)
            
            logger.info("ğŸ‰ æ‰§è¡Œå®Œæˆ!")
            logger.info(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {execution_time} ç§’")
            logger.info(f"ğŸ“º æ€»é¢‘é“æ•°: {len(self.channel_db)}")
            logger.info(f"âœ… æœ‰æ•ˆæµæ•°é‡: {speed_stats['success_count']}")
            logger.info(f"ğŸ¯ æ¨¡æ¿åŒ¹é…: {matched_count} ä¸ªé¢‘é“")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    processor = IPTVProcessor()
    success = processor.run()
    
    if success:
        logger.info("âœ… IPTVå¤„ç†å®Œæˆ!")
        sys.exit(0)
    else:
        logger.error("âŒ IPTVå¤„ç†å¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()
