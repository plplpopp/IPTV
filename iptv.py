#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
IPTVç›´æ’­æºç»ˆææ•´ç†å·¥å…·

å·¥ä½œæµç¨‹ï¼š
1. ä¼˜å…ˆåŠ è½½local.txt â†’ è¡¥å……ç½‘ç»œæº â†’ åˆå¹¶å»é‡
2. ä¸¥æ ¼æŒ‰demo.txtæ¨¡æ¿è¿‡æ»¤ï¼ˆéæ¨¡æ¿é¢‘é“å…¨éƒ¨ä¸¢å¼ƒï¼‰
3. å…¨é¢‘é“FFmpegæµ‹é€Ÿï¼ˆæ¯ä¸ªé¢‘é“ç‹¬ç«‹è¿›åº¦æ¡ï¼‰
4. æ¯ä¸ªé¢‘é“ä¿ç•™æœ€ä¼˜8ä¸ªæœ‰æ•ˆæº
5. ç”Ÿæˆå¸¦å“åº”æ—¶é—´çš„iptv.txtå’Œiptv.m3u
"""

import requests
import re
import os
import subprocess
from urllib.parse import urlparse
from collections import defaultdict
import concurrent.futures
import time
from tqdm import tqdm

# ====================== é…ç½®åŒºåŸŸ ======================
URLS = [
    "https://raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt",
    "https://raw.githubusercontent.com/wwb521/live/main/tv.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv4/result.m3u",
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u"
]

LOCAL_SOURCE = "local.txt"
BLACKLIST_FILE = "blacklist.txt"
TEMPLATE_FILE = "demo.txt"
OUTPUT_TXT = "iptv.txt"
OUTPUT_M3U = "iptv.m3u"

MAX_SOURCES = 8           # æ¯ä¸ªé¢‘é“ä¿ç•™æœ€ä¼˜æºæ•°
SPEED_TEST_TIMEOUT = 5     # æµ‹é€Ÿè¶…æ—¶(ç§’)
MAX_WORKERS = 6            # å¹¶å‘æµ‹é€Ÿçº¿ç¨‹æ•°

# ====================== æ ¸å¿ƒå¼•æ“ ======================
class IPTVProcessor:
    def __init__(self):
        self.template_channels = set()
        self.blacklist = self.load_blacklist()
        self.load_template()

    def load_blacklist(self):
        """åŠ è½½é»‘åå•åŸŸåå…³é”®è¯"""
        if os.path.exists(BLACKLIST_FILE):
            with open(BLACKLIST_FILE, 'r', encoding='utf-8') as f:
                return [line.strip().lower() for line in f if line.strip()]
        return []

    def load_template(self):
        """åŠ è½½æ¨¡æ¿å¹¶æ„å»ºé¢‘é“é›†åˆ"""
        if os.path.exists(TEMPLATE_FILE):
            with open(TEMPLATE_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.endswith(",#genre#"):
                        self.template_channels.add(self.clean_name(line))

    def clean_name(self, name):
        """æ·±åº¦æ¸…æ´—é¢‘é“åç§°"""
        name = re.sub(r'CCTV[\s\-_]?(\d+)', lambda m: f"CCTV-{m.group(1)}", name, flags=re.IGNORECASE)
        name = re.sub(r'[Â·|_ï¼ˆï¼‰ã€ã€‘]', '', name)
        return name.strip()

    def fetch_sources(self):
        """è·å–æ‰€æœ‰æºï¼ˆæœ¬åœ°ä¼˜å…ˆï¼‰"""
        sources = []
        
        # ä¼˜å…ˆåŠ è½½æœ¬åœ°æº
        if os.path.exists(LOCAL_SOURCE):
            with open(LOCAL_SOURCE, 'r', encoding='utf-8') as f:
                print(f"âœ… å·²åŠ è½½æœ¬åœ°æº: {LOCAL_SOURCE}")
                sources.append(f.read())

        # è¡¥å……ç½‘ç»œæº
        print("ğŸŒ æŠ“å–ç½‘ç»œæº...")
        with tqdm(URLS, desc="è¿›åº¦") as pbar:
            for url in pbar:
                if self.is_blocked(url):
                    pbar.write(f"ğŸš« è·³è¿‡é»‘åå•URL: {url}")
                    continue
                
                if content := self.fetch_url(url):
                    sources.append(content)
                else:
                    pbar.write(f"âš ï¸ è·å–å¤±è´¥: {url.split('/')[-1]}")
        
        return "\n".join(sources)

    def fetch_url(self, url):
        """æŠ“å–å•ä¸ªURLå†…å®¹"""
        try:
            r = requests.get(url, timeout=10)
            r.encoding = 'utf-8'
            return r.text if r.status_code == 200 else None
        except:
            return None

    def is_blocked(self, url):
        """æ£€æŸ¥URLæ˜¯å¦åœ¨é»‘åå•ä¸­"""
        domain = urlparse(url).netloc.split(':')[0].lower()
        return any(kw in domain for kw in self.blacklist)

    def parse_sources(self, content):
        """è§£ææ‰€æœ‰æºå¹¶è¿‡æ»¤éæ¨¡æ¿é¢‘é“"""
        channels = defaultdict(list)
        
        # åˆ¤æ–­å†…å®¹æ ¼å¼
        is_m3u = content.startswith("#EXTM3U")
        
        for line in content.splitlines():
            line = line.strip()
            if not line:
                continue
                
            if is_m3u and line.startswith("#EXTINF"):
                # å¤„ç†M3Uæ ¼å¼
                if match := re.search(r'tvg-name="([^"]+)"', line):
                    name = self.clean_name(match.group(1))
                    if name in self.template_channels:
                        current_name = name
            elif not is_m3u and ',' in line:
                # å¤„ç†TXTæ ¼å¼
                name, url = line.split(',', 1)
                name = self.clean_name(name.strip())
                if name in self.template_channels:
                    channels[name].append(url.strip())
            elif line.startswith("http") and current_name:
                # M3Uçš„URLè¡Œ
                channels[current_name].append(line.strip())
                current_name = None
        
        return channels

    def speed_test(self, url):
        """å¢å¼ºç‰ˆæµ‹é€Ÿå‡½æ•°"""
        try:
            start = time.time()
            cmd = [
                "ffmpeg", "-i", url,
                "-t", str(SPEED_TEST_TIMEOUT),
                "-f", "null", "-",
                "-v", "quiet", "-stats"
            ]
            subprocess.run(cmd, check=True, 
                         stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE,
                         timeout=SPEED_TEST_TIMEOUT)
            return {
                "url": url,
                "time": (time.time() - start) * 1000,
                "status": "success"
            }
        except subprocess.TimeoutExpired:
            return {"url": url, "time": SPEED_TEST_TIMEOUT*1000, "status": "timeout"}
        except:
            return {"url": url, "time": float('inf'), "status": "error"}

    def process_channels(self, channels):
        """å¤„ç†æ‰€æœ‰é¢‘é“ï¼ˆæµ‹é€Ÿ+ç­›é€‰ï¼‰"""
        result = []
        total_channels = len(channels)
        
        with tqdm(total=total_channels, desc="ğŸ”„ é¢‘é“å¤„ç†è¿›åº¦") as chan_pbar:
            for name, urls in channels.items():
                chan_pbar.set_postfix_str(f"{name[:10]}...")
                
                # æµ‹é€Ÿå½“å‰é¢‘é“çš„æ‰€æœ‰æº
                speed_results = []
                with tqdm(urls, desc=f"â±ï¸ {name[:15]}", leave=False) as url_pbar:
                    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                        futures = [executor.submit(self.speed_test, url) for url in urls]
                        for future in concurrent.futures.as_completed(futures):
                            speed_results.append(future.result())
                            url_pbar.update(1)
                
                # ç­›é€‰æœ€ä¼˜æº
                valid_sources = [s for s in speed_results if s['status'] == 'success']
                valid_sources.sort(key=lambda x: x['time'])
                best_sources = valid_sources[:MAX_SOURCES]
                
                result.append({
                    "name": name,
                    "sources": best_sources,
                    "best_time": best_sources[0]['time'] if best_sources else None
                })
                chan_pbar.update(1)
        
        return sorted(result, key=lambda x: x['best_time'] or float('inf'))

    def generate_output(self, channels):
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"""
        # åŠ è½½æ¨¡æ¿ç»“æ„
        with open(TEMPLATE_FILE, 'r', encoding='utf-8') as f:
            template = [line.strip() for line in f if line.strip()]
        
        # ç”ŸæˆTXT
        with open(OUTPUT_TXT, 'w', encoding='utf-8') as f:
            current_genre = ""
            for line in template:
                if line.endswith(",#genre#"):
                    current_genre = line.replace(",#genre#", "")
                    f.write(f"\n{current_genre},#genre#\n")
                else:
                    name = self.clean_name(line)
                    if name in (c['name'] for c in channels):
                        channel = next(c for c in channels if c['name'] == name)
                        for src in channel['sources']:
                            f.write(f"{name},{src['url']} #å“åº”:{int(src['time'])}ms\n")
        
        # ç”ŸæˆM3U
        with open(OUTPUT_M3U, 'w', encoding='utf-8') as f:
            f.write("#EXTM3U\n")
            current_genre = ""
            for line in template:
                if line.endswith(",#genre#"):
                    current_genre = line.replace(",#genre#", "")
                else:
                    name = self.clean_name(line)
                    if name in (c['name'] for c in channels):
                        channel = next(c for c in channels if c['name'] == name)
                        for src in channel['sources']:
                            f.write(f'#EXTINF:-1 tvg-name="{name}" group-title="{current_genre}",{name}\n{src["url"]}\n')

# ====================== ä¸»ç¨‹åº ======================
if __name__ == "__main__":
    print("ğŸ¬ IPTVç›´æ’­æºç»ˆææ•´ç†å·¥å…·")
    print(f"ğŸ› ï¸ é…ç½®: è¶…æ—¶{SPEED_TEST_TIMEOUT}s | ä¿ç•™{MAX_SOURCES}æº | å¹¶å‘{MAX_WORKERS}çº¿ç¨‹")
    
    processor = IPTVProcessor()
    
    print("\nğŸ” æ­£åœ¨è·å–ç›´æ’­æº...")
    content = processor.fetch_sources()
    
    print("\nğŸ§¹ æ­£åœ¨æ¸…æ´—æ•°æ®...")
    channels = processor.parse_sources(content)
    print(f"ğŸ“Š æœ‰æ•ˆé¢‘é“: {len(channels)} | å¾…æµ‹é€Ÿæº: {sum(len(u) for u in channels.values())}")
    
    print("\nâš¡ æ­£åœ¨å…¨é¢‘é“æµ‹é€Ÿ...")
    processed_channels = processor.process_channels(channels)
    
    print("\nğŸ’¾ æ­£åœ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶...")
    processor.generate_output(processed_channels)
    
    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼ç”Ÿæˆæ–‡ä»¶: {OUTPUT_TXT} å’Œ {OUTPUT_M3U}")
