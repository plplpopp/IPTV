#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
IPTVç›´æ’­æºç»ˆææ•´ç†å·¥å…·
"""

import requests
import re
import os
import subprocess
import sys
from urllib.parse import urlparse
from collections import defaultdict
import concurrent.futures
import time
from tqdm import tqdm

# ====================== é…ç½®åŒºåŸŸ ======================
URLS = [
    "https://raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt",
    "https://raw.githubusercontent.com/wwb521/live/main/tv.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv4/result.m3u",  
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
    "https://raw.githubusercontent.com/suxuang/myIPTV/main/ipv4.m3u",
    "https://raw.githubusercontent.com/vbskycn/iptv/master/tv/iptv4.txt",
    "https://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt",
    "http://47.120.41.246:8899/zb.txt",
]

LOCAL_SOURCE = "local.txt"
BLACKLIST_FILE = "blacklist.txt"
TEMPLATE_FILE = "demo.txt"
OUTPUT_TXT = "iptv.txt"
OUTPUT_M3U = "iptv.m3u"

MAX_SOURCES = 8
SPEED_TEST_TIMEOUT = 5
MAX_WORKERS = 6

# ====================== æ ¸å¿ƒå¼•æ“ ======================
class IPTVProcessor:
    def __init__(self):
        self.template_channels = set()
        self.blacklist = self.load_blacklist()
        self.load_template()
        self.success_count = 0
        self.failed_count = 0

    def load_blacklist(self):
        """åŠ è½½é»‘åå•åŸŸåå…³é”®è¯"""
        blacklist = []
        if os.path.exists(BLACKLIST_FILE):
            try:
                with open(BLACKLIST_FILE, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip().lower()
                        if line and not line.startswith('#'):
                            blacklist.append(line)
                print(f"âœ… å·²åŠ è½½é»‘åå•: {len(blacklist)}ä¸ªå…³é”®è¯")
            except Exception as e:
                print(f"âš ï¸ è¯»å–é»‘åå•å¤±è´¥: {e}")
        return blacklist

    def load_template(self):
        """åŠ è½½æ¨¡æ¿å¹¶æ„å»ºé¢‘é“é›†åˆ"""
        if not os.path.exists(TEMPLATE_FILE):
            print(f"âŒ æ¨¡æ¿æ–‡ä»¶ {TEMPLATE_FILE} ä¸å­˜åœ¨")
            return
            
        try:
            with open(TEMPLATE_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.endswith(",#genre#"):
                        cleaned_name = self.clean_name(line)
                        if cleaned_name:
                            self.template_channels.add(cleaned_name)
            print(f"âœ… å·²åŠ è½½æ¨¡æ¿: {len(self.template_channels)}ä¸ªé¢‘é“")
        except Exception as e:
            print(f"âŒ è¯»å–æ¨¡æ¿å¤±è´¥: {e}")

    def clean_name(self, name):
        """æ·±åº¦æ¸…æ´—é¢‘é“åç§°"""
        if not name:
            return ""
            
        try:
            # æ ‡å‡†åŒ–å¤®è§†åç§°
            name = re.sub(r'CCTV[\s\-_]?(\d+)', lambda m: f"CCTV-{m.group(1)}", name, flags=re.IGNORECASE)
            name = re.sub(r'å¤®è§†(\d+)', lambda m: f"CCTV-{m.group(1)}", name)
            
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
            name = re.sub(r'[Â·|_ï¼ˆï¼‰ã€ã€‘\s]+', ' ', name)
            
            return name.strip()
        except:
            return name.strip() if name else ""

    def fetch_sources(self):
        """è·å–æ‰€æœ‰æºï¼ˆæœ¬åœ°ä¼˜å…ˆï¼‰"""
        sources = []
        
        # ä¼˜å…ˆåŠ è½½æœ¬åœ°æº
        if os.path.exists(LOCAL_SOURCE):
            try:
                with open(LOCAL_SOURCE, 'r', encoding='utf-8') as f:
                    local_content = f.read()
                    sources.append(local_content)
                    print(f"âœ… å·²åŠ è½½æœ¬åœ°æº: {len(local_content.splitlines())}è¡Œ")
            except Exception as e:
                print(f"âš ï¸ è¯»å–æœ¬åœ°æºå¤±è´¥: {e}")
        else:
            print("â„¹ï¸ æœ¬åœ°æºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")

        # è¡¥å……ç½‘ç»œæº
        if URLS:
            print("ğŸŒ æŠ“å–ç½‘ç»œæº...")
            successful_urls = []
            
            with tqdm(URLS, desc="è¿›åº¦", ncols=80) as pbar:
                for url in pbar:
                    if self.is_blocked(url):
                        pbar.write(f"ğŸš« è·³è¿‡é»‘åå•URL: {url.split('/')[-1]}")
                        continue
                    
                    if content := self.fetch_url(url):
                        sources.append(content)
                        successful_urls.append(url.split('/')[-1])
                    else:
                        pbar.write(f"âš ï¸ è·å–å¤±è´¥: {url.split('/')[-1]}")
                    
                    pbar.update(1)
            
            if successful_urls:
                print(f"âœ… æˆåŠŸè·å– {len(successful_urls)} ä¸ªç½‘ç»œæº")
        
        return "\n".join(sources) if sources else ""

    def fetch_url(self, url):
        """æŠ“å–å•ä¸ªURLå†…å®¹"""
        try:
            response = requests.get(url, timeout=15, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            response.encoding = 'utf-8'
            return response.text if response.status_code == 200 else None
        except requests.exceptions.RequestException as e:
            return None
        except Exception as e:
            return None

    def is_blocked(self, url):
        """æ£€æŸ¥URLæ˜¯å¦åœ¨é»‘åå•ä¸­"""
        try:
            domain = urlparse(url).netloc.split(':')[0].lower()
            return any(kw in domain for kw in self.blacklist)
        except:
            return False

    def parse_sources(self, content):
        """ä¿®å¤ç‰ˆï¼šè§£ææ‰€æœ‰æºå¹¶è¿‡æ»¤éæ¨¡æ¿é¢‘é“"""
        if not content:
            print("âŒ å†…å®¹ä¸ºç©ºï¼Œæ— æ³•è§£æ")
            return defaultdict(list)
            
        channels = defaultdict(list)
        is_m3u = content.startswith("#EXTM3U")
        current_name = None  # ä¿®å¤ï¼šæå‰åˆå§‹åŒ–å˜é‡
        
        print(f"ğŸ” è§£æ{'M3U' if is_m3u else 'TXT'}æ ¼å¼æ•°æ®...")
        
        lines = content.splitlines()
        with tqdm(total=len(lines), desc="è§£æè¿›åº¦", ncols=80) as pbar:
            for line in lines:
                line = line.strip()
                if not line:
                    pbar.update(1)
                    continue
                    
                try:
                    if is_m3u:
                        if line.startswith("#EXTINF"):
                            # å¤„ç†M3Uæ ¼å¼çš„é¢‘é“ä¿¡æ¯è¡Œ
                            name_match = re.search(r'tvg-name="([^"]+)"', line)
                            if not name_match:
                                # å°è¯•å…¶ä»–æ ¼å¼
                                name_match = re.search(r',([^,]+)$', line)
                            
                            if name_match:
                                name = self.clean_name(name_match.group(1))
                                if name in self.template_channels:
                                    current_name = name
                                else:
                                    current_name = None
                        elif line.startswith("http"):
                            # M3Uçš„URLè¡Œ - åªæœ‰åœ¨æœ‰é¢‘é“åæ—¶æ‰å¤„ç†
                            if current_name:
                                channels[current_name].append(line)
                                current_name = None  # é‡ç½®
                    else:
                        # å¤„ç†TXTæ ¼å¼
                        if ',' in line and not line.endswith(",#genre#"):
                            parts = line.split(',', 1)
                            if len(parts) == 2:
                                name, url = parts[0].strip(), parts[1].strip()
                                if url.startswith('http'):
                                    name = self.clean_name(name)
                                    if name in self.template_channels:
                                        channels[name].append(url)
                except Exception as e:
                    # è·³è¿‡è§£æé”™è¯¯çš„è¡Œ
                    continue
                finally:
                    pbar.update(1)
        
        # ç»Ÿè®¡ç»“æœ
        total_sources = sum(len(urls) for urls in channels.values())
        print(f"âœ… è§£æå®Œæˆ: {len(channels)}ä¸ªé¢‘é“, {total_sources}ä¸ªæº")
        
        return channels

    def speed_test(self, url):
        """å¢å¼ºç‰ˆæµ‹é€Ÿå‡½æ•°"""
        try:
            start_time = time.time()
            process = subprocess.run([
                "ffmpeg", "-i", url,
                "-t", str(SPEED_TEST_TIMEOUT),
                "-f", "null", "-",
                "-v", "quiet", "-stats"
            ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=SPEED_TEST_TIMEOUT)
            
            if process.returncode == 0:
                self.success_count += 1
                return {
                    "url": url,
                    "time": (time.time() - start_time) * 1000,
                    "status": "success"
                }
            else:
                self.failed_count += 1
                return {
                    "url": url,
                    "time": SPEED_TEST_TIMEOUT * 1000,
                    "status": "failed"
                }
                
        except subprocess.TimeoutExpired:
            self.failed_count += 1
            return {
                "url": url,
                "time": SPEED_TEST_TIMEOUT * 1000,
                "status": "timeout"
            }
        except Exception as e:
            self.failed_count += 1
            return {
                "url": url,
                "time": float('inf'),
                "status": "error"
            }

    def process_channels(self, channels):
        """å¤„ç†æ‰€æœ‰é¢‘é“ï¼ˆæµ‹é€Ÿ+ç­›é€‰ï¼‰"""
        if not channels:
            print("âŒ æ²¡æœ‰å¯å¤„ç†çš„é¢‘é“æ•°æ®")
            return []
            
        result = []
        total_channels = len(channels)
        
        print(f"âš¡ å¼€å§‹æµ‹é€Ÿå¤„ç† {total_channels} ä¸ªé¢‘é“...")
        
        with tqdm(total=total_channels, desc="ğŸ”„ é¢‘é“å¤„ç†", ncols=80) as chan_pbar:
            for channel_name, urls in channels.items():
                if not urls:
                    result.append({
                        "name": channel_name,
                        "sources": [],
                        "best_time": None
                    })
                    chan_pbar.update(1)
                    continue
                    
                chan_pbar.set_postfix_str(f"{channel_name[:12]}...")
                
                # æµ‹é€Ÿå½“å‰é¢‘é“çš„æ‰€æœ‰æº
                speed_results = []
                with tqdm(urls, desc=f"â±ï¸ {channel_name[:10]}", leave=False, ncols=60) as url_pbar:
                    with concurrent.futures.ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(urls))) as executor:
                        future_to_url = {executor.submit(self.speed_test, url): url for url in urls}
                        for future in concurrent.futures.as_completed(future_to_url):
                            speed_results.append(future.result())
                            url_pbar.update(1)
                
                # ç­›é€‰æœ€ä¼˜æº
                valid_sources = [s for s in speed_results if s['status'] == 'success']
                valid_sources.sort(key=lambda x: x['time'])
                best_sources = valid_sources[:MAX_SOURCES]
                
                result.append({
                    "name": channel_name,
                    "sources": best_sources,
                    "best_time": best_sources[0]['time'] if best_sources else None
                })
                chan_pbar.update(1)
        
        # ç»Ÿè®¡æµ‹é€Ÿç»“æœ
        total_tested = self.success_count + self.failed_count
        success_rate = (self.success_count / total_tested * 100) if total_tested > 0 else 0
        print(f"ğŸ“Š æµ‹é€Ÿç»Ÿè®¡: æˆåŠŸ {self.success_count}, å¤±è´¥ {self.failed_count}, æˆåŠŸç‡ {success_rate:.1f}%")
        
        return result

    def generate_output(self, processed_channels):
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"""
        if not processed_channels:
            print("âŒ æ²¡æœ‰å¯è¾“å‡ºçš„æ•°æ®")
            return
            
        # ç»Ÿè®¡æœ‰æ•ˆé¢‘é“
        valid_channels = [c for c in processed_channels if c['sources']]
        print(f"ğŸ’¾ ç”Ÿæˆè¾“å‡ºæ–‡ä»¶: {len(valid_channels)}ä¸ªæœ‰æ•ˆé¢‘é“")
        
        try:
            # ç”ŸæˆTXTæ–‡ä»¶
            with open(OUTPUT_TXT, 'w', encoding='utf-8') as f:
                # è¯»å–æ¨¡æ¿ç»“æ„
                if os.path.exists(TEMPLATE_FILE):
                    with open(TEMPLATE_FILE, 'r', encoding='utf-8') as template_file:
                        template_lines = [line.strip() for line in template_file if line.strip()]
                
                current_genre = "æœªåˆ†ç±»"
                for line in template_lines:
                    if line.endswith(",#genre#"):
                        current_genre = line.replace(",#genre#", "")
                        f.write(f"\n{current_genre},#genre#\n")
                    else:
                        name = self.clean_name(line)
                        channel_data = next((c for c in processed_channels if c['name'] == name), None)
                        if channel_data and channel_data['sources']:
                            for source in channel_data['sources']:
                                time_info = f" #å“åº”:{int(source['time'])}ms" if source['time'] < float('inf') else ""
                                f.write(f"{name},{source['url']}{time_info}\n")
            
            # ç”ŸæˆM3Uæ–‡ä»¶
            with open(OUTPUT_M3U, 'w', encoding='utf-8') as f:
                f.write("#EXTM3U\n")
                current_genre = "æœªåˆ†ç±»"
                for line in template_lines:
                    if line.endswith(",#genre#"):
                        current_genre = line.replace(",#genre#", "")
                    else:
                        name = self.clean_name(line)
                        channel_data = next((c for c in processed_channels if c['name'] == name), None)
                        if channel_data and channel_data['sources']:
                            for source in channel_data['sources']:
                                time_info = f" #å“åº”:{int(source['time'])}ms" if source['time'] < float('inf') else ""
                                f.write(f'#EXTINF:-1 tvg-name="{name}" group-title="{current_genre}",{name}{time_info}\n{source["url"]}\n')
            
            print(f"âœ… æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {OUTPUT_TXT}, {OUTPUT_M3U}")
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")

# ====================== ä¸»ç¨‹åº ======================
def main():
    print("ğŸ¬ IPTVç›´æ’­æºç»ˆææ•´ç†å·¥å…· - ä¿®å¤ç‰ˆ")
    print(f"ğŸ› ï¸ é…ç½®: è¶…æ—¶{SPEED_TEST_TIMEOUT}s | ä¿ç•™{MAX_SOURCES}æº | å¹¶å‘{MAX_WORKERS}çº¿ç¨‹")
    
    try:
        processor = IPTVProcessor()
        
        # è·å–ç›´æ’­æº
        content = processor.fetch_sources()
        if not content:
            print("âŒ æ— æ³•è·å–ç›´æ’­æºæ•°æ®ï¼Œç¨‹åºé€€å‡º")
            return
        
        # è§£æå’Œæ¸…æ´—æ•°æ®
        channels = processor.parse_sources(content)
        if not channels:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„é¢‘é“æ•°æ®ï¼Œç¨‹åºé€€å‡º")
            return
        
        # æµ‹é€Ÿå¤„ç†
        processed_channels = processor.process_channels(channels)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        processor.generate_output(processed_channels)
        
        print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
