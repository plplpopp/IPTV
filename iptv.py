import requests
import pandas as pd
import re
import os
import time
import concurrent.futures
from urllib.parse import urlparse
from tqdm import tqdm
import sys
import json
import urllib3
from collections import defaultdict

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============================ é…ç½®æ–‡ä»¶ ============================
# æºURLåˆ—è¡¨
URL_SOURCES = [
    "https://raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt",
    "https://raw.githubusercontent.com/wwb521/live/main/tv.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv4/result.m3u",  
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
    "https://raw.githubusercontent.com/suxuang/myIPTV/main/ipv4.m3u",
    "https://raw.githubusercontent.com/vbskycn/iptv/master/tv/iptv4.txt",
    "https://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt",
    "http://47.120.41.246:8899/zb.txt",
]

# æœ¬åœ°æºæ–‡ä»¶
LOCAL_SOURCE_FILE = "local.txt"

# æ¨¡æ¿é¢‘é“æ–‡ä»¶
TEMPLATE_FILE = "demo.txt"

# è¾“å‡ºæ–‡ä»¶
OUTPUT_TXT = "iptv.txt"
OUTPUT_M3U = "iptv.m3u"

# æ¯ä¸ªé¢‘é“ä¿ç•™çš„æ¥å£æ•°é‡
MAX_STREAMS_PER_CHANNEL = 5

# è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
REQUEST_TIMEOUT = 8

# æµ‹é€Ÿè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
SPEED_TEST_TIMEOUT = 12

# æœ€å¤§çº¿ç¨‹æ•°
MAX_WORKERS = 15

# ============================ é¢‘é“åç§°æ˜ å°„å’Œè§„åˆ™ ============================
CHANNEL_MAPPING_RULES = {
    # CCTVé¢‘é“æ˜ å°„
    'CCTV-1': ['CCTV1', 'CCTV-1', 'CCTV 1', 'å¤®è§†1å¥—', 'ä¸­å¤®1å¥—', 'CCTV1ç»¼åˆ'],
    'CCTV-2': ['CCTV2', 'CCTV-2', 'CCTV 2', 'å¤®è§†2å¥—', 'ä¸­å¤®2å¥—', 'CCTV2è´¢ç»'],
    'CCTV-3': ['CCTV3', 'CCTV-3', 'CCTV 3', 'å¤®è§†3å¥—', 'ä¸­å¤®3å¥—', 'CCTV3ç»¼è‰º'],
    'CCTV-4': ['CCTV4', 'CCTV-4', 'CCTV 4', 'å¤®è§†4å¥—', 'ä¸­å¤®4å¥—', 'CCTV4ä¸­æ–‡å›½é™…'],
    'CCTV-5': ['CCTV5', 'CCTV-5', 'CCTV 5', 'å¤®è§†5å¥—', 'ä¸­å¤®5å¥—', 'CCTV5ä½“è‚²'],
    'CCTV-5+': ['CCTV5+', 'CCTV5plus', 'CCTV-5+', 'CCTV5 Plus', 'å¤®è§†5+'],
    'CCTV-6': ['CCTV6', 'CCTV-6', 'CCTV 6', 'å¤®è§†6å¥—', 'ä¸­å¤®6å¥—', 'CCTV6ç”µå½±'],
    'CCTV-7': ['CCTV7', 'CCTV-7', 'CCTV 7', 'å¤®è§†7å¥—', 'ä¸­å¤®7å¥—', 'CCTV7å›½é˜²å†›äº‹'],
    'CCTV-8': ['CCTV8', 'CCTV-8', 'CCTV 8', 'å¤®è§†8å¥—', 'ä¸­å¤®8å¥—', 'CCTV8ç”µè§†å‰§'],
    'CCTV-9': ['CCTV9', 'CCTV-9', 'CCTV 9', 'å¤®è§†9å¥—', 'ä¸­å¤®9å¥—', 'CCTV9çºªå½•'],
    'CCTV-10': ['CCTV10', 'CCTV-10', 'CCTV 10', 'å¤®è§†10å¥—', 'ä¸­å¤®10å¥—', 'CCTV10ç§‘æ•™'],
    'CCTV-11': ['CCTV11', 'CCTV-11', 'CCTV 11', 'å¤®è§†11å¥—', 'ä¸­å¤®11å¥—', 'CCTV11æˆæ›²'],
    'CCTV-12': ['CCTV12', 'CCTV-12', 'CCTV 12', 'å¤®è§†12å¥—', 'ä¸­å¤®12å¥—', 'CCTV12ç¤¾ä¼šä¸æ³•'],
    'CCTV-13': ['CCTV13', 'CCTV-13', 'CCTV 13', 'å¤®è§†13å¥—', 'ä¸­å¤®13å¥—', 'CCTV13æ–°é—»'],
    'CCTV-14': ['CCTV14', 'CCTV-14', 'CCTV 14', 'å¤®è§†14å¥—', 'ä¸­å¤®14å¥—', 'CCTV14å°‘å„¿'],
    'CCTV-15': ['CCTV15', 'CCTV-15', 'CCTV 15', 'å¤®è§†15å¥—', 'ä¸­å¤®15å¥—', 'CCTV15éŸ³ä¹'],
    'CCTV-16': ['CCTV16', 'CCTV-16', 'CCTV 16', 'å¤®è§†16å¥—', 'ä¸­å¤®16å¥—', 'CCTV16å¥¥æ—åŒ¹å…‹'],
    'CCTV-17': ['CCTV17', 'CCTV-17', 'CCTV 17', 'å¤®è§†17å¥—', 'ä¸­å¤®17å¥—', 'CCTV17å†œä¸šå†œæ‘'],
    
    # å«è§†é¢‘é“æ˜ å°„
    'åŒ—äº¬å«è§†': ['åŒ—äº¬å«è§†', 'åŒ—äº¬ç”µè§†å°', 'BTV', 'åŒ—äº¬å°'],
    'æ¹–å—å«è§†': ['æ¹–å—å«è§†', 'æ¹–å—ç”µè§†å°', 'HUNAN'],
    'æµ™æ±Ÿå«è§†': ['æµ™æ±Ÿå«è§†', 'æµ™æ±Ÿç”µè§†å°', 'ZHEJIANG'],
    'æ±Ÿè‹å«è§†': ['æ±Ÿè‹å«è§†', 'æ±Ÿè‹ç”µè§†å°', 'JIANGSU'],
    'ä¸œæ–¹å«è§†': ['ä¸œæ–¹å«è§†', 'ä¸Šæµ·ä¸œæ–¹', 'DRAGON'],
    'å®‰å¾½å«è§†': ['å®‰å¾½å«è§†', 'å®‰å¾½ç”µè§†å°', 'ANHUI'],
    'å¹¿ä¸œå«è§†': ['å¹¿ä¸œå«è§†', 'å¹¿ä¸œç”µè§†å°', 'GUANGDONG'],
    'æ·±åœ³å«è§†': ['æ·±åœ³å«è§†', 'æ·±åœ³ç”µè§†å°', 'SHENZHEN'],
    'å±±ä¸œå«è§†': ['å±±ä¸œå«è§†', 'å±±ä¸œç”µè§†å°', 'SHANDONG'],
    'å¤©æ´¥å«è§†': ['å¤©æ´¥å«è§†', 'å¤©æ´¥ç”µè§†å°', 'TIANJIN'],
    'æ¹–åŒ—å«è§†': ['æ¹–åŒ—å«è§†', 'æ¹–åŒ—ç”µè§†å°', 'HUBEI'],
    'å››å·å«è§†': ['å››å·å«è§†', 'å››å·ç”µè§†å°', 'SICHUAN'],
    'è¾½å®å«è§†': ['è¾½å®å«è§†', 'è¾½å®ç”µè§†å°', 'LIAONING'],
    'æ²³å—å«è§†': ['æ²³å—å«è§†', 'æ²³å—ç”µè§†å°', 'HENAN'],
    'é‡åº†å«è§†': ['é‡åº†å«è§†', 'é‡åº†ç”µè§†å°', 'CHONGQING'],
    'é»‘é¾™æ±Ÿå«è§†': ['é»‘é¾™æ±Ÿå«è§†', 'é»‘é¾™æ±Ÿç”µè§†å°', 'HEILONGJIANG'],
    'æ²³åŒ—å«è§†': ['æ²³åŒ—å«è§†', 'æ²³åŒ—ç”µè§†å°', 'HEBEI'],
    'å‰æ—å«è§†': ['å‰æ—å«è§†', 'å‰æ—ç”µè§†å°', 'JILIN'],
    'é™•è¥¿å«è§†': ['é™•è¥¿å«è§†', 'é™•è¥¿ç”µè§†å°', 'SHAANXI'],
    'å±±è¥¿å«è§†': ['å±±è¥¿å«è§†', 'å±±è¥¿ç”µè§†å°', 'SHANXI'],
    'ç”˜è‚ƒå«è§†': ['ç”˜è‚ƒå«è§†', 'ç”˜è‚ƒç”µè§†å°', 'GANSU'],
    'é’æµ·å«è§†': ['é’æµ·å«è§†', 'é’æµ·ç”µè§†å°', 'QINGHAI'],
    'ç¦å»ºå«è§†': ['ç¦å»ºå«è§†', 'ç¦å»ºç”µè§†å°', 'FUJIAN'],
    'æ±Ÿè¥¿å«è§†': ['æ±Ÿè¥¿å«è§†', 'æ±Ÿè¥¿ç”µè§†å°', 'JIANGXI'],
    'å¹¿è¥¿å«è§†': ['å¹¿è¥¿å«è§†', 'å¹¿è¥¿ç”µè§†å°', 'GUANGXI'],
    'è´µå·å«è§†': ['è´µå·å«è§†', 'è´µå·ç”µè§†å°', 'GUIZHOU'],
    'äº‘å—å«è§†': ['äº‘å—å«è§†', 'äº‘å—ç”µè§†å°', 'YUNNAN'],
    'å†…è’™å¤å«è§†': ['å†…è’™å¤å«è§†', 'å†…è’™å¤ç”µè§†å°', 'NEIMENGGU'],
    'æ–°ç–†å«è§†': ['æ–°ç–†å«è§†', 'æ–°ç–†ç”µè§†å°', 'XINJIANG'],
    'è¥¿è—å«è§†': ['è¥¿è—å«è§†', 'è¥¿è—ç”µè§†å°', 'XIZANG'],
    'å®å¤å«è§†': ['å®å¤å«è§†', 'å®å¤ç”µè§†å°', 'NINGXIA'],
    'æµ·å—å«è§†': ['æµ·å—å«è§†', 'æµ·å—ç”µè§†å°', 'HAINAN'],
    
    # å…¶ä»–é¢‘é“
    'å‡¤å‡°å«è§†': ['å‡¤å‡°å«è§†', 'å‡¤å‡°ä¸­æ–‡', 'å‡¤å‡°å°', 'FENG HUANG'],
    'å‡¤å‡°å«è§†é¦™æ¸¯': ['å‡¤å‡°å«è§†é¦™æ¸¯', 'å‡¤å‡°é¦™æ¸¯'],
}

# ============================ æ­£åˆ™è¡¨è¾¾å¼ ============================
# IPv4åœ°å€åŒ¹é…
ipv4_pattern = re.compile(r'^https?://(\d{1,3}\.){3}\d{1,3}')

# é¢‘é“åç§°å’ŒURLåŒ¹é…
channel_pattern = re.compile(r"^([^,]+?),\s*(https?://.+)", re.IGNORECASE)

# M3Uæ ¼å¼è§£æ
extinf_pattern = re.compile(r'tvg-name="([^"]*)"', re.IGNORECASE)
extinf_name_pattern = re.compile(r'#EXTINF:.*?,(.+)', re.IGNORECASE)

def create_correct_template():
    """åˆ›å»ºæ­£ç¡®çš„æ¨¡æ¿æ–‡ä»¶æ ¼å¼ï¼ˆåªæœ‰é¢‘é“åç§°ï¼‰"""
    print("ğŸ“ åˆ›å»ºæ­£ç¡®çš„æ¨¡æ¿æ–‡ä»¶æ ¼å¼...")
    
    template_content = """å¤®è§†é¢‘é“,#genre#
CCTV-1
CCTV-2
CCTV-3
CCTV-4
CCTV-5
CCTV-5+
CCTV-6
CCTV-7
CCTV-8
CCTV-9
CCTV-10
CCTV-11
CCTV-12
CCTV-13
CCTV-14
CCTV-15
CCTV-16
CCTV-17
å«è§†é¢‘é“,#genre#
å®‰å¾½å«è§†
å¹¿ä¸œå«è§†
æµ™æ±Ÿå«è§†
æ¹–å—å«è§†
åŒ—äº¬å«è§†
æ¹–åŒ—å«è§†
é»‘é¾™æ±Ÿå«è§†
é‡åº†å«è§†
ä¸œæ–¹å«è§†
ä¸œå—å«è§†
ç”˜è‚ƒå«è§†
å‡¤å‡°å«è§†
å¹¿è¥¿å«è§†
è´µå·å«è§†
æµ·å—å«è§†
æ²³åŒ—å«è§†
æ²³å—å«è§†
æ±Ÿè‹å«è§†
æ±Ÿè¥¿å«è§†
å‰æ—å«è§†
è¾½å®å«è§†
å†…è’™å¤å«è§†
å®å¤å«è§†
é’æµ·å«è§†
å±±ä¸œå«è§†
å±±è¥¿å«è§†
é™•è¥¿å«è§†
å››å·å«è§†
å¤©æ´¥å«è§†
è¥¿è—å«è§†
æ–°ç–†å«è§†
äº‘å—å«è§†
å…¶ä»–é¢‘é“,#genre#
å®‰å¾½å›½é™…
å®‰å¾½å½±è§†
ç¬¬ä¸€è´¢ç»
æ¢¨å›­é¢‘é“"""
    
    try:
        with open(TEMPLATE_FILE, 'w', encoding='utf-8') as f:
            f.write(template_content)
        print(f"âœ… åˆ›å»ºæ¨¡æ¿æ–‡ä»¶: {TEMPLATE_FILE}")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
        return False

def clean_channel_name(channel_name):
    """
    æ·±åº¦æ¸…ç†é¢‘é“åç§°ï¼Œå»é™¤ä¸éœ€è¦çš„åç¼€å’Œä¿®é¥°è¯
    """
    if not channel_name:
        return ""
    
    # å»é™¤å¸¸è§çš„åç¼€å’Œè´¨é‡æ ‡è¯†
    suffixes = [
        'é«˜æ¸…', 'è¶…æ¸…', 'æ ‡æ¸…', 'HD', 'FHD', '4K', '8K', 'ç›´æ’­', 'é¢‘é“', 'å«è§†å°', 
        'ç”µè§†å°', 'å°', 'é¢‘é“', 'CHANNEL', 'CCTV', 'å«è§†', 'ç»¼åˆ', 'æºç ', 'ç¨³å®š',
        'æµç•…', 'ç§’å¼€', 'ç‹¬å®¶', 'ç²¾å“', 'ä¼˜è´¨', 'æ¨è', 'æœ€ä½³', 'å¤‡ç”¨', 'çº¿è·¯'
    ]
    
    # å»é™¤æ‹¬å·å†…å®¹ï¼ˆåŒ…æ‹¬å„ç§æ‹¬å·ï¼‰
    cleaned_name = re.sub(r'[\(ï¼ˆ\[ã€].*?[\)ï¼‰\]ã€‘]', '', channel_name)
    
    # å»é™¤è´¨é‡æ ‡è¯†
    quality_patterns = [
        r'\d{3,4}[PpXx]',  # 1080p, 720pç­‰
        r'[Pp]é«˜æ¸…',        # Pé«˜æ¸…
        r'[Hh]265',         # H265
        r'[Hh]264',         # H264
        r'[Aa][Vv][Cc]',    # AVC
        r'[Hh][Ee][Vv][Cc]', # HEVC
    ]
    
    for pattern in quality_patterns:
        cleaned_name = re.sub(pattern, '', cleaned_name)
    
    # å»é™¤åç¼€è¯
    for suffix in suffixes:
        cleaned_name = cleaned_name.replace(suffix, '')
    
    # æ ‡å‡†åŒ–CCTVåç§°
    cctv_match = re.search(r'CCTV[\-\s]*(\d+\+?)', cleaned_name, re.IGNORECASE)
    if cctv_match:
        num = cctv_match.group(1)
        cleaned_name = f"CCTV-{num}" if '+' not in num else f"CCTV-{num}"
    
    # æ ‡å‡†åŒ–å«è§†åç§°
    if 'å«è§†' not in cleaned_name and any(prov in cleaned_name for prov in ['åŒ—äº¬', 'æ¹–å—', 'æµ™æ±Ÿ', 'æ±Ÿè‹', 'ä¸œæ–¹', 'å®‰å¾½', 'å¹¿ä¸œ']):
        cleaned_name = cleaned_name + 'å«è§†'
    
    # å»é™¤å¤šä½™ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
    cleaned_name = re.sub(r'\s+', ' ', cleaned_name).strip()
    cleaned_name = re.sub(r'[ä¸¨|]', '', cleaned_name).strip()
    
    return cleaned_name

def format_channel_name_for_output(template_channel):
    """
    æ ¼å¼åŒ–è¾“å‡ºç”¨çš„é¢‘é“åç§°ï¼Œç¡®ä¿æ˜¾ç¤ºå®Œæ•´çš„æ ‡å‡†åç§°
    """
    return template_channel.strip()

def load_template_channels():
    """åŠ è½½æ¨¡æ¿é¢‘é“åˆ—è¡¨ï¼ˆåªæœ‰é¢‘é“åç§°ï¼‰"""
    if not os.path.exists(TEMPLATE_FILE):
        print(f"âŒ æ¨¡æ¿æ–‡ä»¶ {TEMPLATE_FILE} ä¸å­˜åœ¨")
        if not create_correct_template():
            return []
    
    template_channels = []
    template_channel_names = []  # åªå­˜å‚¨é¢‘é“åç§°
    
    try:
        print(f"ğŸ“ æ­£åœ¨åŠ è½½æ¨¡æ¿æ–‡ä»¶: {TEMPLATE_FILE}")
        with open(TEMPLATE_FILE, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line:
                    template_channels.append(line)
                    
                    # åªæå–é¢‘é“åç§°ï¼ˆéåˆ†ç»„è¡Œï¼‰
                    if '#genre#' not in line and ',' not in line:
                        template_channel_names.append(line)
        
        # ç»Ÿè®¡ä¿¡æ¯
        genre_lines = [line for line in template_channels if '#genre#' in line]
        
        print(f"âœ… æ¨¡æ¿æ–‡ä»¶åŠ è½½å®Œæˆ:")
        print(f"  - æ€»è¡Œæ•°: {len(template_channels)}")
        print(f"  - åˆ†ç»„æ•°: {len(genre_lines)}")
        print(f"  - é¢‘é“æ•°: {len(template_channel_names)}")
        
        if not template_channel_names:
            print("âŒ æ¨¡æ¿ä¸­æ²¡æœ‰æœ‰æ•ˆçš„é¢‘é“åç§°")
            return []
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªé¢‘é“åç§°ä½œä¸ºç¤ºä¾‹
        print("é¢‘é“åç§°ç¤ºä¾‹:")
        for i, channel in enumerate(template_channel_names[:8], 1):
            print(f"  {i}. {channel}")
        
        return template_channels
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
        return []

def load_local_sources():
    """ä¼˜å…ˆåŠ è½½æœ¬åœ°æºæ–‡ä»¶"""
    local_streams = []
    if not os.path.exists(LOCAL_SOURCE_FILE):
        print(f"âš ï¸  æœ¬åœ°æºæ–‡ä»¶ {LOCAL_SOURCE_FILE} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return local_streams
    
    try:
        print(f"ğŸ“ æ­£åœ¨ä¼˜å…ˆåŠ è½½æœ¬åœ°æºæ–‡ä»¶: {LOCAL_SOURCE_FILE}")
        with open(LOCAL_SOURCE_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å¤„ç†M3Uæ ¼å¼
        if content.strip().startswith('#EXTM3U'):
            lines = content.splitlines()
            current_channel = None
            for line in lines:
                line = line.strip()
                if line.startswith('#EXTINF'):
                    # æå–é¢‘é“åç§°
                    match = extinf_name_pattern.search(line)
                    if match:
                        current_channel = match.group(1).strip()
                elif line.startswith('http') and current_channel:
                    local_streams.append(('local', f"{current_channel},{line}"))
                    current_channel = None
        else:
            # å¤„ç†æ™®é€šæ ¼å¼
            for line_num, line in enumerate(content.splitlines(), 1):
                line = line.strip()
                if line and not line.startswith('#'):
                    local_streams.append(('local', line))
                    
        print(f"âœ… æœ¬åœ°æºæ–‡ä»¶åŠ è½½å®Œæˆï¼Œå…± {len(local_streams)} ä¸ªæµ")
    except Exception as e:
        print(f"âŒ åŠ è½½æœ¬åœ°æºæ–‡ä»¶å¤±è´¥: {e}")
    
    return local_streams

def fetch_online_sources():
    """æŠ“å–åœ¨çº¿æºæ•°æ®"""
    online_streams = []
    
    def fetch_single_url(url):
        """è·å–å•ä¸ªURLçš„æºæ•°æ®"""
        try:
            print(f"ğŸŒ æ­£åœ¨æŠ“å–: {url}")
            response = requests.get(url, timeout=25, verify=False)
            response.encoding = 'utf-8'
            if response.status_code == 200:
                lines = [line.strip() for line in response.text.splitlines() if line.strip()]
                print(f"âœ… æˆåŠŸæŠ“å– {url}: {len(lines)} è¡Œ")
                return (url, lines)
            else:
                print(f"âŒ æŠ“å– {url} å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return (url, [])
        except requests.exceptions.Timeout:
            print(f"â° æŠ“å– {url} è¶…æ—¶")
            return (url, [])
        except Exception as e:
            print(f"âŒ æŠ“å– {url} å¤±è´¥: {str(e)[:100]}...")
            return (url, [])
    
    if not URL_SOURCES:
        print("âš ï¸  æ²¡æœ‰é…ç½®åœ¨çº¿æºURL")
        return online_streams
    
    print("ğŸŒ æ­£åœ¨æŠ“å–åœ¨çº¿æº...")
    try:
        with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(URL_SOURCES), 6)) as executor:
            future_to_url = {executor.submit(fetch_single_url, url): url for url in URL_SOURCES}
            
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    source_url, result = future.result()
                    online_streams.extend([(source_url, line) for line in result])
                except Exception as e:
                    print(f"âŒ å¤„ç† {url} æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… åœ¨çº¿æºæŠ“å–å®Œæˆï¼Œå…±è·å– {len(online_streams)} è¡Œæ•°æ®")
    except Exception as e:
        print(f"âŒ æŠ“å–åœ¨çº¿æºæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    return online_streams

def parse_stream_line(source, line):
    """è§£ææµæ•°æ®è¡Œï¼Œæå–é¢‘é“åç§°å’ŒURL"""
    # è·³è¿‡æ³¨é‡Šè¡Œå’Œç©ºè¡Œ
    if not line or line.startswith('#'):
        return None
    
    # å°è¯•åŒ¹é…æ ‡å‡†æ ¼å¼: é¢‘é“åç§°,URL
    match = channel_pattern.match(line)
    if match:
        channel_name = match.group(1).strip()
        url = match.group(2).strip()
        return (channel_name, url, source)
    
    # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
    if ',' in line:
        parts = line.split(',', 1)
        if len(parts) == 2 and parts[1].startswith(('http://', 'https://')):
            return (parts[0].strip(), parts[1].strip(), source)
    
    return None

def build_complete_channel_database(local_streams, online_streams):
    """æ„å»ºå®Œæ•´çš„é¢‘é“æ•°æ®åº“"""
    print("ğŸ“Š æ­£åœ¨æ„å»ºå®Œæ•´é¢‘é“æ•°æ®åº“...")
    channel_db = {}
    processed_count = 0
    duplicate_count = 0
    
    all_streams = local_streams + online_streams
    
    # ç”¨äºå»é‡çš„URLé›†åˆ
    seen_urls = set()
    
    for source, line in all_streams:
        result = parse_stream_line(source, line)
        if result:
            channel_name, url, source_info = result
            
            # URLå»é‡
            if url in seen_urls:
                duplicate_count += 1
                continue
            seen_urls.add(url)
            
            # æ·±åº¦æ¸…ç†é¢‘é“åç§°ç”¨äºåŒ¹é…
            cleaned_name = clean_channel_name(channel_name)
            
            if cleaned_name and url:
                if cleaned_name not in channel_db:
                    channel_db[cleaned_name] = []
                
                channel_db[cleaned_name].append((url, source_info, {}))
                processed_count += 1
    
    print(f"âœ… å®Œæ•´é¢‘é“æ•°æ®åº“æ„å»ºå®Œæˆ:")
    print(f"  - å¤„ç†æ•°æ®è¡Œ: {processed_count}")
    print(f"  - å»é‡URLæ•°: {duplicate_count}")
    print(f"  - å”¯ä¸€é¢‘é“æ•°: {len(channel_db)}")
    print(f"  - æ€»æµæ•°é‡: {sum(len(urls) for urls in channel_db.values())}")
    
    # æ˜¾ç¤ºé¢‘é“ç»Ÿè®¡
    print("\nğŸ“ˆ é¢‘é“æ•°é‡ç»Ÿè®¡:")
    channel_counts = {}
    for channel_name, urls in channel_db.items():
        count = len(urls)
        if count not in channel_counts:
            channel_counts[count] = []
        channel_counts[count].append(channel_name)
    
    for count in sorted(channel_counts.keys(), reverse=True)[:10]:
        channels = channel_counts[count]
        print(f"  - {count}ä¸ªæµ: {len(channels)}ä¸ªé¢‘é“")
        if count >= 3:
            print(f"    ç¤ºä¾‹: {', '.join(channels[:2])}")
    
    return channel_db

def comprehensive_speed_test(url):
    """å…¨é¢æµ‹é€ŸåŠŸèƒ½"""
    try:
        start_time = time.time()
        response = requests.head(url, timeout=REQUEST_TIMEOUT, verify=False, 
                               headers={'User-Agent': 'Mozilla/5.0'})
        head_time = time.time()
        response_time_ms = round((head_time - start_time) * 1000)
        
        if response.status_code != 200:
            return (False, None, None, f"HTTP {response.status_code}")
        
        download_speed = None
        try:
            chunk_size = 1024 * 50
            start_download = time.time()
            download_response = requests.get(url, timeout=SPEED_TEST_TIMEOUT, 
                                           verify=False, stream=True,
                                           headers={'User-Agent': 'Mozilla/5.0'})
            
            downloaded = 0
            for chunk in download_response.iter_content(chunk_size=chunk_size):
                if chunk:
                    downloaded += len(chunk)
                    if downloaded >= chunk_size:
                        break
            
            end_download = time.time()
            download_time = end_download - start_download
            
            if download_time > 0.1:
                download_speed = round((downloaded / 1024) / download_time)
            
            download_response.close()
            
        except Exception as e:
            download_speed = None
        
        return (True, response_time_ms, download_speed, None)
        
    except requests.exceptions.Timeout:
        return (False, None, None, "Timeout")
    except requests.exceptions.ConnectionError:
        return (False, None, None, "Connection Error")
    except Exception as e:
        return (False, None, None, str(e)[:50])

def speed_test_all_channels(channel_db):
    """å¯¹æ‰€æœ‰é¢‘é“è¿›è¡Œæµ‹é€Ÿ"""
    print("\nğŸš€ å¼€å§‹å…¨é¢æµ‹é€Ÿ...")
    
    total_urls = sum(len(urls) for urls in channel_db.values())
    print(f"ğŸ“Š éœ€è¦æµ‹é€Ÿçš„URLæ€»æ•°: {total_urls}")
    
    if total_urls == 0:
        print("âš ï¸  æ²¡æœ‰éœ€è¦æµ‹é€Ÿçš„URLï¼Œè·³è¿‡æµ‹é€Ÿæ­¥éª¤")
        return channel_db, {
            'total_tested': 0,
            'success_count': 0,
            'timeout_count': 0,
            'error_count': 0,
            'response_times': []
        }
    
    all_urls_to_test = []
    url_to_channel_map = {}
    
    for channel_name, urls in channel_db.items():
        for url, source, _ in urls:
            all_urls_to_test.append(url)
            url_to_channel_map[url] = channel_name
    
    speed_stats = {
        'total_tested': 0,
        'success_count': 0,
        'timeout_count': 0,
        'error_count': 0,
        'response_times': []
    }
    
    print("â±ï¸  æ­£åœ¨è¿›è¡Œå…¨é¢æµ‹é€Ÿ...")
    with tqdm(total=len(all_urls_to_test), desc="å…¨é¢æµ‹é€Ÿ", unit="URL", 
              bar_format='{l_bar}{bar:30}{r_bar}{bar:-30b}') as pbar:
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_url = {executor.submit(comprehensive_speed_test, url): url for url in all_urls_to_test}
            
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                channel_name = url_to_channel_map[url]
                
                try:
                    is_alive, response_time, download_speed, error_msg = future.result()
                    speed_stats['total_tested'] += 1
                    
                    for i, (stream_url, source, speed_info) in enumerate(channel_db[channel_name]):
                        if stream_url == url:
                            channel_db[channel_name][i] = (
                                stream_url, 
                                source, 
                                {
                                    'alive': is_alive,
                                    'response_time': response_time,
                                    'download_speed': download_speed,
                                    'error': error_msg,
                                    'score': calculate_stream_score(is_alive, response_time, download_speed)
                                }
                            )
                            break
                    
                    if is_alive:
                        speed_stats['success_count'] += 1
                        if response_time:
                            speed_stats['response_times'].append(response_time)
                    else:
                        if error_msg == "Timeout":
                            speed_stats['timeout_count'] += 1
                        else:
                            speed_stats['error_count'] += 1
                    
                    pbar.set_postfix(
                        success=f"{speed_stats['success_count']}/{speed_stats['total_tested']}",
                        avg_time=f"{sum(speed_stats['response_times'])/len(speed_stats['response_times']) if speed_stats['response_times'] else 0:.0f}ms"
                    )
                    pbar.update(1)
                    
                except Exception as e:
                    pbar.update(1)
    
    if speed_stats['response_times']:
        avg_response_time = sum(speed_stats['response_times']) / len(speed_stats['response_times'])
        min_response_time = min(speed_stats['response_times'])
        max_response_time = max(speed_stats['response_times'])
    else:
        avg_response_time = min_response_time = max_response_time = 0
    
    print(f"\nâœ… å…¨é¢æµ‹é€Ÿå®Œæˆ:")
    print(f"  - æµ‹è¯•æ€»æ•°: {speed_stats['total_tested']}")
    print(f"  - æˆåŠŸ: {speed_stats['success_count']} ({speed_stats['success_count']/speed_stats['total_tested']*100:.1f}%)")
    print(f"  - è¶…æ—¶: {speed_stats['timeout_count']}")
    print(f"  - é”™è¯¯: {speed_stats['error_count']}")
    if speed_stats['response_times']:
        print(f"  - å¹³å‡å“åº”: {avg_response_time:.0f}ms")
        print(f"  - æœ€å¿«å“åº”: {min_response_time}ms")
        print(f"  - æœ€æ…¢å“åº”: {max_response_time}ms")
    
    return channel_db, speed_stats

def calculate_stream_score(is_alive, response_time, download_speed):
    """è®¡ç®—æµè´¨é‡ç»¼åˆè¯„åˆ†"""
    if not is_alive:
        return 0
    
    score = 0
    
    if response_time:
        if response_time <= 100:
            score += 60
        elif response_time <= 300:
            score += 50
        elif response_time <= 500:
            score += 40
        elif response_time <= 1000:
            score += 30
        elif response_time <= 2000:
            score += 20
        else:
            score += 10
    
    if download_speed:
        if download_speed >= 1000:
            score += 40
        elif download_speed >= 500:
            score += 30
        elif download_speed >= 200:
            score += 20
        elif download_speed >= 100:
            score += 10
        else:
            score += 5
    
    return score

def is_channel_match(template_channel, db_channel):
    """
    ç²¾å‡†åŒ¹é…é¢‘é“åç§°ï¼Œä½¿ç”¨æ˜ å°„è§„åˆ™
    """
    template_clean = clean_channel_name(template_channel)
    db_clean = clean_channel_name(db_channel)
    
    template_lower = template_clean.lower().strip()
    db_lower = db_clean.lower().strip()
    
    # å®Œå…¨åŒ¹é…
    if template_lower == db_lower:
        return True
    
    # ä½¿ç”¨æ˜ å°„è§„åˆ™åŒ¹é…
    for standard_name, variants in CHANNEL_MAPPING_RULES.items():
        standard_clean = clean_channel_name(standard_name).lower()
        
        # å¦‚æœæ¨¡æ¿é¢‘é“åœ¨æ ‡å‡†åç§°ä¸­
        if template_lower == standard_clean:
            # æ£€æŸ¥æ•°æ®åº“é¢‘é“æ˜¯å¦åœ¨å˜ä½“åˆ—è¡¨ä¸­
            for variant in variants:
                if db_lower == clean_channel_name(variant).lower():
                    return True
        
        # å¦‚æœæ•°æ®åº“é¢‘é“æ˜¯æ ‡å‡†åç§°
        if db_lower == standard_clean:
            # æ£€æŸ¥æ¨¡æ¿é¢‘é“æ˜¯å¦åœ¨å˜ä½“åˆ—è¡¨ä¸­
            for variant in variants:
                if template_lower == clean_channel_name(variant).lower():
                    return True
    
    # å¯¹äºCCTVé¢‘é“è¿›è¡Œç²¾å‡†åŒ¹é…
    if 'cctv' in template_lower and 'cctv' in db_lower:
        # æå–CCTVæ•°å­—éƒ¨åˆ†
        template_nums = re.findall(r'cctv[-\s]*(\d+\+?)', template_lower)
        db_nums = re.findall(r'cctv[-\s]*(\d+\+?)', db_lower)
        
        if template_nums and db_nums:
            # æ•°å­—éƒ¨åˆ†å®Œå…¨åŒ¹é…
            if template_nums[0] == db_nums[0]:
                return True
        
        # å¤„ç†CCTV-5+ç­‰ç‰¹æ®Šæƒ…å†µ
        if 'cctv-5+' in template_lower and any(x in db_lower for x in ['cctv5+', 'cctv-5+', 'cctv5plus']):
            return True
        if 'cctv5+' in template_lower and any(x in db_lower for x in ['cctv5+', 'cctv-5+', 'cctv5plus']):
            return True
    
    # å¯¹äºå«è§†é¢‘é“è¿›è¡Œç²¾å‡†åŒ¹é…
    if 'å«è§†' in template_clean and 'å«è§†' in db_clean:
        template_province = template_clean.replace('å«è§†', '').strip()
        db_province = db_clean.replace('å«è§†', '').strip()
        if template_province == db_province:
            return True
        # å¤„ç†ç®€ç§°åŒ¹é…
        if template_province in db_province or db_province in template_province:
            return True
    
    # å…¶ä»–é¢‘é“çš„å®½æ¾åŒ¹é…
    template_no_space = template_lower.replace(' ', '').replace('-', '')
    db_no_space = db_lower.replace(' ', '').replace('-', '')
    
    if template_no_space in db_no_space or db_no_space in template_no_space:
        similarity = len(set(template_no_space) & set(db_no_space)) / len(set(template_no_space) | set(db_no_space))
        if similarity > 0.7:  # ç›¸ä¼¼åº¦é˜ˆå€¼
            return True
    
    return False

def find_matching_channels(template_channel, channel_db):
    """æŸ¥æ‰¾åŒ¹é…çš„é¢‘é“"""
    matched_urls = []
    
    for db_channel, urls in channel_db.items():
        if is_channel_match(template_channel, db_channel):
            valid_urls = [(url, source, info) for url, source, info in urls 
                        if info.get('alive', False)]
            matched_urls.extend(valid_urls)
    
    return matched_urls

def match_template_channels(template_channels, channel_db):
    """åŒ¹é…æ¨¡æ¿é¢‘é“å¹¶é€‰æ‹©æœ€ä½³æµ"""
    print("\nğŸ¯ å¼€å§‹æ¨¡æ¿é¢‘é“åŒ¹é…...")
    
    txt_lines = []
    m3u_lines = ['#EXTM3U']
    current_group = "é»˜è®¤åˆ†ç»„"
    matched_count = 0
    total_matched_streams = 0
    
    for line in template_channels:
        if '#genre#' in line:
            group_name = line.replace(',#genre#', '').strip()
            current_group = group_name
            txt_lines.append(line)
            continue
        
        # æ¨¡æ¿è¡Œåªæœ‰é¢‘é“åç§°ï¼ˆæ²¡æœ‰URLï¼‰
        if line and not line.endswith('#genre#'):
            # ä½¿ç”¨åŸå§‹æ¨¡æ¿åç§°ï¼Œä¸è¿›è¡Œæ¸…ç†
            template_channel_original = line
            # ç”¨äºåŒ¹é…çš„æ¸…ç†ååç§°
            template_channel_for_match = clean_channel_name(line)
            
            print(f"  ğŸ” æŸ¥æ‰¾é¢‘é“: {template_channel_original}")
            
            matched_urls = find_matching_channels(template_channel_for_match, channel_db)
            
            if matched_urls:
                matched_urls.sort(key=lambda x: x[2].get('score', 0), reverse=True)
                best_urls = matched_urls[:MAX_STREAMS_PER_CHANNEL]
                
                for url, source, info in best_urls:
                    # ä½¿ç”¨åŸå§‹æ¨¡æ¿åç§°è¾“å‡ºï¼Œç¡®ä¿æ˜¾ç¤ºå®Œæ•´çš„"CCTV-1"ç­‰åç§°
                    output_channel_name = format_channel_name_for_output(template_channel_original)
                    txt_lines.append(f"{output_channel_name},{url}")
                    m3u_lines.append(f'#EXTINF:-1 group-title="{current_group}",{output_channel_name}')
                    m3u_lines.append(url)
                
                matched_count += 1
                total_matched_streams += len(best_urls)
                print(f"  âœ… {template_channel_original}: æ‰¾åˆ° {len(best_urls)} ä¸ªä¼˜è´¨æµ (è¯„åˆ†: {best_urls[0][2].get('score', 0) if best_urls else 0})")
            else:
                print(f"  âŒ {template_channel_original}: æœªæ‰¾åˆ°æœ‰æ•ˆæµ")
    
    try:
        with open(OUTPUT_TXT, 'w', encoding='utf-8') as f:
            f.write('\n'.join(txt_lines))
        print(f"âœ… ç”ŸæˆTXTæ–‡ä»¶: {OUTPUT_TXT}ï¼Œå…± {len(txt_lines)} è¡Œ")
    except Exception as e:
        print(f"âŒ å†™å…¥TXTæ–‡ä»¶å¤±è´¥: {e}")
    
    try:
        with open(OUTPUT_M3U, 'w', encoding='utf-8') as f:
            f.write('\n'.join(m3u_lines))
        print(f"âœ… ç”ŸæˆM3Uæ–‡ä»¶: {OUTPUT_M3U}ï¼Œå…± {len(m3u_lines)} è¡Œ")
    except Exception as e:
        print(f"âŒ å†™å…¥M3Uæ–‡ä»¶å¤±è´¥: {e}")
    
    print(f"ğŸ¯ æ¨¡æ¿åŒ¹é…å®Œæˆ: {matched_count} ä¸ªé¢‘é“åŒ¹é…æˆåŠŸï¼Œå…± {total_matched_streams} ä¸ªæµ")
    return matched_count

def test_code_integrity():
    """æµ‹è¯•ä»£ç å®Œæ•´æ€§"""
    print("ğŸ§ª å¼€å§‹ä»£ç å®Œæ•´æ€§æµ‹è¯•...")
    
    tests_passed = 0
    tests_failed = 0
    
    # æµ‹è¯•1: é¢‘é“åç§°æ¸…ç†
    try:
        test_cases = [
            ("CCTV-1é«˜æ¸…", "CCTV-1"),
            ("æ¹–å—å«è§†HD", "æ¹–å—å«è§†"),
            ("CCTV5+ è¶…æ¸…", "CCTV-5+"),
            ("åŒ—äº¬ç”µè§†å°", "åŒ—äº¬å«è§†"),
        ]
        
        for input_name, expected in test_cases:
            result = clean_channel_name(input_name)
            assert result == expected, f"æ¸…ç†æµ‹è¯•å¤±è´¥: {input_name} -> {result} (æœŸæœ›: {expected})"
        
        print("âœ… é¢‘é“åç§°æ¸…ç†æµ‹è¯•é€šè¿‡")
        tests_passed += 1
    except Exception as e:
        print(f"âŒ é¢‘é“åç§°æ¸…ç†æµ‹è¯•å¤±è´¥: {e}")
        tests_failed += 1
    
    # æµ‹è¯•2: é¢‘é“åŒ¹é…
    try:
        test_cases = [
            ("CCTV-1", "CCTV1", True),
            ("æ¹–å—å«è§†", "æ¹–å—ç”µè§†å°", True),
            ("CCTV-1", "æ¹–å—å«è§†", False),
        ]
        
        for template, db_channel, expected in test_cases:
            result = is_channel_match(template, db_channel)
            assert result == expected, f"åŒ¹é…æµ‹è¯•å¤±è´¥: {template} vs {db_channel} -> {result} (æœŸæœ›: {expected})"
        
        print("âœ… é¢‘é“åŒ¹é…æµ‹è¯•é€šè¿‡")
        tests_passed += 1
    except Exception as e:
        print(f"âŒ é¢‘é“åŒ¹é…æµ‹è¯•å¤±è´¥: {e}")
        tests_failed += 1
    
    # æµ‹è¯•3: æµè¯„åˆ†è®¡ç®—
    try:
        test_cases = [
            (True, 100, 500, 100),  # ä¼˜è´¨æµ
            (False, 100, 500, 0),   # æ— æ•ˆæµ
            (True, 2000, 50, 25),   # æ…¢é€Ÿæµ
        ]
        
        for alive, response_time, download_speed, expected_min in test_cases:
            result = calculate_stream_score(alive, response_time, download_speed)
            assert result >= expected_min, f"è¯„åˆ†æµ‹è¯•å¤±è´¥: å¾—åˆ° {result} (æœŸæœ›è‡³å°‘: {expected_min})"
        
        print("âœ… æµè¯„åˆ†æµ‹è¯•é€šè¿‡")
        tests_passed += 1
    except Exception as e:
        print(f"âŒ æµè¯„åˆ†æµ‹è¯•å¤±è´¥: {e}")
        tests_failed += 1
    
    print(f"\nğŸ“Š å®Œæ•´æ€§æµ‹è¯•ç»“æœ: {tests_passed} é€šè¿‡, {tests_failed} å¤±è´¥")
    return tests_failed == 0

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ IPTVé¢‘é“æ•´ç†å·¥å…·å¼€å§‹è¿è¡Œ...")
    start_time = time.time()
    
    # ä»£ç å®Œæ•´æ€§æµ‹è¯•
    if not test_code_integrity():
        print("âŒ ä»£ç å®Œæ•´æ€§æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
        return
    
    # 1. ä¼˜å…ˆåŠ è½½æœ¬åœ°æº
    print("\n" + "="*50)
    print("æ­¥éª¤1: ä¼˜å…ˆåŠ è½½æœ¬åœ°æº")
    local_streams = load_local_sources()
    
    # 2. æŠ“å–åœ¨çº¿æº
    print("\n" + "="*50)
    print("æ­¥éª¤2: æŠ“å–åœ¨çº¿æº")
    online_streams = fetch_online_sources()
    
    # 3. åˆå¹¶æ‰€æœ‰æºæ„å»ºå®Œæ•´æ•°æ®åº“
    print("\n" + "="*50)
    print("æ­¥éª¤3: åˆå¹¶æ‰€æœ‰æºæ„å»ºå®Œæ•´æ•°æ®åº“")
    channel_db = build_complete_channel_database(local_streams, online_streams)
    
    if not channel_db:
        print("âŒ æ— æ³•æ„å»ºé¢‘é“æ•°æ®åº“ï¼Œåœæ­¢æ‰§è¡Œ")
        return
    
    # 4. å¯¹æ‰€æœ‰é¢‘é“è¿›è¡Œæµ‹é€Ÿ
    print("\n" + "="*50)
    print("æ­¥éª¤4: å…¨é¢æµ‹é€Ÿå’Œå»¶æ—¶æµ‹è¯•")
    channel_db, speed_stats = speed_test_all_channels(channel_db)
    
    # 5. åŠ è½½æ¨¡æ¿å¹¶è¿›è¡ŒåŒ¹é…
    print("\n" + "="*50)
    print("æ­¥éª¤5: æ¨¡æ¿é¢‘é“åŒ¹é…")
    template_channels = load_template_channels()
    if template_channels:
        matched_count = match_template_channels(template_channels, channel_db)
    else:
        matched_count = 0
        print("âŒ æ— æ³•åŠ è½½æ¨¡æ¿ï¼Œè·³è¿‡åŒ¹é…")
    
    # æœ€ç»ˆç»Ÿè®¡
    end_time = time.time()
    execution_time = round(end_time - start_time, 2)
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰§è¡Œå®Œæˆ!")
    print("="*60)
    print("ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"  â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {execution_time} ç§’")
    print(f"  ğŸ“º æ€»é¢‘é“æ•°: {len(channel_db)}")
    print(f"  ğŸ”— æ€»æµæ•°é‡: {sum(len(urls) for urls in channel_db.values())}")
    print(f"  âœ… æœ‰æ•ˆæµæ•°é‡: {speed_stats['success_count']}")
    print(f"  ğŸ¯ æ¨¡æ¿åŒ¹é…: {matched_count} ä¸ªé¢‘é“")
    if speed_stats['response_times']:
        print(f"  ğŸ“ˆ å¹³å‡å“åº”: {sum(speed_stats['response_times'])/len(speed_stats['response_times']):.0f}ms")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"  - {OUTPUT_TXT} (é¢‘é“åˆ—è¡¨)")
    print(f"  - {OUTPUT_M3U} (M3Uæ’­æ”¾åˆ—è¡¨)")
    print("="*60)

if __name__ == "__main__":
    main()
