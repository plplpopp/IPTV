import requests
import pandas as pd
import re
import os
import time
import concurrent.futures
from urllib.parse import urlparse
from tqdm import tqdm
import sys
import subprocess
import json

# ============================ é…ç½®æ–‡ä»¶ ============================
# æºURLåˆ—è¡¨
URL_SOURCES = [
    "https://raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt",
    "https://raw.githubusercontent.com/wwb521/live/main/tv.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv4/result.m3u",  
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
    "https://raw.githubusercontent.com/suxuang/myIPTV/main/ipv4.m3u",
    "https://raw.githubusercontent.com/vbskycn/iptv/master/tv/iptv4.txt",
    "https://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt",
    "http://47.120.41.246:8899/zb.txt",
]

# åŠŸèƒ½å¼€å…³é…ç½®
CONFIG = {
    'ENABLE_BLACKLIST': True,           # å¯ç”¨é»‘åå•è¿‡æ»¤
    'ENABLE_RESOLUTION_FILTER': True,   # å¯ç”¨åˆ†è¾¨ç‡è¿‡æ»¤
    'MIN_RESOLUTION': 720,              # æœ€ä½åˆ†è¾¨ç‡è¦æ±‚ (720p)
    'ENABLE_CVT_SOURCE': True,          # å¯ç”¨.cvtæºå¤„ç†
    'ENABLE_FFMPEG_TEST': True,         # å¯ç”¨FFmpegæµ‹é€Ÿ (éœ€è¦å®‰è£…FFmpeg)
    'ENABLE_SPEED_TEST': True,          # å¯ç”¨å¸¸è§„æµ‹é€Ÿ
    'ENABLE_LOCAL_SOURCE': True,        # å¯ç”¨æœ¬åœ°æº
    'ENABLE_ONLINE_SOURCE': True,       # å¯ç”¨åœ¨çº¿æº
    'ENABLE_SPECIAL_FORMATS': True,     # å¯ç”¨ç‰¹æ®Šæ ¼å¼æ”¯æŒ
    'ENABLE_DIRECT_STREAM_TEST': True,  # å¯ç”¨ç›´æ¥æµæµ‹è¯•
    'MAX_STREAMS_PER_CHANNEL': 8,       # æ¯ä¸ªé¢‘é“ä¿ç•™çš„æ¥å£æ•°é‡
    'REQUEST_TIMEOUT': 10,              # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    'SPEED_TEST_TIMEOUT': 15,           # æµ‹é€Ÿè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    'FFMPEG_TIMEOUT': 25,               # FFmpegæµ‹é€Ÿè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    'FFMPEG_TEST_DURATION': 10,         # FFmpegæµ‹è¯•æ—¶é•¿ï¼ˆç§’ï¼‰
    'MAX_WORKERS': 15,                  # æœ€å¤§çº¿ç¨‹æ•°
}

# ç‰¹æ®Šæ ¼å¼æ”¯æŒ
SPECIAL_FORMATS = ['.ctv', '.cvt', '.m3u8', '.ts', '.flv', '.mpd']

# æ–‡ä»¶é…ç½®
FILES = {
    'LOCAL_SOURCE_FILE': "local.txt",
    'BLACKLIST_FILE': "blacklist.txt",
    'TEMPLATE_FILE': "demo.txt",
    'OUTPUT_TXT': "iptv.txt",
    'OUTPUT_M3U': "iptv.m3u",
}

# ============================ æ­£åˆ™è¡¨è¾¾å¼ ============================
# IPv4åœ°å€åŒ¹é…
ipv4_pattern = re.compile(r'^https?://(\d{1,3}\.){3}\d{1,3}')

# é¢‘é“åç§°å’ŒURLåŒ¹é…
channel_pattern = re.compile(r"^([^,]+?),\s*(https?://.+)", re.IGNORECASE)

# M3Uæ ¼å¼è§£æ
extinf_pattern = re.compile(r'tvg-name="([^"]*)"', re.IGNORECASE)
extinf_name_pattern = re.compile(r'#EXTINF:.*?,(.+)', re.IGNORECASE)

# åˆ†è¾¨ç‡åŒ¹é…
resolution_pattern = re.compile(r'(\d{3,4})[xÃ—*]?(\d{3,4})', re.IGNORECASE)

def load_blacklist():
    """åŠ è½½é»‘åå•å…³é”®è¯"""
    blacklist = []
    if not CONFIG['ENABLE_BLACKLIST']:
        print("âš™ï¸  é»‘åå•åŠŸèƒ½å·²ç¦ç”¨")
        return blacklist
        
    blacklist_file = FILES['BLACKLIST_FILE']
    if not os.path.exists(blacklist_file):
        print(f"âš ï¸  é»‘åå•æ–‡ä»¶ {blacklist_file} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºç¤ºä¾‹æ–‡ä»¶")
        create_sample_blacklist()
        return blacklist
    
    try:
        with open(blacklist_file, 'r', encoding='utf-8') as f:
            blacklist = [line.strip().lower() for line in f if line.strip() and not line.startswith('#')]
        print(f"âœ… åŠ è½½é»‘åå•: {len(blacklist)} ä¸ªå…³é”®è¯")
        if blacklist:
            print(f"   å…³é”®è¯ç¤ºä¾‹: {', '.join(blacklist[:5])}")
    except Exception as e:
        print(f"âŒ åŠ è½½é»‘åå•å¤±è´¥: {e}")
    
    return blacklist

def create_sample_blacklist():
    """åˆ›å»ºç¤ºä¾‹é»‘åå•æ–‡ä»¶"""
    sample_content = """# é»‘åå•æ–‡ä»¶ - æ¯è¡Œä¸€ä¸ªå…³é”®è¯
# ç¬¦åˆè¿™äº›å…³é”®è¯çš„é¢‘é“æˆ–URLå°†è¢«è¿‡æ»¤

# å¹¿å‘Šç›¸å…³
advertisement
ad_
ads
æ¨å¹¿
å¹¿å‘Š

# ä½è´¨é‡
low quality
bad quality
lag
å¡é¡¿

# ç‰¹å®šåŸŸå
example.com
bad-domain.com

# å…¶ä»–ä¸éœ€è¦çš„å†…å®¹
adult
èµŒåš
"""
    try:
        with open(FILES['BLACKLIST_FILE'], 'w', encoding='utf-8') as f:
            f.write(sample_content)
        print(f"âœ… å·²åˆ›å»ºç¤ºä¾‹é»‘åå•æ–‡ä»¶: {FILES['BLACKLIST_FILE']}")
    except Exception as e:
        print(f"âŒ åˆ›å»ºé»‘åå•æ–‡ä»¶å¤±è´¥: {e}")

def is_blacklisted(channel_name, url, blacklist):
    """æ£€æŸ¥æ˜¯å¦åœ¨é»‘åå•ä¸­"""
    if not blacklist or not CONFIG['ENABLE_BLACKLIST']:
        return False
    
    combined_text = f"{channel_name} {url}".lower()
    
    for keyword in blacklist:
        if keyword in combined_text:
            print(f"ğŸš« é»‘åå•è¿‡æ»¤: {channel_name} - å…³é”®è¯: {keyword}")
            return True
    
    return False

def detect_resolution_from_name(channel_name):
    """ä»é¢‘é“åç§°ä¸­æ£€æµ‹åˆ†è¾¨ç‡"""
    # å¸¸è§åˆ†è¾¨ç‡æ˜ å°„
    resolution_keywords = {
        '4k': 2160, 'uhd': 2160, 'ultra': 2160, '2160p': 2160,
        '1080p': 1080, '1080': 1080, 'fhd': 1080, 'fullhd': 1080,
        '720p': 720, '720': 720, 'hd': 720,
        '540p': 540, '540': 540,
        '480p': 480, '480': 480, 'sd': 480,
        '360p': 360, '360': 360
    }
    
    name_lower = channel_name.lower()
    
    # æ£€æŸ¥åˆ†è¾¨ç‡å…³é”®è¯
    for keyword, resolution in resolution_keywords.items():
        if keyword in name_lower:
            return resolution
    
    # å°è¯•åŒ¹é…æ•°å­—åˆ†è¾¨ç‡
    match = resolution_pattern.search(channel_name)
    if match:
        width = int(match.group(1))
        height = int(match.group(2))
        return max(width, height)
    
    return None

def check_resolution_requirement(channel_name, detected_resolution):
    """æ£€æŸ¥åˆ†è¾¨ç‡æ˜¯å¦ç¬¦åˆè¦æ±‚"""
    if not CONFIG['ENABLE_RESOLUTION_FILTER']:
        return True
    
    min_resolution = CONFIG['MIN_RESOLUTION']
    
    if detected_resolution is None:
        # æ— æ³•æ£€æµ‹åˆ†è¾¨ç‡æ—¶ï¼Œé»˜è®¤ä¿ç•™
        return True
    
    if detected_resolution >= min_resolution:
        return True
    else:
        print(f"ğŸ“º åˆ†è¾¨ç‡è¿‡æ»¤: {channel_name} - {detected_resolution}p < {min_resolution}p")
        return False

def handle_special_formats(url):
    """å¤„ç†ç‰¹æ®Šæ ¼å¼çš„URL"""
    if not CONFIG['ENABLE_SPECIAL_FORMATS']:
        return url
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šæ ¼å¼
    for format_ext in SPECIAL_FORMATS:
        if url.endswith(format_ext):
            print(f"ğŸ”§ æ£€æµ‹åˆ°ç‰¹æ®Šæ ¼å¼: {format_ext} - {url}")
            
            # å¯¹äº.ctv/.cvtæ ¼å¼ï¼Œå¯ä»¥æ·»åŠ ç‰¹æ®Šå¤„ç†é€»è¾‘
            if format_ext in ['.ctv', '.cvt']:
                # è¿™é‡Œå¯ä»¥æ·»åŠ ç‰¹æ®Šæ ¼å¼çš„ç‰¹æ®Šå¤„ç†
                # ä¾‹å¦‚ï¼šè½¬æ¢ä¸ºå…¶ä»–æ ¼å¼æˆ–æ·»åŠ ç‰¹å®šå‚æ•°
                pass
                
    return url

def test_special_stream(url):
    """æµ‹è¯•ç‰¹æ®Šæ ¼å¼çš„æµåª’ä½“é“¾æ¥"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Origin': 'https://freetv.fun',
            'Referer': 'https://freetv.fun/'
        }
        
        start_time = time.time()
        
        # å¯¹äºç‰¹æ®Šæ ¼å¼ï¼Œä½¿ç”¨GETè¯·æ±‚æµ‹è¯•
        response = requests.get(
            url, 
            timeout=CONFIG['REQUEST_TIMEOUT'],
            headers=headers,
            verify=False,
            stream=True
        )
        
        response_time = round((time.time() - start_time) * 1000)
        
        if response.status_code == 200:
            # æ£€æŸ¥å†…å®¹ç±»å‹
            content_type = response.headers.get('content-type', '').lower()
            
            # å¯¹äºè§†é¢‘æµï¼Œé€šå¸¸ä¼šæœ‰ç‰¹å®šçš„content-type
            video_content_types = [
                'video/', 'application/vnd.apple.mpegurl', 
                'application/x-mpegurl', 'audio/mpegurl', 'application/dash+xml'
            ]
            
            is_video_stream = any(video_type in content_type for video_type in video_content_types)
            
            # æˆ–è€…é€šè¿‡æ–‡ä»¶æ‰©å±•ååˆ¤æ–­
            is_special_format = any(url.endswith(ext) for ext in SPECIAL_FORMATS)
            
            if is_video_stream or is_special_format:
                # å°è¯•è¯»å–ä¸€å°éƒ¨åˆ†æ•°æ®æ¥ç¡®è®¤æµå¯ç”¨æ€§
                chunk_size = 1024 * 10  # 10KB
                downloaded = 0
                
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        downloaded += len(chunk)
                        if downloaded >= chunk_size:
                            break
                
                response.close()
                return {
                    'alive': True,
                    'response_time': response_time,
                    'download_speed': None,  # ç‰¹æ®Šæ ¼å¼ä¸è®¡ç®—ä¸‹è½½é€Ÿåº¦
                    'error': None,
                    'special_format': True,
                    'content_type': content_type
                }
            else:
                response.close()
                return {
                    'alive': False,
                    'response_time': response_time,
                    'download_speed': None,
                    'error': f"éè§†é¢‘æµå†…å®¹ç±»å‹: {content_type}",
                    'special_format': False
                }
        else:
            response.close()
            return {
                'alive': False,
                'response_time': response_time,
                'download_speed': None,
                'error': f"HTTP {response.status_code}",
                'special_format': False
            }
            
    except requests.exceptions.Timeout:
        return {
            'alive': False,
            'response_time': None,
            'download_speed': None,
            'error': "è¿æ¥è¶…æ—¶",
            'special_format': False
        }
    except requests.exceptions.ConnectionError:
        return {
            'alive': False,
            'response_time': None,
            'download_speed': None,
            'error': "è¿æ¥é”™è¯¯",
            'special_format': False
        }
    except Exception as e:
        return {
            'alive': False,
            'response_time': None,
            'download_speed': None,
            'error': f"æµ‹è¯•é”™è¯¯: {str(e)[:50]}",
            'special_format': False
        }

def create_correct_template():
    """åˆ›å»ºæ­£ç¡®çš„æ¨¡æ¿æ–‡ä»¶æ ¼å¼ï¼ˆåªæœ‰é¢‘é“åç§°ï¼‰"""
    print("ğŸ“ åˆ›å»ºæ­£ç¡®çš„æ¨¡æ¿æ–‡ä»¶æ ¼å¼...")
    
    template_content = """å¤®è§†é¢‘é“,#genre#
CCTV-1
CCTV-2
CCTV-3
CCTV-4
CCTV-5
CCTV-5+
CCTV-6
CCTV-7
CCTV-8
CCTV-9
CCTV-10
CCTV-11
CCTV-12
CCTV-13
CCTV-14
CCTV-15
CCTV-16
CCTV-17

å«è§†é¢‘é“,#genre#
å®‰å¾½å«è§†
å¹¿ä¸œå«è§†
æµ™æ±Ÿå«è§†
æ¹–å—å«è§†
åŒ—äº¬å«è§†
æ¹–åŒ—å«è§†
é»‘é¾™æ±Ÿå«è§†
é‡åº†å«è§†
ä¸œæ–¹å«è§†
ä¸œå—å«è§†
ç”˜è‚ƒå«è§†
å‡¤å‡°å«è§†
å¹¿è¥¿å«è§†
è´µå·å«è§†
æµ·å—å«è§†
æ²³åŒ—å«è§†
æ²³å—å«è§†
æ±Ÿè‹å«è§†
æ±Ÿè¥¿å«è§†
å‰æ—å«è§†
è¾½å®å«è§†
å†…è’™å¤å«è§†
å®å¤å«è§†
é’æµ·å«è§†
å±±ä¸œå«è§†
å±±è¥¿å«è§†
é™•è¥¿å«è§†
å››å·å«è§†
å¤©æ´¥å«è§†
è¥¿è—å«è§†
æ–°ç–†å«è§†
äº‘å—å«è§†

å…¶ä»–é¢‘é“,#genre#
å®‰å¾½å›½é™…
å®‰å¾½å½±è§†
ç¬¬ä¸€è´¢ç»
æ¢¨å›­é¢‘é“"""
    
    try:
        with open(FILES['TEMPLATE_FILE'], 'w', encoding='utf-8') as f:
            f.write(template_content)
        print(f"âœ… åˆ›å»ºæ¨¡æ¿æ–‡ä»¶: {FILES['TEMPLATE_FILE']}")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
        return False

def clean_channel_name(channel_name):
    """
    æ¸…ç†é¢‘é“åç§°ï¼Œå»é™¤ä¸éœ€è¦çš„åç¼€
    """
    # å»é™¤å¸¸è§çš„åç¼€
    suffixes = ['ç»¼åˆ', 'é«˜æ¸…', 'è¶…æ¸…', 'æ ‡æ¸…', 'HD', 'FHD', '4K', 'ç›´æ’­', 'é¢‘é“', 'å«è§†å°']
    pattern = r'[\(ï¼ˆ].*?[\)ï¼‰]|\s*-\s*.*$|\s*â€“\s*.*$'
    
    cleaned_name = channel_name.strip()
    
    # å»é™¤æ‹¬å·å†…å®¹
    cleaned_name = re.sub(pattern, '', cleaned_name)
    
    # å»é™¤åç¼€
    for suffix in suffixes:
        cleaned_name = cleaned_name.replace(suffix, '').strip()
    
    # å»é™¤å¤šä½™ç©ºæ ¼
    cleaned_name = re.sub(r'\s+', ' ', cleaned_name).strip()
    
    return cleaned_name

def format_channel_name_for_output(template_channel):
    """
    æ ¼å¼åŒ–è¾“å‡ºç”¨çš„é¢‘é“åç§°ï¼Œç¡®ä¿æ˜¾ç¤ºå®Œæ•´çš„æ ‡å‡†åç§°
    """
    # ä¿æŒæ¨¡æ¿ä¸­çš„åŸå§‹åç§°ï¼Œä¸åšæ¸…ç†
    return template_channel.strip()

def load_template_channels():
    """åŠ è½½æ¨¡æ¿é¢‘é“åˆ—è¡¨ï¼ˆåªæœ‰é¢‘é“åç§°ï¼‰"""
    if not os.path.exists(FILES['TEMPLATE_FILE']):
        print(f"âŒ æ¨¡æ¿æ–‡ä»¶ {FILES['TEMPLATE_FILE']} ä¸å­˜åœ¨")
        if not create_correct_template():
            return []
    
    template_channels = []
    template_channel_names = []  # åªå­˜å‚¨é¢‘é“åç§°
    
    try:
        print(f"ğŸ“ æ­£åœ¨åŠ è½½æ¨¡æ¿æ–‡ä»¶: {FILES['TEMPLATE_FILE']}")
        with open(FILES['TEMPLATE_FILE'], 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line:
                    template_channels.append(line)
                    
                    # åªæå–é¢‘é“åç§°ï¼ˆéåˆ†ç»„è¡Œï¼‰
                    if '#genre#' not in line and ',' not in line:
                        template_channel_names.append(line)
        
        # ç»Ÿè®¡ä¿¡æ¯
        genre_lines = [line for line in template_channels if '#genre#' in line]
        
        print(f"âœ… æ¨¡æ¿æ–‡ä»¶åŠ è½½å®Œæˆ:")
        print(f"  - æ€»è¡Œæ•°: {len(template_channels)}")
        print(f"  - åˆ†ç»„æ•°: {len(genre_lines)}")
        print(f"  - é¢‘é“æ•°: {len(template_channel_names)}")
        
        if not template_channel_names:
            print("âŒ æ¨¡æ¿ä¸­æ²¡æœ‰æœ‰æ•ˆçš„é¢‘é“åç§°")
            return []
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªé¢‘é“åç§°ä½œä¸ºç¤ºä¾‹
        print("é¢‘é“åç§°ç¤ºä¾‹:")
        for i, channel in enumerate(template_channel_names[:8], 1):
            print(f"  {i}. {channel}")
        
        return template_channels
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
        return []

def load_local_sources():
    """ä¼˜å…ˆåŠ è½½æœ¬åœ°æºæ–‡ä»¶"""
    local_streams = []
    if not CONFIG['ENABLE_LOCAL_SOURCE']:
        print("âš™ï¸  æœ¬åœ°æºåŠŸèƒ½å·²ç¦ç”¨")
        return local_streams
        
    if not os.path.exists(FILES['LOCAL_SOURCE_FILE']):
        print(f"âš ï¸  æœ¬åœ°æºæ–‡ä»¶ {FILES['LOCAL_SOURCE_FILE']} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return local_streams
    
    try:
        print(f"ğŸ“ æ­£åœ¨ä¼˜å…ˆåŠ è½½æœ¬åœ°æºæ–‡ä»¶: {FILES['LOCAL_SOURCE_FILE']}")
        with open(FILES['LOCAL_SOURCE_FILE'], 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line and not line.startswith('#'):
                    local_streams.append(('local', line))
        print(f"âœ… æœ¬åœ°æºæ–‡ä»¶åŠ è½½å®Œæˆï¼Œå…± {len(local_streams)} ä¸ªæµ")
    except Exception as e:
        print(f"âŒ åŠ è½½æœ¬åœ°æºæ–‡ä»¶å¤±è´¥: {e}")
    
    return local_streams

def fetch_online_sources():
    """æŠ“å–åœ¨çº¿æºæ•°æ®"""
    online_streams = []
    
    if not CONFIG['ENABLE_ONLINE_SOURCE']:
        print("âš™ï¸  åœ¨çº¿æºåŠŸèƒ½å·²ç¦ç”¨")
        return online_streams
    
    def fetch_single_url(url):
        """è·å–å•ä¸ªURLçš„æºæ•°æ®"""
        try:
            print(f"ğŸŒ æ­£åœ¨æŠ“å–: {url}")
            response = requests.get(url, timeout=25, verify=False)
            response.encoding = 'utf-8'
            if response.status_code == 200:
                lines = [line.strip() for line in response.text.splitlines() if line.strip()]
                print(f"âœ… æˆåŠŸæŠ“å– {url}: {len(lines)} è¡Œ")
                return (url, lines)
            else:
                print(f"âŒ æŠ“å– {url} å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return (url, [])
        except requests.exceptions.Timeout:
            print(f"â° æŠ“å– {url} è¶…æ—¶")
            return (url, [])
        except Exception as e:
            print(f"âŒ æŠ“å– {url} å¤±è´¥: {str(e)[:100]}...")
            return (url, [])
    
    if not URL_SOURCES:
        print("âš ï¸  æ²¡æœ‰é…ç½®åœ¨çº¿æºURL")
        return online_streams
    
    print("ğŸŒ æ­£åœ¨æŠ“å–åœ¨çº¿æº...")
    try:
        with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(URL_SOURCES), 6)) as executor:
            future_to_url = {executor.submit(fetch_single_url, url): url for url in URL_SOURCES}
            
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    source_url, result = future.result()
                    online_streams.extend([(source_url, line) for line in result])
                except Exception as e:
                    print(f"âŒ å¤„ç† {url} æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… åœ¨çº¿æºæŠ“å–å®Œæˆï¼Œå…±è·å– {len(online_streams)} è¡Œæ•°æ®")
    except Exception as e:
        print(f"âŒ æŠ“å–åœ¨çº¿æºæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    return online_streams

def parse_stream_line(source, line, blacklist):
    """è§£ææµæ•°æ®è¡Œï¼Œæå–é¢‘é“åç§°å’ŒURL"""
    # è·³è¿‡M3Uæ ¼å¼çš„EXTINFè¡Œ
    if line.startswith('#EXTINF'):
        return None
    
    # è·³è¿‡æ³¨é‡Šè¡Œå’Œç©ºè¡Œ
    if not line or line.startswith('#'):
        return None
    
    # å°è¯•åŒ¹é…æ ‡å‡†æ ¼å¼: é¢‘é“åç§°,URL
    match = channel_pattern.match(line)
    if match:
        channel_name = match.group(1).strip()
        url = match.group(2).strip()
        
        # ç‰¹æ®Šæ ¼å¼å¤„ç†
        if CONFIG['ENABLE_SPECIAL_FORMATS']:
            url = handle_special_formats(url)
        
        # é»‘åå•æ£€æŸ¥
        if is_blacklisted(channel_name, url, blacklist):
            return None
        
        # åˆ†è¾¨ç‡æ£€æŸ¥
        detected_resolution = detect_resolution_from_name(channel_name)
        if not check_resolution_requirement(channel_name, detected_resolution):
            return None
            
        # .cvtæºå¤„ç†
        if CONFIG['ENABLE_CVT_SOURCE'] and url.endswith('.cvt'):
            print(f"ğŸ”§ å‘ç°.cvtæº: {channel_name}")
        
        return (channel_name, url, source, detected_resolution)
    
    # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
    if ',' in line:
        parts = line.split(',', 1)
        if len(parts) == 2 and parts[1].startswith(('http://', 'https://')):
            channel_name = parts[0].strip()
            url = parts[1].strip()
            
            # ç‰¹æ®Šæ ¼å¼å¤„ç†
            if CONFIG['ENABLE_SPECIAL_FORMATS']:
                url = handle_special_formats(url)
            
            # é»‘åå•æ£€æŸ¥
            if is_blacklisted(channel_name, url, blacklist):
                return None
            
            # åˆ†è¾¨ç‡æ£€æŸ¥
            detected_resolution = detect_resolution_from_name(channel_name)
            if not check_resolution_requirement(channel_name, detected_resolution):
                return None
                
            return (channel_name, url, source, detected_resolution)
    
    return None

def build_complete_channel_database(local_streams, online_streams, blacklist):
    """æ„å»ºå®Œæ•´çš„é¢‘é“æ•°æ®åº“"""
    print("ğŸ“Š æ­£åœ¨æ„å»ºå®Œæ•´é¢‘é“æ•°æ®åº“...")
    channel_db = {}
    processed_count = 0
    filtered_count = 0
    
    all_streams = local_streams + online_streams
    
    for source, line in all_streams:
        result = parse_stream_line(source, line, blacklist)
        if result:
            channel_name, url, source_info, resolution = result
            # æ¸…ç†é¢‘é“åç§°ç”¨äºåŒ¹é…
            cleaned_name = clean_channel_name(channel_name)
            
            if cleaned_name not in channel_db:
                channel_db[cleaned_name] = []
            
            if not any(existing_url == url for existing_url, _, _, _ in channel_db[cleaned_name]):
                channel_db[cleaned_name].append((url, source_info, resolution, {}))
            processed_count += 1
        else:
            filtered_count += 1
    
    print(f"âœ… å®Œæ•´é¢‘é“æ•°æ®åº“æ„å»ºå®Œæˆ:")
    print(f"  - å¤„ç†æ•°æ®è¡Œ: {processed_count + filtered_count}")
    print(f"  - è¿‡æ»¤æ•°æ®è¡Œ: {filtered_count}")
    print(f"  - æœ‰æ•ˆæ•°æ®è¡Œ: {processed_count}")
    print(f"  - å”¯ä¸€é¢‘é“æ•°: {len(channel_db)}")
    print(f"  - æ€»æµæ•°é‡: {sum(len(urls) for urls in channel_db.values())}")
    
    # æ˜¾ç¤ºé¢‘é“ç»Ÿè®¡
    print("\nğŸ“ˆ é¢‘é“æ•°é‡ç»Ÿè®¡:")
    channel_counts = {}
    for channel_name, urls in channel_db.items():
        count = len(urls)
        if count not in channel_counts:
            channel_counts[count] = []
        channel_counts[count].append(channel_name)
    
    for count in sorted(channel_counts.keys(), reverse=True)[:10]:
        channels = channel_counts[count]
        print(f"  - {count}ä¸ªæµ: {len(channels)}ä¸ªé¢‘é“")
        if count >= 3:
            print(f"    ç¤ºä¾‹: {', '.join(channels[:2])}")
    
    return channel_db

def ffmpeg_speed_test(url):
    """ä½¿ç”¨FFmpegè¿›è¡Œæµ‹é€Ÿ - æµ‹è¯•10ç§’"""
    if not CONFIG['ENABLE_FFMPEG_TEST']:
        return None, None, "FFmpegæµ‹è¯•å·²ç¦ç”¨"
    
    try:
        # æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, timeout=5)
        if result.returncode != 0:
            return None, None, "FFmpegæœªå®‰è£…æˆ–ä¸å¯ç”¨"
    except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
        return None, None, f"FFmpegæ£€æŸ¥å¤±è´¥: {str(e)}"
    
    try:
        start_time = time.time()
        
        # ä½¿ç”¨FFmpegæµ‹è¯•æµï¼ˆæµ‹è¯•10ç§’ï¼‰
        test_duration = CONFIG['FFMPEG_TEST_DURATION']
        cmd = [
            'ffmpeg',
            '-i', url,
            '-t', str(test_duration),  # æµ‹è¯•10ç§’
            '-f', 'null', '-',
            '-y'  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
        ]
        
        print(f"ğŸ¬ FFmpegæµ‹è¯• {url} - æ—¶é•¿: {test_duration}ç§’")
        
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            timeout=CONFIG['FFMPEG_TIMEOUT'],
            text=True
        )
        
        end_time = time.time()
        total_time = round((end_time - start_time) * 1000)
        
        # è§£æFFmpegè¾“å‡ºè·å–ä¿¡æ¯
        output = result.stderr
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè¿æ¥
        if "Connection refused" in output:
            return False, total_time, "è¿æ¥è¢«æ‹’ç»"
        if "Failed to resolve" in output:
            return False, total_time, "åŸŸåè§£æå¤±è´¥"
        if "Server returned 4" in output or "HTTP error" in output:
            return False, total_time, "HTTPé”™è¯¯"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘æµ
        if "Video:" in output:
            # å°è¯•è§£æåˆ†è¾¨ç‡
            video_match = re.search(r'Video:.*?(\d+)x(\d+)', output)
            if video_match:
                width = int(video_match.group(1))
                height = int(video_match.group(2))
                resolution = max(width, height)
            else:
                resolution = None
            
            # å°è¯•è§£æç ç‡
            bitrate_match = re.search(r'bitrate:\s*(\d+)\s*kb/s', output)
            bitrate = bitrate_match.group(1) if bitrate_match else "æœªçŸ¥"
            
            # å°è¯•è§£æå¸§ç‡
            fps_match = re.search(r'(\d+(?:\.\d+)?)\s*fps', output)
            fps = fps_match.group(1) if fps_match else "æœªçŸ¥"
            
            success_msg = f"FFmpegæµ‹è¯•æˆåŠŸ ({test_duration}ç§’)"
            if resolution:
                success_msg += f" - åˆ†è¾¨ç‡: {resolution}p"
            if bitrate != "æœªçŸ¥":
                success_msg += f" - ç ç‡: {bitrate}kb/s"
            if fps != "æœªçŸ¥":
                success_msg += f" - å¸§ç‡: {fps}fps"
                
            return True, total_time, success_msg
        else:
            return False, total_time, "æ— è§†é¢‘æµ"
            
    except subprocess.TimeoutExpired:
        return False, None, f"FFmpegæµ‹è¯•è¶…æ—¶ ({CONFIG['FFMPEG_TIMEOUT']}ç§’)"
    except Exception as e:
        return False, None, f"FFmpegé”™è¯¯: {str(e)[:50]}"

def comprehensive_speed_test(url):
    """å…¨é¢æµ‹é€ŸåŠŸèƒ½"""
    speed_info = {}
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šæ ¼å¼
    is_special_format = any(url.endswith(ext) for ext in SPECIAL_FORMATS)
    
    if is_special_format and CONFIG['ENABLE_DIRECT_STREAM_TEST']:
        print(f"ğŸ¯ æµ‹è¯•ç‰¹æ®Šæ ¼å¼æµ: {url}")
        return test_special_stream(url)
    
    # å¸¸è§„HTTPæµ‹é€Ÿ
    if CONFIG['ENABLE_SPEED_TEST']:
        try:
            start_time = time.time()
            response = requests.head(url, timeout=CONFIG['REQUEST_TIMEOUT'], verify=False, 
                                   headers={'User-Agent': 'Mozilla/5.0'})
            head_time = time.time()
            response_time_ms = round((head_time - start_time) * 1000)
            
            if response.status_code != 200:
                speed_info.update({
                    'alive': False,
                    'response_time': response_time_ms,
                    'error': f"HTTP {response.status_code}"
                })
                return speed_info
            
            download_speed = None
            try:
                chunk_size = 1024 * 50
                start_download = time.time()
                download_response = requests.get(url, timeout=CONFIG['SPEED_TEST_TIMEOUT'], 
                                               verify=False, stream=True,
                                               headers={'User-Agent': 'Mozilla/5.0'})
                
                downloaded = 0
                for chunk in download_response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        downloaded += len(chunk)
                        if downloaded >= chunk_size:
                            break
                
                end_download = time.time()
                download_time = end_download - start_download
                
                if download_time > 0.1:
                    download_speed = round((downloaded / 1024) / download_time)
                
                download_response.close()
                
            except Exception as e:
                download_speed = None
            
            speed_info.update({
                'alive': True,
                'response_time': response_time_ms,
                'download_speed': download_speed,
                'error': None
            })
            
        except requests.exceptions.Timeout:
            speed_info.update({
                'alive': False,
                'response_time': None,
                'download_speed': None,
                'error': "Timeout"
            })
        except requests.exceptions.ConnectionError:
            speed_info.update({
                'alive': False, 
                'response_time': None,
                'download_speed': None,
                'error': "Connection Error"
            })
        except Exception as e:
            speed_info.update({
                'alive': False,
                'response_time': None, 
                'download_speed': None,
                'error': str(e)[:50]
            })
    
    # FFmpegæµ‹é€Ÿ - åªæœ‰åœ¨å¸¸è§„æµ‹è¯•æˆåŠŸæ—¶æ‰è¿›è¡Œ
    if CONFIG['ENABLE_FFMPEG_TEST'] and speed_info.get('alive', False):
        print(f"ğŸ” è¿›è¡ŒFFmpegæ·±åº¦æµ‹è¯•: {url}")
        ffmpeg_alive, ffmpeg_response_time, ffmpeg_error = ffmpeg_speed_test(url)
        speed_info.update({
            'ffmpeg_alive': ffmpeg_alive,
            'ffmpeg_response_time': ffmpeg_response_time,
            'ffmpeg_error': ffmpeg_error
        })
        
        # å¦‚æœFFmpegæµ‹è¯•å¤±è´¥ï¼Œä½†å¸¸è§„æµ‹è¯•æˆåŠŸï¼Œé™ä½è¯„åˆ†
        if not ffmpeg_alive:
            print(f"âš ï¸  FFmpegæµ‹è¯•å¤±è´¥ä½†å¸¸è§„æµ‹è¯•æˆåŠŸ: {url}")
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    speed_info['score'] = calculate_stream_score(speed_info)
    
    return speed_info

def calculate_stream_score(speed_info):
    """è®¡ç®—æµè´¨é‡ç»¼åˆè¯„åˆ†"""
    if not speed_info.get('alive', False):
        return 0
    
    score = 0
    
    # å“åº”æ—¶é—´è¯„åˆ†
    response_time = speed_info.get('response_time')
    if response_time:
        if response_time <= 100:
            score += 60
        elif response_time <= 300:
            score += 50
        elif response_time <= 500:
            score += 40
        elif response_time <= 1000:
            score += 30
        elif response_time <= 2000:
            score += 20
        else:
            score += 10
    
    # ä¸‹è½½é€Ÿåº¦è¯„åˆ†
    download_speed = speed_info.get('download_speed')
    if download_speed:
        if download_speed >= 1000:
            score += 40
        elif download_speed >= 500:
            score += 30
        elif download_speed >= 200:
            score += 20
        elif download_speed >= 100:
            score += 10
        else:
            score += 5
    
    # FFmpegæµ‹è¯•åŠ åˆ†ï¼ˆé‡è¦æƒé‡ï¼‰
    if speed_info.get('ffmpeg_alive'):
        score += 30  # å¢åŠ FFmpegæµ‹è¯•çš„æƒé‡
        # FFmpegå“åº”æ—¶é—´ä¹Ÿè€ƒè™‘
        ffmpeg_time = speed_info.get('ffmpeg_response_time')
        if ffmpeg_time and ffmpeg_time <= 5000:  # 5ç§’å†…å®Œæˆæµ‹è¯•
            score += 10
    else:
        # FFmpegæµ‹è¯•å¤±è´¥ä½†å¸¸è§„æµ‹è¯•æˆåŠŸï¼Œé€‚å½“æ‰£åˆ†
        if speed_info.get('alive'):
            score -= 15
    
    # ç‰¹æ®Šæ ¼å¼æµåŠ åˆ†
    if speed_info.get('special_format'):
        score += 15
    
    return max(0, score)  # ç¡®ä¿åˆ†æ•°ä¸ä¸ºè´Ÿ

def speed_test_all_channels(channel_db):
    """å¯¹æ‰€æœ‰é¢‘é“è¿›è¡Œæµ‹é€Ÿ"""
    print("\nğŸš€ å¼€å§‹å…¨é¢æµ‹é€Ÿ...")
    
    total_urls = sum(len(urls) for urls in channel_db.values())
    print(f"ğŸ“Š éœ€è¦æµ‹é€Ÿçš„URLæ€»æ•°: {total_urls}")
    
    # å¦‚æœå¯ç”¨FFmpegæµ‹è¯•ï¼Œæ˜¾ç¤ºæç¤º
    if CONFIG['ENABLE_FFMPEG_TEST']:
        print(f"ğŸ¬ FFmpegæµ‹é€Ÿå·²å¯ç”¨ - æ¯ä¸ªæµæµ‹è¯•{CONFIG['FFMPEG_TEST_DURATION']}ç§’")
        print("âš ï¸  æ³¨æ„: FFmpegæµ‹é€Ÿä¼šæ˜¾è‘—å¢åŠ æµ‹è¯•æ—¶é—´ï¼Œä½†ç»“æœæ›´å‡†ç¡®")
    
    all_urls_to_test = []
    url_to_channel_map = {}
    
    for channel_name, urls in channel_db.items():
        for url, source, resolution, _ in urls:
            all_urls_to_test.append(url)
            url_to_channel_map[url] = channel_name
    
    speed_stats = {
        'total_tested': 0,
        'success_count': 0,
        'timeout_count': 0,
        'error_count': 0,
        'ffmpeg_success_count': 0,
        'ffmpeg_fail_count': 0,
        'response_times': []
    }
    
    print("â±ï¸  æ­£åœ¨è¿›è¡Œå…¨é¢æµ‹é€Ÿ...")
    with tqdm(total=len(all_urls_to_test), desc="å…¨é¢æµ‹é€Ÿ", unit="URL", 
              bar_format='{l_bar}{bar:30}{r_bar}{bar:-30b}') as pbar:
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=CONFIG['MAX_WORKERS']) as executor:
            future_to_url = {executor.submit(comprehensive_speed_test, url): url for url in all_urls_to_test}
            
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                channel_name = url_to_channel_map[url]
                
                try:
                    speed_info = future.result()
                    speed_stats['total_tested'] += 1
                    
                    for i, (stream_url, source, resolution, _) in enumerate(channel_db[channel_name]):
                        if stream_url == url:
                            channel_db[channel_name][i] = (
                                stream_url, 
                                source, 
                                resolution,
                                speed_info
                            )
                            break
                    
                    if speed_info.get('alive', False):
                        speed_stats['success_count'] += 1
                        response_time = speed_info.get('response_time')
                        if response_time:
                            speed_stats['response_times'].append(response_time)
                        
                        # FFmpegç»Ÿè®¡
                        if speed_info.get('ffmpeg_alive'):
                            speed_stats['ffmpeg_success_count'] += 1
                        elif CONFIG['ENABLE_FFMPEG_TEST']:
                            speed_stats['ffmpeg_fail_count'] += 1
                    else:
                        if speed_info.get('error') == "Timeout":
                            speed_stats['timeout_count'] += 1
                        else:
                            speed_stats['error_count'] += 1
                    
                    # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                    postfix_info = {
                        'success': f"{speed_stats['success_count']}/{speed_stats['total_tested']}",
                    }
                    if speed_stats['response_times']:
                        postfix_info['avg_time'] = f"{sum(speed_stats['response_times'])/len(speed_stats['response_times']):.0f}ms"
                    if CONFIG['ENABLE_FFMPEG_TEST']:
                        postfix_info['ffmpeg'] = f"{speed_stats['ffmpeg_success_count']}PASS"
                    
                    pbar.set_postfix(**postfix_info)
                    pbar.update(1)
                    
                except Exception as e:
                    pbar.update(1)
    
    if speed_stats['response_times']:
        avg_response_time = sum(speed_stats['response_times']) / len(speed_stats['response_times'])
        min_response_time = min(speed_stats['response_times'])
        max_response_time = max(speed_stats['response_times'])
    else:
        avg_response_time = min_response_time = max_response_time = 0
    
    print(f"\nâœ… å…¨é¢æµ‹é€Ÿå®Œæˆ:")
    print(f"  - æµ‹è¯•æ€»æ•°: {speed_stats['total_tested']}")
    print(f"  - æˆåŠŸ: {speed_stats['success_count']} ({speed_stats['success_count']/speed_stats['total_tested']*100:.1f}%)")
    print(f"  - è¶…æ—¶: {speed_stats['timeout_count']}")
    print(f"  - é”™è¯¯: {speed_stats['error_count']}")
    if CONFIG['ENABLE_FFMPEG_TEST']:
        print(f"  - FFmpegæµ‹è¯•æˆåŠŸ: {speed_stats['ffmpeg_success_count']}")
        print(f"  - FFmpegæµ‹è¯•å¤±è´¥: {speed_stats['ffmpeg_fail_count']}")
    print(f"  - å¹³å‡å“åº”: {avg_response_time:.0f}ms")
    print(f"  - æœ€å¿«å“åº”: {min_response_time}ms")
    print(f"  - æœ€æ…¢å“åº”: {max_response_time}ms")
    
    return channel_db, speed_stats

def is_exact_channel_match(template_channel, db_channel):
    """
    ç²¾å‡†åŒ¹é…é¢‘é“åç§° - åªè¿›è¡Œå®Œå…¨åŒ¹é…
    """
    template_clean = clean_channel_name(template_channel)
    db_clean = clean_channel_name(db_channel)
    
    # å®Œå…¨åŒ¹é…
    return template_clean == db_clean

def find_matching_channels(template_channel, channel_db):
    """æŸ¥æ‰¾ç²¾å‡†åŒ¹é…çš„é¢‘é“"""
    matched_urls = []
    
    for db_channel, urls in channel_db.items():
        if is_exact_channel_match(template_channel, db_channel):
            valid_urls = [(url, source, resolution, info) for url, source, resolution, info in urls 
                        if info.get('alive', False)]
            matched_urls.extend(valid_urls)
    
    return matched_urls

def match_template_channels(template_channels, channel_db):
    """åŒ¹é…æ¨¡æ¿é¢‘é“å¹¶é€‰æ‹©æœ€ä½³æµ"""
    print("\nğŸ¯ å¼€å§‹æ¨¡æ¿é¢‘é“ç²¾å‡†åŒ¹é…...")
    
    txt_lines = []
    m3u_lines = ['#EXTM3U']
    current_group = "é»˜è®¤åˆ†ç»„"
    matched_count = 0
    
    for line in template_channels:
        if '#genre#' in line:
            group_name = line.replace(',#genre#', '').strip()
            current_group = group_name
            txt_lines.append(line)
            continue
        
        # æ¨¡æ¿è¡Œåªæœ‰é¢‘é“åç§°ï¼ˆæ²¡æœ‰URLï¼‰
        if line and not line.endswith('#genre#'):
            # ä½¿ç”¨åŸå§‹æ¨¡æ¿åç§°ï¼Œä¸è¿›è¡Œæ¸…ç†
            template_channel_original = line
            
            print(f"  ğŸ” ç²¾å‡†æŸ¥æ‰¾é¢‘é“: {template_channel_original}")
            
            matched_urls = find_matching_channels(template_channel_original, channel_db)
            
            if matched_urls:
                matched_urls.sort(key=lambda x: x[3].get('score', 0), reverse=True)
                best_urls = matched_urls[:CONFIG['MAX_STREAMS_PER_CHANNEL']]
                
                for url, source, resolution, info in best_urls:
                    # ä½¿ç”¨åŸå§‹æ¨¡æ¿åç§°è¾“å‡ºï¼Œç¡®ä¿æ˜¾ç¤ºå®Œæ•´çš„æ ‡å‡†åç§°
                    output_channel_name = format_channel_name_for_output(template_channel_original)
                    
                    # æ·»åŠ åˆ†è¾¨ç‡ä¿¡æ¯åˆ°é¢‘é“åç§°ï¼ˆä¸æ·»åŠ âœ…æ ‡è®°ï¼‰
                    if resolution and CONFIG['ENABLE_RESOLUTION_FILTER']:
                        output_channel_name = f"{output_channel_name}({resolution}p)"
                    
                    txt_lines.append(f"{output_channel_name},{url}")
                    m3u_lines.append(f'#EXTINF:-1 group-title="{current_group}",{output_channel_name}')
                    m3u_lines.append(url)
                
                matched_count += 1
                print(f"  âœ… {template_channel_original}: æ‰¾åˆ° {len(best_urls)} ä¸ªç²¾å‡†åŒ¹é…çš„ä¼˜è´¨æµ")
            else:
                print(f"  âŒ {template_channel_original}: æœªæ‰¾åˆ°ç²¾å‡†åŒ¹é…çš„æœ‰æ•ˆæµ")
    
    try:
        with open(FILES['OUTPUT_TXT'], 'w', encoding='utf-8') as f:
            f.write('\n'.join(txt_lines))
        print(f"âœ… ç”ŸæˆTXTæ–‡ä»¶: {FILES['OUTPUT_TXT']}ï¼Œå…± {len(txt_lines)} è¡Œ")
    except Exception as e:
        print(f"âŒ å†™å…¥TXTæ–‡ä»¶å¤±è´¥: {e}")
    
    try:
        with open(FILES['OUTPUT_M3U'], 'w', encoding='utf-8') as f:
            f.write('\n'.join(m3u_lines))
        print(f"âœ… ç”ŸæˆM3Uæ–‡ä»¶: {FILES['OUTPUT_M3U']}ï¼Œå…± {len(m3u_lines)} è¡Œ")
    except Exception as e:
        print(f"âŒ å†™å…¥M3Uæ–‡ä»¶å¤±è´¥: {e}")
    
    print(f"ğŸ¯ æ¨¡æ¿ç²¾å‡†åŒ¹é…å®Œæˆ: {matched_count} ä¸ªé¢‘é“åŒ¹é…æˆåŠŸ")
    return matched_count

def print_config_summary():
    """æ‰“å°é…ç½®æ‘˜è¦"""
    print("âš™ï¸  å½“å‰é…ç½®:")
    print(f"  - é»‘åå•è¿‡æ»¤: {'âœ…' if CONFIG['ENABLE_BLACKLIST'] else 'âŒ'}")
    print(f"  - åˆ†è¾¨ç‡è¿‡æ»¤: {'âœ…' if CONFIG['ENABLE_RESOLUTION_FILTER'] else 'âŒ'} (æœ€ä½{CONFIG['MIN_RESOLUTION']}p)")
    print(f"  - .cvtæºå¤„ç†: {'âœ…' if CONFIG['ENABLE_CVT_SOURCE'] else 'âŒ'}")
    print(f"  - FFmpegæµ‹é€Ÿ: {'âœ…' if CONFIG['ENABLE_FFMPEG_TEST'] else 'âŒ'} (æµ‹è¯•{CONFIG['FFMPEG_TEST_DURATION']}ç§’)")
    print(f"  - å¸¸è§„æµ‹é€Ÿ: {'âœ…' if CONFIG['ENABLE_SPEED_TEST'] else 'âŒ'}")
    print(f"  - ç‰¹æ®Šæ ¼å¼æ”¯æŒ: {'âœ…' if CONFIG['ENABLE_SPECIAL_FORMATS'] else 'âŒ'}")
    print(f"  - ç›´æ¥æµæµ‹è¯•: {'âœ…' if CONFIG['ENABLE_DIRECT_STREAM_TEST'] else 'âŒ'}")
    print(f"  - æœ¬åœ°æº: {'âœ…' if CONFIG['ENABLE_LOCAL_SOURCE'] else 'âŒ'}")
    print(f"  - åœ¨çº¿æº: {'âœ…' if CONFIG['ENABLE_ONLINE_SOURCE'] else 'âŒ'}")
    print(f"  - ç²¾å‡†åŒ¹é…: âœ… (å·²å¯ç”¨)")
    print(f"  - æ¯é¢‘é“æœ€å¤§æµæ•°: {CONFIG['MAX_STREAMS_PER_CHANNEL']}")
    print(f"  - æœ€å¤§çº¿ç¨‹æ•°: {CONFIG['MAX_WORKERS']}")

def test_freetv_ctv_stream():
    """ä¸“é—¨æµ‹è¯•freetvçš„.ctvæµ"""
    test_url = "https://stream1.freetv.fun/cctv4-zhong-wen-guo-ji-1.ctv"
    
    print(f"\nğŸ” æµ‹è¯•ç‰¹å®šæµ: {test_url}")
    
    # æ–¹æ³•1: ç›´æ¥HTTPè¯·æ±‚æµ‹è¯•
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': '*/*',
            'Accept-Encoding': 'identity',
            'Connection': 'keep-alive',
        }
        
        response = requests.get(test_url, headers=headers, timeout=10, stream=True, verify=False)
        print(f"ğŸ“¡ å“åº”çŠ¶æ€: {response.status_code}")
        print(f"ğŸ“¦ å†…å®¹ç±»å‹: {response.headers.get('content-type')}")
        print(f"ğŸ“ å†…å®¹é•¿åº¦: {response.headers.get('content-length')}")
        
        # å°è¯•è¯»å–å‰å‡ ä¸ªå­—èŠ‚
        chunk = response.raw.read(100)
        print(f"ğŸ”¢ å‰100å­—èŠ‚: {chunk[:20]}...")
        
        response.close()
        
        # å¦‚æœå¯ç”¨FFmpegï¼Œä¹Ÿè¿›è¡ŒFFmpegæµ‹è¯•
        if CONFIG['ENABLE_FFMPEG_TEST']:
            print(f"ğŸ¬ è¿›è¡ŒFFmpegæ·±åº¦æµ‹è¯•...")
            ffmpeg_alive, ffmpeg_time, ffmpeg_msg = ffmpeg_speed_test(test_url)
            print(f"FFmpegç»“æœ: {'é€šè¿‡' if ffmpeg_alive else 'å¤±è´¥'} - {ffmpeg_msg}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ IPTVé¢‘é“æ•´ç†å·¥å…·å¼€å§‹è¿è¡Œ...")
    start_time = time.time()
    
    # æ‰“å°é…ç½®æ‘˜è¦
    print_config_summary()
    
    # æµ‹è¯•ç‰¹å®šæµï¼ˆå¯é€‰ï¼‰
    if CONFIG['ENABLE_SPECIAL_FORMATS']:
        test_freetv_ctv_stream()
    
    # 1. åŠ è½½é»‘åå•
    print("\n" + "="*50)
    print("æ­¥éª¤1: åŠ è½½é»‘åå•")
    blacklist = load_blacklist()
    
    # 2. ä¼˜å…ˆåŠ è½½æœ¬åœ°æº
    print("\n" + "="*50)
    print("æ­¥éª¤2: ä¼˜å…ˆåŠ è½½æœ¬åœ°æº")
    local_streams = load_local_sources()
    
    # 3. æŠ“å–åœ¨çº¿æº
    print("\n" + "="*50)
    print("æ­¥éª¤3: æŠ“å–åœ¨çº¿æº")
    online_streams = fetch_online_sources()
    
    # 4. åˆå¹¶æ‰€æœ‰æºæ„å»ºå®Œæ•´æ•°æ®åº“
    print("\n" + "="*50)
    print("æ­¥éª¤4: åˆå¹¶æ‰€æœ‰æºæ„å»ºå®Œæ•´æ•°æ®åº“")
    channel_db = build_complete_channel_database(local_streams, online_streams, blacklist)
    
    if not channel_db:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„é¢‘é“æ•°æ®ï¼Œç¨‹åºé€€å‡º")
        return
    
    # 5. å¯¹æ‰€æœ‰é¢‘é“è¿›è¡Œæµ‹é€Ÿ
    print("\n" + "="*50)
    print("æ­¥éª¤5: å…¨é¢æµ‹é€Ÿå’Œå»¶æ—¶æµ‹è¯•")
    channel_db, speed_stats = speed_test_all_channels(channel_db)
    
    # 6. åŠ è½½æ¨¡æ¿å¹¶è¿›è¡ŒåŒ¹é…
    print("\n" + "="*50)
    print("æ­¥éª¤6: æ¨¡æ¿é¢‘é“ç²¾å‡†åŒ¹é…")
    template_channels = load_template_channels()
    if template_channels:
        matched_count = match_template_channels(template_channels, channel_db)
    else:
        matched_count = 0
        print("âŒ æ— æ³•åŠ è½½æ¨¡æ¿ï¼Œè·³è¿‡åŒ¹é…")
    
    # æœ€ç»ˆç»Ÿè®¡
    end_time = time.time()
    execution_time = round(end_time - start_time, 2)
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰§è¡Œå®Œæˆ!")
    print("="*60)
    print("ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"  â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {execution_time} ç§’")
    print(f"  ğŸ“º æ€»é¢‘é“æ•°: {len(channel_db)}")
    print(f"  ğŸ”— æ€»æµæ•°é‡: {sum(len(urls) for urls in channel_db.values())}")
    print(f"  âœ… æœ‰æ•ˆæµæ•°é‡: {speed_stats['success_count']}")
    if CONFIG['ENABLE_FFMPEG_TEST']:
        print(f"  ğŸ¬ FFmpegéªŒè¯æˆåŠŸ: {speed_stats['ffmpeg_success_count']}")
    print(f"  ğŸ¯ ç²¾å‡†åŒ¹é…: {matched_count} ä¸ªé¢‘é“")
    if speed_stats['response_times']:
        print(f"  ğŸ“ˆ å¹³å‡å“åº”: {sum(speed_stats['response_times'])/len(speed_stats['response_times']):.0f}ms")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"  - {FILES['OUTPUT_TXT']} (é¢‘é“åˆ—è¡¨)")
    print(f"  - {FILES['OUTPUT_M3U']} (M3Uæ’­æ”¾åˆ—è¡¨)")
    print("="*60)

if __name__ == "__main__":
    requests.packages.urllib3.disable_warnings()
    main()
