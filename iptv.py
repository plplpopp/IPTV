import sys
import time
import socket
import requests
import json
import re
import os
import threading
import ipaddress
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urljoin, urlparse
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('iptv_system.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class IPTVScanner:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Connection': 'keep-alive'
        })
        self.timeout = 3
        self.found_servers = []
        self.lock = threading.Lock()
        
        # å¸¸è§çš„IPTVç«¯å£
        self.common_ports = [80, 8080, 8000, 8001, 8002, 8081, 8082, 8090, 8888, 9000]
        
        # å¸¸è§çš„IPTV JSONè·¯å¾„
        self.json_paths = [
            "/iptv/live/1000.json?key=txiptv",
            "/iptv/live/1000.json",
            "/live/1000.json",
            "/tv/1000.json",
            "/iptv/live.json",
            "/api/live",
            "/live.json"
        ]

    def generate_ip_ranges(self):
        """ç”Ÿæˆå¸¸è§çš„å›½å†…IPæ®µ"""
        ip_ranges = []
        
        # ç”µä¿¡IPæ®µ
        telecom_ranges = [
            "58.16.0.0/16", "58.17.0.0/16", "58.18.0.0/16", "58.19.0.0/16",
            "60.0.0.0/11", "60.160.0.0/11", "60.208.0.0/12",
            "113.0.0.0/13", "113.8.0.0/15", "113.16.0.0/12",
            "114.80.0.0/12", "114.96.0.0/13", "114.104.0.0/14",
            "115.48.0.0/12", "115.152.0.0/13", "115.160.0.0/12",
            "116.1.0.0/16", "116.2.0.0/15", "116.4.0.0/14",
            "117.8.0.0/13", "117.16.0.0/12", "117.32.0.0/11",
            "118.74.0.0/15", "118.76.0.0/16", "118.80.0.0/13",
            "119.0.0.0/13", "119.8.0.0/15", "119.10.0.0/16"
        ]
        
        # è”é€šIPæ®µ
        unicom_ranges = [
            "60.8.0.0/13", "60.16.0.0/12", "60.24.0.0/13",
            "61.128.0.0/10", "61.160.0.0/12", "61.176.0.0/13",
            "111.0.0.0/10", "111.64.0.0/12", "111.80.0.0/13",
            "112.0.0.0/10", "112.64.0.0/14", "112.80.0.0/12",
            "113.200.0.0/15", "113.202.0.0/16", "113.204.0.0/14",
            "114.224.0.0/12", "114.240.0.0/12", "115.24.0.0/14"
        ]
        
        # ç§»åŠ¨IPæ®µ
        mobile_ranges = [
            "111.0.0.0/10", "111.64.0.0/12", "111.80.0.0/13",
            "112.0.0.0/10", "112.64.0.0/14", "112.80.0.0/12",
            "113.200.0.0/15", "113.202.0.0/16", "113.204.0.0/14",
            "114.224.0.0/12", "114.240.0.0/12", "115.24.0.0/14"
        ]
        
        all_ranges = telecom_ranges + unicom_ranges + mobile_ranges
        
        # éšæœºé€‰æ‹©ä¸€äº›IPæ®µè¿›è¡Œæ‰«æ
        selected_ranges = random.sample(all_ranges, min(10, len(all_ranges)))
        
        for ip_range in selected_ranges:
            network = ipaddress.ip_network(ip_range, strict=False)
            # ä»æ¯ä¸ªç½‘æ®µä¸­éšæœºé€‰æ‹©ä¸€äº›IP
            ip_count = min(20, network.num_addresses)
            for _ in range(ip_count):
                ip = str(network[random.randint(0, network.num_addresses - 1)])
                ip_ranges.append(ip)
                
        return ip_ranges

    def test_port(self, ip, port):
        """æµ‹è¯•ç«¯å£æ˜¯å¦å¼€æ”¾"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(2)
            result = sock.connect_ex((ip, port))
            sock.close()
            return result == 0
        except:
            return False

    def test_iptv_server(self, ip, port):
        """æµ‹è¯•æ˜¯å¦ä¸ºæœ‰æ•ˆçš„IPTVæœåŠ¡å™¨"""
        base_url = f"http://{ip}:{port}"
        
        for json_path in self.json_paths:
            try:
                url = urljoin(base_url, json_path)
                response = self.session.get(url, timeout=self.timeout)
                
                if response.status_code == 200:
                    # æ£€æŸ¥è¿”å›å†…å®¹æ˜¯å¦ä¸ºæœ‰æ•ˆçš„JSON
                    try:
                        data = response.json()
                        # æ£€æŸ¥JSONç»“æ„æ˜¯å¦åŒ…å«é¢‘é“æ•°æ®
                        if isinstance(data, dict) and 'data' in data:
                            if isinstance(data['data'], list) and len(data['data']) > 0:
                                return True, url, len(data['data'])
                        elif isinstance(data, list) and len(data) > 0:
                            return True, url, len(data)
                    except:
                        continue
            except:
                continue
                
        return False, None, 0

    def scan_single_ip(self, ip):
        """æ‰«æå•ä¸ªIPçš„æ‰€æœ‰å¸¸è§ç«¯å£"""
        for port in self.common_ports:
            if self.test_port(ip, port):
                logging.info(f"âœ… Port {port} open on {ip}")
                is_iptv, url, channel_count = self.test_iptv_server(ip, port)
                if is_iptv:
                    with self.lock:
                        self.found_servers.append({
                            'ip': ip,
                            'port': port,
                            'url': url,
                            'channel_count': channel_count,
                            'server_url': f"http://{ip}:{port}"
                        })
                    logging.info(f"ğŸ¯ Found IPTV server: {ip}:{port} with {channel_count} channels")
                    break  # æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆæœåŠ¡å°±åœæ­¢æ‰«æè¯¥IPçš„å…¶ä»–ç«¯å£
                
        return []

    def quick_scan_common_servers(self):
        """å¿«é€Ÿæ‰«æå·²çŸ¥çš„å¸¸è§æœåŠ¡å™¨"""
        common_servers = [
            "60.214.107.42", "113.57.127.43", "58.222.24.11",
            "117.169.120.140", "112.30.144.207", "183.134.100.98",
            "60.214.107.43", "113.57.127.44", "58.222.24.12",
            "117.169.120.141", "112.30.144.208"
        ]
        
        logging.info("ğŸ” Quick scanning common IPTV servers...")
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_ip = {executor.submit(self.scan_single_ip, ip): ip for ip in common_servers}
            
            for future in as_completed(future_to_ip):
                ip = future_to_ip[future]
                try:
                    future.result()
                except Exception as e:
                    logging.error(f"âŒ Error scanning {ip}: {e}")
                    
        return len(self.found_servers)

    def deep_scan_network(self, max_ips=100):
        """æ·±åº¦æ‰«æç½‘ç»œ"""
        logging.info("ğŸŒ Starting deep network scan...")
        ip_list = self.generate_ip_ranges()
        
        # é™åˆ¶æ‰«æçš„IPæ•°é‡
        ip_list = ip_list[:max_ips]
        
        logging.info(f"ğŸ“¡ Scanning {len(ip_list)} IP addresses...")
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_ip = {executor.submit(self.scan_single_ip, ip): ip for ip in ip_list}
            
            for i, future in enumerate(as_completed(future_to_ip)):
                ip = future_to_ip[future]
                try:
                    future.result()
                    if (i + 1) % 20 == 0:
                        logging.info(f"ğŸ“Š Progress: {i+1}/{len(ip_list)} - Found: {len(self.found_servers)} servers")
                except Exception as e:
                    logging.debug(f"Error scanning {ip}: {e}")
                    
        return len(self.found_servers)

    def save_found_servers(self, filename="discovered_servers.txt"):
        """ä¿å­˜å‘ç°çš„æœåŠ¡å™¨"""
        if not self.found_servers:
            logging.warning("âš ï¸ No servers to save")
            return
            
        try:
            with open(filename, "w", encoding="utf-8") as f:
                f.write("# Discovered IPTV Servers\n")
                f.write(f"# Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# Total Servers: {len(self.found_servers)}\n")
                f.write("# Format: ServerURL,IP,Port,ChannelCount\n")
                f.write("# \n")
                
                for server in self.found_servers:
                    f.write(f"{server['server_url']},{server['ip']},{server['port']},{server['channel_count']}\n")
                    
            logging.info(f"ğŸ’¾ Saved {len(self.found_servers)} servers to {filename}")
        except Exception as e:
            logging.error(f"âŒ Error saving servers: {e}")

    def load_servers_for_collection(self):
        """ä¸ºé¢‘é“æ”¶é›†å‡†å¤‡æœåŠ¡å™¨åˆ—è¡¨"""
        return [server['server_url'] for server in self.found_servers]

class IPTVCollector:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Connection': 'keep-alive'
        })

    def load_servers_from_file(self, filename="discovered_servers.txt"):
        """ä»æ–‡ä»¶åŠ è½½æœåŠ¡å™¨åˆ—è¡¨"""
        servers = []
        if os.path.exists(filename):
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            parts = line.split(',')
                            if parts and parts[0].startswith('http'):
                                servers.append(parts[0])
                logging.info(f"ğŸ“ Loaded {len(servers)} servers from {filename}")
            except Exception as e:
                logging.warning(f"âš ï¸ Could not load servers from file: {e}")
        return servers

    def clean_channel_name(self, name):
        """æ¸…ç†é¢‘é“åç§°"""
        if not name:
            return ""
        
        # é¢‘é“åç§°æ˜ å°„è¡¨
        name_mappings = {
            r"ä¸­å¤®(\d+)": r"CCTV\1",
            r"CCTV-?(\d+)": r"CCTV\1",
            r"é«˜æ¸…": "",
            r"HD": "",
            r"è¶…æ¸…": "",
            r"æ ‡æ¸…": "",
            r"é¢‘é“": "",
            r"å°": "",
            r"[-_\s]": "",
            r"PLUS": "+",
            r"[()ï¼ˆï¼‰]": "",
            r"CCTV1ç»¼åˆ": "CCTV1",
            r"CCTV2è´¢ç»": "CCTV2",
            r"CCTV3ç»¼è‰º": "CCTV3",
            r"CCTV4ä¸­æ–‡å›½é™…": "CCTV4",
            r"CCTV4å›½é™…": "CCTV4",
            r"CCTV5ä½“è‚²": "CCTV5",
            r"CCTV6ç”µå½±": "CCTV6",
            r"CCTV7å†›äº‹": "CCTV7",
            r"CCTV7å†›å†œ": "CCTV7",
            r"CCTV7å›½é˜²å†›äº‹": "CCTV7",
            r"CCTV8ç”µè§†å‰§": "CCTV8",
            r"CCTV9è®°å½•": "CCTV9",
            r"CCTV9çºªå½•": "CCTV9",
            r"CCTV10ç§‘æ•™": "CCTV10",
            r"CCTV11æˆæ›²": "CCTV11",
            r"CCTV12ç¤¾ä¼šä¸æ³•": "CCTV12",
            r"CCTV13æ–°é—»": "CCTV13",
            r"CCTVæ–°é—»": "CCTV13",
            r"CCTV14å°‘å„¿": "CCTV14",
            r"CCTV15éŸ³ä¹": "CCTV15",
            r"CCTV16å¥¥æ—åŒ¹å…‹": "CCTV16",
            r"CCTV17å†œä¸šå†œæ‘": "CCTV17",
            r"CCTV5\+ä½“è‚²èµ›è§†": "CCTV5+",
            r"CCTV5\+ä½“è‚²èµ›äº‹": "CCTV5+"
        }
        
        cleaned_name = str(name)
        for pattern, replacement in name_mappings.items():
            cleaned_name = re.sub(pattern, replacement, cleaned_name)
        
        return cleaned_name.strip()

    def is_valid_url(self, url):
        """éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ"""
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except:
            return False

    def test_channel_quality(self, channel_url):
        """æµ‹è¯•é¢‘é“è´¨é‡"""
        try:
            start_time = time.time()
            response = self.session.head(channel_url, timeout=5, allow_redirects=True)
            response_time = time.time() - start_time
            
            if response.status_code in [200, 302]:
                return True, response_time
            return False, response_time
        except:
            return False, float('inf')

    def process_single_server(self, server_url):
        """å¤„ç†å•ä¸ªæœåŠ¡å™¨"""
        results = []
        try:
            # å¯èƒ½çš„JSONè·¯å¾„åˆ—è¡¨
            json_paths = [
                "/iptv/live/1000.json?key=txiptv",
                "/iptv/live/1000.json",
                "/live/1000.json",
                "/tv/1000.json",
                "/iptv/live.json",
                "/api/live",
                "/live.json"
            ]
            
            for json_path in json_paths:
                try:
                    # æ„å»ºå®Œæ•´çš„JSON URL
                    if json_path.startswith('/'):
                        json_url = f"{server_url}{json_path}"
                    else:
                        json_url = f"{server_url}/{json_path}"
                    
                    logging.info(f"Trying: {json_url}")
                    
                    response = self.session.get(json_url, timeout=8)
                    if response.status_code == 200:
                        try:
                            json_data = response.json()
                        except json.JSONDecodeError:
                            logging.warning(f"Invalid JSON from {json_url}")
                            continue
                        
                        channel_count = 0
                        # å¤„ç†ä¸åŒçš„JSONç»“æ„
                        data_list = json_data.get('data', [])
                        if not data_list and isinstance(json_data, list):
                            data_list = json_data
                        
                        for item in data_list:
                            if isinstance(item, dict):
                                name = item.get('name', '') or item.get('title', '')
                                urlx = item.get('url', '') or item.get('link', '')
                                
                                if name and urlx:
                                    cleaned_name = self.clean_channel_name(name)
                                    
                                    # æ„å»ºå®Œæ•´çš„é¢‘é“URL
                                    if urlx.startswith(('http://', 'https://')):
                                        full_url = urlx
                                    elif urlx.startswith('/'):
                                        full_url = f"{server_url}{urlx}"
                                    else:
                                        full_url = f"{server_url}/{urlx}"
                                    
                                    if self.is_valid_url(full_url):
                                        # æµ‹è¯•é¢‘é“å¯ç”¨æ€§
                                        is_available, response_time = self.test_channel_quality(full_url)
                                        if is_available:
                                            results.append({
                                                'name': cleaned_name,
                                                'url': full_url,
                                                'response_time': response_time,
                                                'source': server_url,
                                                'quality': 'GOOD' if response_time < 1.0 else 'NORMAL'
                                            })
                                            channel_count += 1
                        
                        if channel_count > 0:
                            logging.info(f"âœ… Found {channel_count} channels from {server_url} using {json_path}")
                            break  # æ‰¾åˆ°æœ‰æ•ˆè·¯å¾„å°±åœæ­¢å°è¯•
                        else:
                            logging.warning(f"âŒ No valid channels found from {server_url} using {json_path}")
                            
                except requests.RequestException as e:
                    logging.debug(f"Request failed for {json_path}: {e}")
                    continue
                except Exception as e:
                    logging.debug(f"Error processing {json_path}: {e}")
                    continue
                    
            if not results:
                logging.warning(f"âŒ No channels found from {server_url} after trying all paths")
                    
        except Exception as e:
            logging.error(f"âŒ Error processing server {server_url}: {str(e)}")
        
        return results

    def process_all_servers(self, servers):
        """å¤„ç†æ‰€æœ‰æœåŠ¡å™¨"""
        logging.info(f"\n{'='*60}")
        logging.info(f"ğŸš€ Starting IPTV collection from {len(servers)} servers")
        logging.info(f"{'='*60}")
        
        try:
            all_results = []
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ‰€æœ‰æœåŠ¡å™¨
            with ThreadPoolExecutor(max_workers=5) as executor:
                future_to_server = {
                    executor.submit(self.process_single_server, server): server 
                    for server in servers
                }
                
                completed = 0
                total = len(future_to_server)
                
                for future in as_completed(future_to_server):
                    completed += 1
                    server_url = future_to_server[future]
                    try:
                        results = future.result()
                        if results:
                            all_results.extend(results)
                            logging.info(f"âœ… [{completed}/{total}] {server_url}: {len(results)} channels")
                        else:
                            logging.info(f"âŒ [{completed}/{total}] {server_url}: No channels found")
                    except Exception as e:
                        logging.error(f"âŒ [{completed}/{total}] {server_url}: Failed - {e}")
            
            # æŒ‰å“åº”æ—¶é—´æ’åº
            all_results.sort(key=lambda x: x['response_time'])
            
            logging.info(f"ğŸ“Š Total: {len(all_results)} channels from {len(servers)} servers")
            return all_results
            
        except Exception as e:
            logging.error(f"âŒ Error processing servers: {str(e)}")
            return []

    def categorize_channels(self, results):
        """å°†é¢‘é“åˆ†ç±»ä¸ºå¤®è§†å’Œå«è§†"""
        cctv_channels = []
        satellite_channels = []
        other_channels = []
        
        # å¤®è§†é¢‘é“å…³é”®è¯
        cctv_keywords = ['CCTV', 'å¤®è§†']
        # å«è§†é¢‘é“å…³é”®è¯ - å„çœå«è§†
        satellite_keywords = [
            'åŒ—äº¬', 'ä¸Šæµ·', 'å¤©æ´¥', 'é‡åº†', 'æ²³åŒ—', 'å±±è¥¿', 'è¾½å®', 'å‰æ—', 'é»‘é¾™æ±Ÿ',
            'æ±Ÿè‹', 'æµ™æ±Ÿ', 'å®‰å¾½', 'ç¦å»º', 'æ±Ÿè¥¿', 'å±±ä¸œ', 'æ²³å—', 'æ¹–åŒ—', 'æ¹–å—',
            'å¹¿ä¸œ', 'æµ·å—', 'å››å·', 'è´µå·', 'äº‘å—', 'é™•è¥¿', 'ç”˜è‚ƒ', 'é’æµ·', 'å°æ¹¾',
            'å†…è’™å¤', 'å¹¿è¥¿', 'è¥¿è—', 'å®å¤', 'æ–°ç–†', 'é¦™æ¸¯', 'æ¾³é—¨',
            'å«è§†', 'æ¹–å—å«è§†', 'æµ™æ±Ÿå«è§†', 'æ±Ÿè‹å«è§†', 'ä¸œæ–¹å«è§†', 'åŒ—äº¬å«è§†'
        ]
        
        for channel in results:
            name = channel['name']
            is_cctv = any(keyword in name for keyword in cctv_keywords)
            is_satellite = any(keyword in name for keyword in satellite_keywords)
            
            if is_cctv:
                cctv_channels.append(channel)
            elif is_satellite:
                satellite_channels.append(channel)
            else:
                other_channels.append(channel)
        
        return {
            'cctv': cctv_channels,
            'satellite': satellite_channels,
            'other': other_channels
        }

    def save_results(self, results, filename, format='txt'):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        if not results:
            logging.warning(f"âš ï¸ No results to save for {filename}")
            return False
        
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else '.', exist_ok=True)
            
            if format == 'txt':
                with open(filename, "w", encoding="utf-8") as file:
                    # å¯¹é¢‘é“è¿›è¡Œåˆ†ç±»
                    categorized = self.categorize_channels(results)
                    
                    # å†™å…¥å¤®è§†é¢‘é“
                    if categorized['cctv']:
                        file.write("å¤®è§†é¢‘é“,#genre#\n")
                        for channel in categorized['cctv']:
                            file.write(f"{channel['name']},{channel['url']}\n")
                        file.write("\n")
                    
                    # å†™å…¥å«è§†é¢‘é“
                    if categorized['satellite']:
                        file.write("å«è§†é¢‘é“,#genre#\n")
                        for channel in categorized['satellite']:
                            file.write(f"{channel['name']},{channel['url']}\n")
                        file.write("\n")
                    
                    # å†™å…¥å…¶ä»–é¢‘é“
                    if categorized['other']:
                        file.write("å…¶ä»–é¢‘é“,#genre#\n")
                        for channel in categorized['other']:
                            file.write(f"{channel['name']},{channel['url']}\n")
            
            elif format == 'm3u':
                with open(filename, "w", encoding="utf-8") as file:
                    file.write("#EXTM3U\n")
                    for result in results:
                        file.write(f"#EXTINF:-1 tvg-name=\"{result['name']}\",{result['name']}\n")
                        file.write(f"{result['url']}\n")
            
            logging.info(f"ğŸ’¾ Saved {len(results)} results to {filename}")
            return True
            
        except Exception as e:
            logging.error(f"âŒ Error saving results to {filename}: {e}")
            return False

def remove_duplicate_channels(results):
    """å»é™¤é‡å¤é¢‘é“ï¼ˆåŸºäºåç§°å’ŒURLï¼‰"""
    unique_channels = {}
    
    for result in results:
        key = (result['name'].lower(), result['url'])
        # ä¿ç•™å“åº”æ—¶é—´æ›´çŸ­çš„ç‰ˆæœ¬
        if key not in unique_channels or result['response_time'] < unique_channels[key]['response_time']:
            unique_channels[key] = result
    
    return list(unique_channels.values())

def generate_stats(results):
    """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
    if not results:
        return
    
    # åˆ›å»ºæ”¶é›†å™¨å®ä¾‹ç”¨äºåˆ†ç±»
    collector = IPTVCollector()
    categorized = collector.categorize_channels(results)
    
    stats = {
        'cctv_count': len(categorized['cctv']),
        'satellite_count': len(categorized['satellite']),
        'other_count': len(categorized['other']),
        'sources': set(),
        'quality_good': 0,
        'quality_normal': 0
    }
    
    for result in results:
        stats['sources'].add(result['source'])
        if result['quality'] == 'GOOD':
            stats['quality_good'] += 1
        else:
            stats['quality_normal'] += 1
    
    logging.info(f"ğŸ“Š Channel Statistics:")
    logging.info(f"   ğŸ“º CCTV Channels: {stats['cctv_count']}")
    logging.info(f"   ğŸ›°ï¸ Satellite Channels: {stats['satellite_count']}")
    logging.info(f"   ğŸ”„ Other Channels: {stats['other_count']}")
    logging.info(f"   âœ… Good Quality: {stats['quality_good']}")
    logging.info(f"   âš ï¸  Normal Quality: {stats['quality_normal']}")
    logging.info(f"   ğŸŒ Unique Sources: {len(stats['sources'])}")

def run_scanner():
    """è¿è¡Œæ‰«æå™¨"""
    scanner = IPTVScanner()
    start_time = time.time()
    
    logging.info("ğŸš€ Starting IPTV Server Scanner")
    logging.info("=" * 50)
    
    # 1. å¿«é€Ÿæ‰«æå·²çŸ¥æœåŠ¡å™¨
    logging.info("ğŸ” Phase 1: Quick scan of known servers...")
    quick_results = scanner.quick_scan_common_servers()
    
    # 2. æ·±åº¦ç½‘ç»œæ‰«æï¼ˆåœ¨GitHub Actionsä¸­å‡å°‘æ‰«ææ•°é‡ï¼‰
    logging.info("ğŸŒ Phase 2: Light network scan...")
    deep_scan_count = scanner.deep_scan_network(max_ips=50)
    
    # ä¿å­˜ç»“æœ
    scanner.save_found_servers()
    
    # ç»Ÿè®¡ä¿¡æ¯
    end_time = time.time()
    processing_time = end_time - start_time
    
    logging.info("=" * 50)
    logging.info("ğŸ“Š SCAN SUMMARY")
    logging.info("=" * 50)
    logging.info(f"â±ï¸  Processing time: {processing_time:.2f} seconds")
    logging.info(f"ğŸ¯ Total servers found: {len(scanner.found_servers)}")
    
    if scanner.found_servers:
        logging.info("\nğŸ“‹ Discovered Servers:")
        for server in scanner.found_servers[:5]:
            logging.info(f"   ğŸ“º {server['ip']}:{server['port']} - {server['channel_count']} channels")
        
        if len(scanner.found_servers) > 5:
            logging.info(f"   ... and {len(scanner.found_servers) - 5} more servers")
    
    logging.info("=" * 50)
    
    return scanner.load_servers_for_collection()

def run_collector(servers=None):
    """è¿è¡Œæ”¶é›†å™¨"""
    collector = IPTVCollector()
    start_time = time.time()
    
    # å¦‚æœæ²¡æœ‰æä¾›æœåŠ¡å™¨ï¼Œå°è¯•ä»æ–‡ä»¶åŠ è½½
    if servers is None:
        servers = collector.load_servers_from_file()
    
    # å¦‚æœæ²¡æœ‰å‘ç°æœåŠ¡å™¨ï¼Œä½¿ç”¨é»˜è®¤æœåŠ¡å™¨
    if not servers:
        default_servers = [
            "http://60.214.107.42:8080",
            "http://113.57.127.43:8080", 
            "http://58.222.24.11:8080",
            "http://117.169.120.140:8080",
            "http://112.30.144.207:8080"
        ]
        servers = default_servers
        logging.info("ğŸ“¡ Using default servers for collection")
    
    logging.info("ğŸš€ Starting IPTV collection process...")
    logging.info(f"ğŸ“¡ Total servers to process: {len(servers)}")
    
    # å¤„ç†æ‰€æœ‰æœåŠ¡å™¨
    all_results = collector.process_all_servers(servers)
    
    # åˆå¹¶æ‰€æœ‰ç»“æœå¹¶å»é‡
    if all_results:
        logging.info(f"\nğŸ”„ Merging and deduplicating {len(all_results)} channels...")
        final_results = remove_duplicate_channels(all_results)
        final_results.sort(key=lambda x: (x['name'], x['response_time']))
        
        # åˆ†ç±»ç»Ÿè®¡
        categorized = collector.categorize_channels(final_results)
        logging.info(f"ğŸ“º Channel Categories:")
        logging.info(f"   ğŸ“º CCTV: {len(categorized['cctv'])} channels")
        logging.info(f"   ğŸ›°ï¸ Satellite: {len(categorized['satellite'])} channels")
        logging.info(f"   ğŸ”„ Other: {len(categorized['other'])} channels")
        
        # ä¿å­˜æœ€ç»ˆæ–‡ä»¶
        collector.save_results(final_results, "iptv.txt", 'txt')
        collector.save_results(final_results, "iptv.m3u", 'm3u')
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        generate_stats(final_results)
        
        logging.info(f"âœ… Merged {len(all_results)} channels into {len(final_results)} unique channels")
    else:
        logging.error("âŒ No valid channels collected!")
        # åˆ›å»ºç©ºçš„IPTVæ–‡ä»¶
        with open("iptv.txt", "w", encoding="utf-8") as f:
            f.write("å¤®è§†é¢‘é“,#genre#\n")
            f.write("å«è§†é¢‘é“,#genre#\n")
        with open("iptv.m3u", "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
    
    # è¾“å‡ºæ€»ç»“
    end_time = time.time()
    processing_time = end_time - start_time
    
    logging.info(f"\n{'='*60}")
    logging.info("ğŸ“Š COLLECTION SUMMARY")
    logging.info(f"{'='*60}")
    logging.info(f"â±ï¸  Processing time: {processing_time:.2f} seconds")
    logging.info(f"ğŸ“º Total channels collected: {len(all_results)}")
    logging.info(f"ğŸ¯ Unique channels: {len(final_results) if all_results else 0}")
    logging.info(f"ğŸ“¡ Servers processed: {len(servers)}")
    logging.info(f"ğŸ’¾ Output files: iptv.txt, iptv.m3u")
    logging.info(f"{'='*60}")

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æ˜¯å¦åœ¨éäº¤äº’ç¯å¢ƒä¸­è¿è¡Œï¼ˆå¦‚GitHub Actionsï¼‰
    if not sys.stdin.isatty():
        logging.info("ğŸ¤– Running in non-interactive mode (GitHub Actions)")
        logging.info("ğŸš€ Starting full IPTV collection process...")
        
        # è¿è¡Œæ‰«æå™¨
        servers = run_scanner()
        
        # è¿è¡Œæ”¶é›†å™¨
        if servers:
            run_collector(servers)
        else:
            logging.warning("âš ï¸ No servers found during scan, using default servers")
            run_collector()
        return
    
    # åŸæœ‰çš„äº¤äº’å¼èœå•ä»£ç ï¼ˆç”¨äºæœ¬åœ°è¿è¡Œï¼‰
    print("\n" + "="*60)
    print("ğŸ¯ IPTV System - Complete Solution")
    print("="*60)
    print("1. ğŸ” Scan for IPTV servers")
    print("2. ğŸ“º Collect channels from existing servers")
    print("3. ğŸš€ Scan and collect (full process)")
    print("4. ğŸ“ Collect from discovered servers")
    print("="*60)
    
    try:
        choice = input("Select option (1-4): ").strip()
        
        if choice == "1":
            run_scanner()
        elif choice == "2":
            run_collector()
        elif choice == "3":
            servers = run_scanner()
            if servers:
                run_collector(servers)
            else:
                run_collector()
        elif choice == "4":
            run_collector()
        else:
            logging.error("âŒ Invalid choice!")
    except EOFError:
        # å¤„ç†éäº¤äº’ç¯å¢ƒä¸­çš„EOFé”™è¯¯
        logging.info("ğŸš€ Auto-selecting full process in non-interactive environment")
        servers = run_scanner()
        if servers:
            run_collector(servers)
        else:
            run_collector()
    except KeyboardInterrupt:
        logging.info("ğŸ‘‹ Operation cancelled by user")

if __name__ == "__main__":
    main()
