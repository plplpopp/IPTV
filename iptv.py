#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import time
import concurrent.futures
import re
from typing import List, Dict, Set, Any
from urllib.parse import urlparse
import json

class IPTVUpdater:
    def __init__(self):
        self.sources = [
            "https://raw.githubusercontent.com/vbskyn/iptv/master/tv/iptv4.txt",
            "https://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt",
            "http://47.120.41.246:8899/zb.txt",
            # å¯ä»¥æ·»åŠ æ›´å¤šæº...
        ]
        
        # åˆå§‹åŒ–æ¨¡æ¿æ ‡å‡†åŒ–è§„åˆ™
        self.ttemplate_norm = {
            'cctv': 'CCTV',
            'ä¸­å¤®': 'CCTV',
            'å¤®è§†': 'CCTV',
            'æ¹–å—å«è§†': 'æ¹–å—',
            'æµ™æ±Ÿå«è§†': 'æµ™æ±Ÿ', 
            'æ±Ÿè‹å«è§†': 'æ±Ÿè‹',
            'åŒ—äº¬å«è§†': 'åŒ—äº¬',
            'ä¸œæ–¹å«è§†': 'ä¸œæ–¹',
            'å¹¿ä¸œå«è§†': 'å¹¿ä¸œ',
            'æ·±åœ³å«è§†': 'æ·±åœ³',
            'å¤©æ´¥å«è§†': 'å¤©æ´¥',
            'å±±ä¸œå«è§†': 'å±±ä¸œ',
            'å®‰å¾½å«è§†': 'å®‰å¾½',
            'é‡åº†å«è§†': 'é‡åº†',
            'å››å·å«è§†': 'å››å·',
            'è¾½å®å«è§†': 'è¾½å®',
            'é»‘é¾™æ±Ÿå«è§†': 'é»‘é¾™æ±Ÿ',
            'æ¹–åŒ—å«è§†': 'æ¹–åŒ—',
            'æ²³å—å«è§†': 'æ²³å—'
        }
        
        self.collected_streams = []
        self.unique_streams = []

    def fetch_source(self, url: str) -> Dict[str, Any]:
        """è·å–å•ä¸ªæºçš„å†…å®¹"""
        print(f"ğŸ“¡ æ­£åœ¨çˆ¬å–ï¼š{url}")
        start_time = time.time()
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            content_length = len(response.text)
            duration = time.time() - start_time
            
            # è§£ææµæ•°é‡
            streams = self.parse_streams(response.text)
            
            print(f"âœ… æˆåŠŸè·å–ï¼š{content_length} å­—ç¬¦")
            print(f"âœ… ä» {url} è·å– {len(streams)} ä¸ªæµ")
            
            return {
                'url': url,
                'status': 'success',
                'content': response.text,
                'streams': streams,
                'content_length': content_length,
                'duration': duration,
                'stream_count': len(streams)
            }
            
        except Exception as e:
            print(f"âŒ è·å–å¤±è´¥ï¼š{url} - {str(e)}")
            return {
                'url': url,
                'status': 'error',
                'error': str(e),
                'content': '',
                'streams': [],
                'content_length': 0,
                'duration': time.time() - start_time,
                'stream_count': 0
            }

    def parse_streams(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­è§£æå‡ºæµURL"""
        streams = []
        
        # å¤šç§æ ¼å¼æ”¯æŒ
        patterns = [
            r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',
            r'^[^#].*\.m3u8?$',
            r'^[^#].*\.flv?$',
            r'^[^#].*\.mp4?$',
            r'^[^#].*\.ts?$'
        ]
        
        for line in content.split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                for pattern in patterns:
                    matches = re.findall(pattern, line)
                    for match in matches:
                        if any(ext in match.lower() for ext in ['.m3u8', '.flv', '.mp4', '.ts', 'rtmp://', 'rtsp://']):
                            streams.append(match)
        
        return streams

    def remove_duplicate_streams(self, streams: List[str]) -> List[str]:
        """å»é™¤é‡å¤çš„æµ"""
        print("ğŸ”„ å¼€å§‹å»é‡å¤„ç†...")
        original_count = len(streams)
        
        # åŸºäºURLå»é‡
        seen_urls = set()
        unique_streams = []
        
        for stream in streams:
            # æ ‡å‡†åŒ–URL
            normalized_url = self.normalize_url(stream)
            if normalized_url not in seen_urls:
                seen_urls.add(normalized_url)
                unique_streams.append(stream)
        
        removed_count = original_count - len(unique_streams)
        print(f"âœ… å»é‡å®Œæˆï¼šç§»é™¤ {removed_count} ä¸ªé‡å¤æµ")
        
        return unique_streams

    def normalize_url(self, url: str) -> str:
        """æ ‡å‡†åŒ–URLç”¨äºå»é‡"""
        try:
            parsed = urlparse(url)
            # ç§»é™¤æŸ¥è¯¢å‚æ•°å’Œç‰‡æ®µ
            normalized = f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
            return normalized.lower()
        except:
            return url.lower()

    class AdvancedSpeedTester:
        def __init__(self, max_workers=10, timeout=5):
            self.max_workers = max_workers
            self.timeout = timeout
            self.session = requests.Session()
            self.session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })

        def test_single_stream(self, stream_url: str) -> Dict:
            """æµ‹è¯•å•ä¸ªæµçš„é€Ÿåº¦å’Œå¯ç”¨æ€§"""
            start_time = time.time()
            try:
                response = self.session.get(
                    stream_url, 
                    timeout=self.timeout,
                    stream=True,
                    verify=False  # å¯¹äºè‡ªç­¾åè¯ä¹¦çš„æº
                )
                response.raise_for_status()
                
                # è¯»å–å‰50KBæµ‹è¯•é€Ÿåº¦
                chunk_size = 1024
                total_read = 0
                max_test_size = 50 * 1024  # 50KB
                test_start = time.time()
                
                for chunk in response.iter_content(chunk_size=chunk_size):
                    total_read += len(chunk)
                    if total_read >= max_test_size:
                        break
                    if time.time() - test_start > self.timeout:
                        break
                
                end_time = time.time()
                duration = end_time - start_time
                speed = total_read / duration if duration > 0 else 0
                
                return {
                    'url': stream_url,
                    'status': 'success',
                    'speed_kbps': speed / 1024,
                    'response_time': duration,
                    'content_length': total_read,
                    'quality': 'excellent' if speed > 500 * 1024 else 'good' if speed > 100 * 1024 else 'fair'
                }
                
            except Exception as e:
                return {
                    'url': stream_url,
                    'status': 'error',
                    'error': str(e),
                    'speed_kbps': 0,
                    'response_time': time.time() - start_time,
                    'content_length': 0,
                    'quality': 'poor'
                }

        def batch_test_streams(self, stream_urls: List[str], sample_size: int = 200) -> Dict:
            """æ‰¹é‡æµ‹è¯•æµé€Ÿåº¦ï¼Œæ”¯æŒæŠ½æ ·æµ‹è¯•"""
            if len(stream_urls) > sample_size:
                print(f"ğŸ“Š æµæ•°é‡è¾ƒå¤š({len(stream_urls)})ï¼Œè¿›è¡ŒæŠ½æ ·æµ‹è¯•({sample_size}ä¸ªæ ·æœ¬)")
                # ç®€å•æŠ½æ ·ï¼šå–å‰sample_sizeä¸ª
                stream_urls = stream_urls[:sample_size]
            
            results = {}
            print(f"ğŸš€ å¼€å§‹æµ‹é€Ÿï¼Œå…± {len(stream_urls)} ä¸ªæµ...")
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                future_to_url = {
                    executor.submit(self.test_single_stream, url): url 
                    for url in stream_urls
                }
                
                completed = 0
                for future in concurrent.futures.as_completed(future_to_url):
                    url = future_to_url[future]
                    try:
                        results[url] = future.result()
                        completed += 1
                        if completed % 20 == 0:
                            print(f"ğŸ“ˆ æµ‹é€Ÿè¿›åº¦: {completed}/{len(stream_urls)}")
                    except Exception as e:
                        results[url] = {
                            'url': url,
                            'status': 'error',
                            'error': str(e),
                            'speed_kbps': 0,
                            'response_time': 0,
                            'content_length': 0,
                            'quality': 'poor'
                        }
                        completed += 1
            
            return results

    class SmartSpeedTester:
        def __init__(self):
            self.speed_thresholds = {
                'excellent': 2000,  # 2MB/s
                'good': 500,        # 500KB/s
                'fair': 100,        # 100KB/s
                'poor': 10          # 10KB/s
            }

        def categorize_speed(self, speed_kbps: float) -> str:
            """æ ¹æ®é€Ÿåº¦åˆ†ç±»æµè´¨é‡"""
            if speed_kbps >= self.speed_thresholds['excellent']:
                return 'excellent'
            elif speed_kbps >= self.speed_thresholds['good']:
                return 'good'
            elif speed_kbps >= self.speed_thresholds['fair']:
                return 'fair'
            else:
                return 'poor'

        def optimize_stream_selection(self, test_results: Dict) -> List[str]:
            """ä¼˜åŒ–æµé€‰æ‹©ç­–ç•¥"""
            categorized_streams = {
                'excellent': [],
                'good': [],
                'fair': [],
                'poor': []
            }
            
            # åˆ†ç±»æµ
            for url, result in test_results.items():
                if result['status'] == 'success':
                    category = self.categorize_speed(result['speed_kbps'])
                    categorized_streams[category].append({
                        'url': url,
                        'speed': result['speed_kbps'],
                        'response_time': result['response_time']
                    })
            
            # ä¼˜åŒ–é€‰æ‹©ï¼šä¼˜å…ˆé€‰æ‹©ä¼˜ç§€å’Œè‰¯å¥½çš„æµ
            optimized_streams = []
            
            # æŒ‰å“åº”æ—¶é—´æ’åºå¹¶é€‰æ‹©
            for category in ['excellent', 'good', 'fair']:
                sorted_streams = sorted(categorized_streams[category], 
                                      key=lambda x: x['response_time'])
                for stream in sorted_streams:
                    optimized_streams.append(stream['url'])
            
            return optimized_streams

    def enhanced_speed_testing(self, streams: List[str]) -> Dict:
        """å¢å¼ºçš„æµ‹é€Ÿæµç¨‹"""
        print("âš¡ å¼€å§‹å¢å¼ºæµ‹é€Ÿ...")
        
        # åˆå§‹åŒ–æµ‹é€Ÿå™¨
        speed_tester = self.AdvancedSpeedTester(max_workers=15, timeout=8)
        smart_tester = self.SmartSpeedTester()
        
        # æ‰¹é‡æµ‹é€Ÿ
        test_results = speed_tester.batch_test_streams(streams)
        
        # åˆ†æç»“æœ
        successful = [r for r in test_results.values() if r['status'] == 'success']
        failed = [r for r in test_results.values() if r['status'] == 'error']
        
        print(f"âœ… æµ‹é€ŸæˆåŠŸ: {len(successful)} ä¸ªæµ")
        print(f"âŒ æµ‹é€Ÿå¤±è´¥: {len(failed)} ä¸ªæµ")
        
        if successful:
            avg_speed = sum(r['speed_kbps'] for r in successful) / len(successful)
            max_speed = max(r['speed_kbps'] for r in successful)
            print(f"ğŸ“ˆ å¹³å‡é€Ÿåº¦: {avg_speed:.2f} KB/s")
            print(f"ğŸ† æœ€é«˜é€Ÿåº¦: {max_speed:.2f} KB/s")
            
            # è´¨é‡åˆ†å¸ƒ
            quality_dist = {}
            for result in successful:
                quality = result['quality']
                quality_dist[quality] = quality_dist.get(quality, 0) + 1
            
            print("ğŸ¯ è´¨é‡åˆ†å¸ƒ:", quality_dist)
        
        # ä¼˜åŒ–æµé€‰æ‹©
        optimized_streams = smart_tester.optimize_stream_selection(test_results)
        print(f"ğŸ¯ ä¼˜åŒ–åé€‰æ‹©: {len(optimized_streams)} ä¸ªä¼˜è´¨æµ")
        
        return {
            'test_results': test_results,
            'optimized_streams': optimized_streams,
            'statistics': {
                'total_tested': len(streams),
                'successful': len(successful),
                'failed': len(failed),
                'avg_speed': avg_speed if successful else 0,
                'max_speed': max_speed if successful else 0
            }
        }

    def smart_channel_matching(self, streams: List[str]) -> List[Dict]:
        """æ™ºèƒ½é¢‘é“åŒ¹é…"""
        print("ğŸ” å¼€å§‹æ™ºèƒ½é¢‘é“åŒ¹é…...")
        
        try:
            matched_channels = []
            
            for stream_url in streams:
                channel_name = self.extract_channel_name(stream_url)
                normalized_name = self.normalize_channel_name(channel_name)
                
                matched_channels.append({
                    'name': normalized_name,
                    'url': stream_url,
                    'original_name': channel_name
                })
            
            print(f"âœ… é¢‘é“åŒ¹é…å®Œæˆ: {len(matched_channels)} ä¸ªé¢‘é“")
            return matched_channels
            
        except Exception as e:
            print(f"âŒ æ™ºèƒ½é¢‘é“åŒ¹é…å‡ºé”™: {e}")
            # å›é€€åˆ°åŸºç¡€åŒ¹é…
            return self.basic_channel_matching(streams)

    def extract_channel_name(self, url: str) -> str:
        """ä»URLä¸­æå–é¢‘é“åç§°"""
        try:
            # ä»URLè·¯å¾„ä¸­æå–å¯èƒ½çš„é¢‘é“å
            parsed = urlparse(url)
            path_parts = parsed.path.split('/')
            
            for part in path_parts:
                if part and '.' not in part and len(part) > 1:
                    # ç®€å•çš„é¢‘é“åæå–é€»è¾‘
                    if any(keyword in part.lower() for keyword in ['cctv', 'tv', 'channel', 'live']):
                        return part
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨æœ€åä¸€éƒ¨åˆ†éç©ºè·¯å¾„
            for part in reversed(path_parts):
                if part and '.' not in part:
                    return part
            
            return "æœªçŸ¥é¢‘é“"
        except:
            return "æœªçŸ¥é¢‘é“"

    def normalize_channel_name(self, name: str) -> str:
        """æ ‡å‡†åŒ–é¢‘é“åç§°"""
        if not name or name == "æœªçŸ¥é¢‘é“":
            return "å…¶ä»–é¢‘é“"
        
        name_lower = name.lower()
        
        # ä½¿ç”¨é¢„å®šä¹‰çš„æ ‡å‡†åŒ–è§„åˆ™
        for key, value in self.ttemplate_norm.items():
            if key in name_lower:
                return value
        
        # ç®€å•çš„æ•°å­—é¢‘é“å¤„ç†
        if re.search(r'cctv-?\d+', name_lower):
            match = re.search(r'cctv-?(\d+)', name_lower)
            return f"CCTV-{match.group(1)}"
        
        return name

    def basic_channel_matching(self, streams: List[str]) -> List[Dict]:
        """åŸºç¡€é¢‘é“åŒ¹é…ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        print("ğŸ”„ ä½¿ç”¨åŸºç¡€é¢‘é“åŒ¹é…...")
        
        channels = []
        for i, stream_url in enumerate(streams):
            channels.append({
                'name': f'é¢‘é“{i+1}',
                'url': stream_url,
                'original_name': 'æœªè¯†åˆ«'
            })
        
        return channels

    def generate_optimized_playlist(self, channels: List[Dict]) -> str:
        """ç”Ÿæˆä¼˜åŒ–çš„æ’­æ”¾åˆ—è¡¨"""
        print("ğŸ“ ç”Ÿæˆä¼˜åŒ–æ’­æ”¾åˆ—è¡¨...")
        
        playlist = "#EXTM3U\n"
        playlist += "# Generated by Enhanced IPTV Updater\n"
        playlist += f"# Update Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        playlist += f"# Total Channels: {len(channels)}\n\n"
        
        for channel in channels:
            playlist += f"#EXTINF:-1, {channel['name']}\n"
            playlist += f"{channel['url']}\n\n"
        
        return playlist

    def save_playlist(self, playlist: str, filename: str = "optimized_iptv.m3u"):
        """ä¿å­˜æ’­æ”¾åˆ—è¡¨åˆ°æ–‡ä»¶"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(playlist)
            print(f"ğŸ’¾ æ’­æ”¾åˆ—è¡¨å·²ä¿å­˜: {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ’­æ”¾åˆ—è¡¨å¤±è´¥: {e}")

    def update_documentation(self):
        """æ›´æ–°æ–‡æ¡£"""
        print("ğŸ“„ æ›´æ–°æ–‡æ¡£...")
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´æ–°READMEæˆ–å…¶ä»–æ–‡æ¡£çš„é€»è¾‘
        print("âœ… æ–‡æ¡£æ›´æ–°å®Œæˆ")

    def main_enhanced_update(self):
        """å¢å¼ºçš„ä¸»æ›´æ–°æµç¨‹"""
        print("ğŸ¬ å¼€å§‹å¢å¼ºç‰ˆIPTVæ›´æ–°æµç¨‹...")
        start_time = time.time()
        
        try:
            # 1. è·å–æ‰€æœ‰æº
            print("ğŸŒ è·å–IPTVæº...")
            fetch_results = []
            
            for source in self.sources:
                result = self.fetch_source(source)
                fetch_results.append(result)
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            # ç»Ÿè®¡è·å–ç»“æœ
            successful_fetches = [r for r in fetch_results if r['status'] == 'success']
            failed_fetches = [r for r in fetch_results if r['status'] == 'error']
            
            print(f"ğŸ“Š åœ¨çº¿æºè·å–å®Œæˆ: {len(successful_fetches)} æˆåŠŸ, {len(failed_fetches)} å¤±è´¥")
            
            # 2. æ”¶é›†æ‰€æœ‰æµ
            all_streams = []
            for result in successful_fetches:
                all_streams.extend(result['streams'])
            
            total_streams = len(all_streams)
            print(f"âœ… æ€»å…±æ”¶é›†åˆ°: {total_streams} ä¸ªæµ")
            
            if total_streams == 0:
                print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æµï¼Œç¨‹åºç»“æŸ")
                return
            
            # 3. å»é‡å¤„ç†
            self.unique_streams = self.remove_duplicate_streams(all_streams)
            print(f"ğŸ¯ å»é‡åå‰©ä½™: {len(self.unique_streams)} ä¸ªå”¯ä¸€æµ")
            
            # 4. å¢å¼ºæµ‹é€Ÿ
            speed_test_results = self.enhanced_speed_testing(self.unique_streams)
            
            # 5. æ™ºèƒ½é¢‘é“åŒ¹é…
            matched_channels = self.smart_channel_matching(speed_test_results['optimized_streams'])
            
            # 6. ç”Ÿæˆæ’­æ”¾åˆ—è¡¨
            optimized_playlist = self.generate_optimized_playlist(matched_channels)
            
            # 7. ä¿å­˜ç»“æœ
            self.save_playlist(optimized_playlist)
            
            # 8. æ›´æ–°æ–‡æ¡£
            self.update_documentation()
            
            total_duration = time.time() - start_time
            print(f"ğŸ‰ æ›´æ–°å®Œæˆï¼æ€»è€—æ—¶: {total_duration:.1f} ç§’")
            
            # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
            print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"   ğŸ“¡ æºæ•°é‡: {len(self.sources)}")
            print(f"   ğŸ”— åŸå§‹æµ: {total_streams}")
            print(f"   âœ¨ å”¯ä¸€æµ: {len(self.unique_streams)}") 
            print(f"   ğŸ¯ ä¼˜è´¨æµ: {len(speed_test_results['optimized_streams'])}")
            print(f"   ğŸ“º é¢‘é“æ•°: {len(matched_channels)}")
            print(f"   âš¡ å¹³å‡é€Ÿåº¦: {speed_test_results['statistics']['avg_speed']:.2f} KB/s")
            
            return optimized_playlist
            
        except Exception as e:
            print(f"âŒ æ›´æ–°è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•°"""
    updater = IPTVUpdater()
    updater.main_enhanced_update()

if __name__ == "__main__":
    main()
